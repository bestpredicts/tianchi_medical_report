{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMPKFpGu8nHj"
   },
   "source": [
    "## colab setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.279620Z",
     "start_time": "2021-03-27T05:33:39.597113Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26765,
     "status": "ok",
     "timestamp": 1614751860034,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "9xIF6ARO8GNh",
    "outputId": "f641d585-763d-410b-e949-fd8b4595ce00"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.283549Z",
     "start_time": "2021-03-27T05:33:40.281441Z"
    },
    "id": "AEjsYjfN_3si"
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/track1_round1_train_20210222.csv\"\n",
    "test_path = \"../input/track1_round1_testA_20210222.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.482632Z",
     "start_time": "2021-03-27T05:33:40.285298Z"
    },
    "id": "Yo0TdSbbAH2O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.519680Z",
     "start_time": "2021-03-27T05:33:40.484101Z"
    },
    "id": "H2PtNUAxB1PQ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path,sep=',',header=None)\n",
    "test_df = pd.read_csv(test_path,sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.530750Z",
     "start_time": "2021-03-27T05:33:40.520970Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 41971,
     "status": "ok",
     "timestamp": 1614751875303,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "eivMirH4B5Ei",
    "outputId": "23899729-f68d-4d6e-8573-b823af483deb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>|623 328 538 382 399 400 478 842 698 137 492 2...</td>\n",
       "      <td>|2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>|48 328 538 382 809 623 434 355 382 382 363 14...</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>|623 656 293 851 636 842 698 493 338 266 369 6...</td>\n",
       "      <td>|15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>|48 328 380 259 439 107 380 265 172 470 290 69...</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>|623 328 399 698 493 338 266 14 177 415 511 64...</td>\n",
       "      <td>|16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1     2\n",
       "0  0|  |623 328 538 382 399 400 478 842 698 137 492 2...   |2 \n",
       "1  1|  |48 328 538 382 809 623 434 355 382 382 363 14...     |\n",
       "2  2|  |623 656 293 851 636 842 698 493 338 266 369 6...  |15 \n",
       "3  3|  |48 328 380 259 439 107 380 265 172 470 290 69...     |\n",
       "4  4|  |623 328 399 698 493 338 266 14 177 415 511 64...  |16 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.536604Z",
     "start_time": "2021-03-27T05:33:40.531856Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 41963,
     "status": "ok",
     "timestamp": 1614751875313,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "vDTAh3DrCPwL",
    "outputId": "ba19c2ec-9a9f-4c17-90e3-d3430ac29425"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>|852 328 697 538 142 355 582 800 728 4 647 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>|380 358 343 654 171 832 47 832 690 693 48 563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>|751 335 834 582 717 583 585 693 623 328 107 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>|623 328 649 582 488 12 578 623 538 382 382 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>|83 293 398 797 382 363 145 424 693 698 800 69...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1\n",
       "0  0|  |852 328 697 538 142 355 582 800 728 4 647 169...\n",
       "1  1|  |380 358 343 654 171 832 47 832 690 693 48 563...\n",
       "2  2|  |751 335 834 582 717 583 585 693 623 328 107 3...\n",
       "3  3|  |623 328 649 582 488 12 578 623 538 382 382 26...\n",
       "4  4|  |83 293 398 797 382 363 145 424 693 698 800 69..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.549617Z",
     "start_time": "2021-03-27T05:33:40.537883Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 41948,
     "status": "ok",
     "timestamp": 1614751875315,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3XtljRWgFJZH",
    "outputId": "6164f30d-a830-4454-ddba-eefc2040bf15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1    2\n",
       "0  0|  623 328 538 382 399 400 478 842 698 137 492 26...   2 \n",
       "1  1|  48 328 538 382 809 623 434 355 382 382 363 145...     \n",
       "2  2|  623 656 293 851 636 842 698 493 338 266 369 69...  15 \n",
       "3  3|  48 328 380 259 439 107 380 265 172 470 290 693...     \n",
       "4  4|  623 328 399 698 493 338 266 14 177 415 511 647...  16 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[1]=train_df[1].apply(lambda x:x[1:-1])\n",
    "train_df[2]=train_df[2].apply(lambda x:x[1:])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.561523Z",
     "start_time": "2021-03-27T05:33:40.551704Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 41934,
     "status": "ok",
     "timestamp": 1614751875317,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "2sgxyBw8FQ5x",
    "outputId": "3ceed70e-bbca-4b62-8f8c-62f592c199f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1\n",
       "0  0|  852 328 697 538 142 355 582 800 728 4 647 169 ...\n",
       "1  1|  380 358 343 654 171 832 47 832 690 693 48 563 ...\n",
       "2  2|  751 335 834 582 717 583 585 693 623 328 107 38...\n",
       "3  3|  623 328 649 582 488 12 578 623 538 382 382 265...\n",
       "4  4|  83 293 398 797 382 363 145 424 693 698 800 691..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[1] = test_df[1].apply(lambda x:x[1:-1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.571004Z",
     "start_time": "2021-03-27T05:33:40.562962Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 41923,
     "status": "ok",
     "timestamp": 1614751875318,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "XYkg87_dFkM-",
    "outputId": "0ec740ce-ed49-4412-e83b-2be264c342a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1    2\n",
       "0  0|  623 328 538 382 399 400 478 842 698 137 492 26...   2 \n",
       "1  1|  48 328 538 382 809 623 434 355 382 382 363 145...     \n",
       "2  2|  623 656 293 851 636 842 698 493 338 266 369 69...  15 \n",
       "3  3|  48 328 380 259 439 107 380 265 172 470 290 693...     \n",
       "4  4|  623 328 399 698 493 338 266 14 177 415 511 647...  16 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([train_df,test_df])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.604844Z",
     "start_time": "2021-03-27T05:33:40.572086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.29823076923077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['len'] = all_df[1].apply(lambda x:len(x.split()))\n",
    "all_df['len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.694573Z",
     "start_time": "2021-03-27T05:33:40.606350Z"
    },
    "id": "e0oG5bxPba7w"
   },
   "outputs": [],
   "source": [
    "with open(\"all_data.txt\",'w') as f:\n",
    "    for _ in range(2):\n",
    "        for  l in range(len(all_df)):\n",
    "            text2 = all_df[1].values[l]\n",
    "            f.write(text2+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:40.825165Z",
     "start_time": "2021-03-27T05:33:40.695879Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43965,
     "status": "ok",
     "timestamp": 1614751877382,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "D0owh0q_bw86",
    "outputId": "67ca21b9-20af-4436-a181-2d08b3928b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623 328 538 382 399 400 478 842 698 137 492 266 521 177 415 381 693 700 132 706 317 534 830 290 512 729 327 548 520 445 51 240 711 818 445 358 240 711 693 623 328 380 172 54 175 563 470 609 \r\n",
      "48 328 538 382 809 623 434 355 382 382 363 145 424 389 693 808 266 751 335 832 47 693 583 328 305 206 461 204 48 328 740 204 411 204 549 728 832 122 \r\n",
      "623 656 293 851 636 842 698 493 338 266 369 691 693 380 136 363 399 556 698 66 432 449 177 830 381 332 290 380 26 343 28 177 415 832 14 \r\n",
      "48 328 380 259 439 107 380 265 172 470 290 693 556 698 54 623 34 138 351 761 693 657 305 342 809 618 282 300 654 556 698 432 449 693 380 834 809 343 809 832 47 693 514 569 428 614 34 846 138 693 358 380 136 363 399 556 698 313 66 432 449 177 415 145 693 380 172 809 380 654 439 380 834 832 47 750 256 514 837 231 113 256 \r\n",
      "623 328 399 698 493 338 266 14 177 415 511 647 693 852 60 328 380 172 54 788 591 487 \r\n",
      "80 328 328 54 172 439 741 380 172 842 698 177 777 415 832 14 381 693 623 328 697 382 38 582 382 363 177 257 415 145 755 404 386 106 566 521 \r\n",
      "48 322 795 856 374 439 48 328 443 380 597 172 320 842 698 494 149 266 218 415 106 521 79 693 380 361 200 737 813 306 693 556 698 554 232 823 34 138 351 761 693 305 654 809 282 300 654 678 195 698 432 449 693 66 834 809 343 809 654 556 104 698 832 47 617 256 514 129 231 614 34 138 693 91 382 569 231 134 698 313 66 432 623 \r\n",
      "623 328 659 486 582 162 711 289 606 405 809 78 477 693 697 777 582 162 716 854 832 122 693 697 582 38 582 2 498 165 397 455 693 724 328 697 698 494 504 382 672 514 381 \r\n",
      "852 328 471 585 117 458 399 607 693 380 522 623 304 160 380 303 789 439 852 328 419 571 769 256 661 809 621 499 300 832 582 698 493 338 266 521 177 415 381 \r\n",
      "229 172 200 737 437 547 651 693 623 328 355 653 382 579 488 776 591 487 693 91 400 478 698 477 300 797 415 381 \r\n"
     ]
    }
   ],
   "source": [
    "!head -10 all_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:33:41.420923Z",
     "start_time": "2021-03-27T05:33:40.829283Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44384,
     "status": "ok",
     "timestamp": 1614751877810,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "cm0o-5BkiT9W",
    "outputId": "97ea278c-abf8-4aa9-9486-e59d5d978e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 105\n",
      "328 106\n",
      "698 107\n",
      "380 108\n",
      "415 109\n",
      "177 110\n",
      "381 111\n",
      "809 112\n",
      "623 113\n",
      "858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name '/home/root1/DY/nezha-base-www' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed '/home/root1/DY/nezha-base-www' was a path or url but couldn't find tokenizer filesat this path or url.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "dic={}\n",
    "sep_list = ['[PAD]',\n",
    " '[unused1]',\n",
    " '[unused2]',\n",
    " '[unused3]',\n",
    " '[unused4]',\n",
    " '[unused5]',\n",
    " '[unused6]',\n",
    " '[unused7]',\n",
    " '[unused8]',\n",
    " '[unused9]',\n",
    " '[unused10]',\n",
    " '[unused11]',\n",
    " '[unused12]',\n",
    " '[unused13]',\n",
    " '[unused14]',\n",
    " '[unused15]',\n",
    " '[unused16]',\n",
    " '[unused17]',\n",
    " '[unused18]',\n",
    " '[unused19]',\n",
    " '[unused20]',\n",
    " '[unused21]',\n",
    " '[unused22]',\n",
    " '[unused23]',\n",
    " '[unused24]',\n",
    " '[unused25]',\n",
    " '[unused26]',\n",
    " '[unused27]',\n",
    " '[unused28]',\n",
    " '[unused29]',\n",
    " '[unused30]',\n",
    " '[unused31]',\n",
    " '[unused32]',\n",
    " '[unused33]',\n",
    " '[unused34]',\n",
    " '[unused35]',\n",
    " '[unused36]',\n",
    " '[unused37]',\n",
    " '[unused38]',\n",
    " '[unused39]',\n",
    " '[unused40]',\n",
    " '[unused41]',\n",
    " '[unused42]',\n",
    " '[unused43]',\n",
    " '[unused44]',\n",
    " '[unused45]',\n",
    " '[unused46]',\n",
    " '[unused47]',\n",
    " '[unused48]',\n",
    " '[unused49]',\n",
    " '[unused50]',\n",
    " '[unused51]',\n",
    " '[unused52]',\n",
    " '[unused53]',\n",
    " '[unused54]',\n",
    " '[unused55]',\n",
    " '[unused56]',\n",
    " '[unused57]',\n",
    " '[unused58]',\n",
    " '[unused59]',\n",
    " '[unused60]',\n",
    " '[unused61]',\n",
    " '[unused62]',\n",
    " '[unused63]',\n",
    " '[unused64]',\n",
    " '[unused65]',\n",
    " '[unused66]',\n",
    " '[unused67]',\n",
    " '[unused68]',\n",
    " '[unused69]',\n",
    " '[unused70]',\n",
    " '[unused71]',\n",
    " '[unused72]',\n",
    " '[unused73]',\n",
    " '[unused74]',\n",
    " '[unused75]',\n",
    " '[unused76]',\n",
    " '[unused77]',\n",
    " '[unused78]',\n",
    " '[unused79]',\n",
    " '[unused80]',\n",
    " '[unused81]',\n",
    " '[unused82]',\n",
    " '[unused83]',\n",
    " '[unused84]',\n",
    " '[unused85]',\n",
    " '[unused86]',\n",
    " '[unused87]',\n",
    " '[unused88]',\n",
    " '[unused89]',\n",
    " '[unused90]',\n",
    " '[unused91]',\n",
    " '[unused92]',\n",
    " '[unused93]',\n",
    " '[unused94]',\n",
    " '[unused95]',\n",
    " '[unused96]',\n",
    " '[unused97]',\n",
    " '[unused98]',\n",
    " '[unused99]',\n",
    " '[UNK]',\n",
    " '[CLS]',\n",
    " '[SEP]',\n",
    " '[MASK]',\n",
    " '<S>']\n",
    "\n",
    "\n",
    "for idx,token in enumerate(sep_list):\n",
    "     dic[token]= idx\n",
    "\n",
    "\n",
    "\n",
    "conter=Counter()\n",
    "\n",
    "with open(\"all_data.txt\",'r') as f:\n",
    "    text = f.readlines()\n",
    "    for idx,txt in enumerate(text):\n",
    "        # if idx>100:\n",
    "        #     break\n",
    "        for char in txt.split():\n",
    "            conter[char]+=1\n",
    "\n",
    "most_common=conter.most_common(100000) \n",
    "\n",
    "cont=0\n",
    "for idx,x in enumerate(most_common):\n",
    "    if x[1]>0:\n",
    "        dic[x[0]]=len(dic)\n",
    "    cont+=1\n",
    "    if cont<10:\n",
    "        print(x[0],dic[x[0]])\n",
    "print(cont)\n",
    "\n",
    "\n",
    "# BERTè¯é¢‘\n",
    "import json\n",
    "from pytorch_transformers import BertTokenizer\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/home/root1/DY/nezha-base-www\"\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH )\n",
    "\n",
    "\n",
    "dic = sorted(dic.items(), key=lambda x: x[1], reverse=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:34:01.270057Z",
     "start_time": "2021-03-27T05:33:41.422702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 105\n",
      "328 106\n",
      "698 107\n",
      "380 108\n",
      "415 109\n",
      "177 110\n",
      "381 111\n",
      "809 112\n",
      "623 113\n",
      "858\n",
      "963\n",
      "1286\n",
      "963\n",
      "323\n",
      "[PAD]\n",
      "[unused1]\n",
      "[unused2]\n",
      "[unused3]\n",
      "[unused4]\n",
      "[unused5]\n",
      "[unused6]\n",
      "[unused7]\n",
      "[unused8]\n",
      "[unused9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at NEZHA_BASE_PRETRAIN_100epoch were not used when initializing NeZhaForMaskedLM: ['bert.word_embedding.weight']\n",
      "- This IS expected if you are initializing NeZhaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/root1/anaconda3/lib/python3.7/site-packages/transformers-4.5.0.dev0-py3.7.egg/transformers/data/datasets/language_modeling.py:128: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "dic={}\n",
    "sep_list = ['[PAD]',\n",
    " '[unused1]',\n",
    " '[unused2]',\n",
    " '[unused3]',\n",
    " '[unused4]',\n",
    " '[unused5]',\n",
    " '[unused6]',\n",
    " '[unused7]',\n",
    " '[unused8]',\n",
    " '[unused9]',\n",
    " '[unused10]',\n",
    " '[unused11]',\n",
    " '[unused12]',\n",
    " '[unused13]',\n",
    " '[unused14]',\n",
    " '[unused15]',\n",
    " '[unused16]',\n",
    " '[unused17]',\n",
    " '[unused18]',\n",
    " '[unused19]',\n",
    " '[unused20]',\n",
    " '[unused21]',\n",
    " '[unused22]',\n",
    " '[unused23]',\n",
    " '[unused24]',\n",
    " '[unused25]',\n",
    " '[unused26]',\n",
    " '[unused27]',\n",
    " '[unused28]',\n",
    " '[unused29]',\n",
    " '[unused30]',\n",
    " '[unused31]',\n",
    " '[unused32]',\n",
    " '[unused33]',\n",
    " '[unused34]',\n",
    " '[unused35]',\n",
    " '[unused36]',\n",
    " '[unused37]',\n",
    " '[unused38]',\n",
    " '[unused39]',\n",
    " '[unused40]',\n",
    " '[unused41]',\n",
    " '[unused42]',\n",
    " '[unused43]',\n",
    " '[unused44]',\n",
    " '[unused45]',\n",
    " '[unused46]',\n",
    " '[unused47]',\n",
    " '[unused48]',\n",
    " '[unused49]',\n",
    " '[unused50]',\n",
    " '[unused51]',\n",
    " '[unused52]',\n",
    " '[unused53]',\n",
    " '[unused54]',\n",
    " '[unused55]',\n",
    " '[unused56]',\n",
    " '[unused57]',\n",
    " '[unused58]',\n",
    " '[unused59]',\n",
    " '[unused60]',\n",
    " '[unused61]',\n",
    " '[unused62]',\n",
    " '[unused63]',\n",
    " '[unused64]',\n",
    " '[unused65]',\n",
    " '[unused66]',\n",
    " '[unused67]',\n",
    " '[unused68]',\n",
    " '[unused69]',\n",
    " '[unused70]',\n",
    " '[unused71]',\n",
    " '[unused72]',\n",
    " '[unused73]',\n",
    " '[unused74]',\n",
    " '[unused75]',\n",
    " '[unused76]',\n",
    " '[unused77]',\n",
    " '[unused78]',\n",
    " '[unused79]',\n",
    " '[unused80]',\n",
    " '[unused81]',\n",
    " '[unused82]',\n",
    " '[unused83]',\n",
    " '[unused84]',\n",
    " '[unused85]',\n",
    " '[unused86]',\n",
    " '[unused87]',\n",
    " '[unused88]',\n",
    " '[unused89]',\n",
    " '[unused90]',\n",
    " '[unused91]',\n",
    " '[unused92]',\n",
    " '[unused93]',\n",
    " '[unused94]',\n",
    " '[unused95]',\n",
    " '[unused96]',\n",
    " '[unused97]',\n",
    " '[unused98]',\n",
    " '[unused99]',\n",
    " '[UNK]',\n",
    " '[CLS]',\n",
    " '[SEP]',\n",
    " '[MASK]',\n",
    " '<S>']\n",
    "\n",
    "\n",
    "for idx,token in enumerate(sep_list):\n",
    "     dic[token]= idx\n",
    "\n",
    "# #æ·»åŠ  ä¿è¯è¯è¡¨å¤§å°å’Œbertä¸€æ ·å¤§ è€Œå·²\n",
    "# for i in range(20706,21128):\n",
    "#     dic[str(i]=i\n",
    "# print(len(dic))\n",
    "\n",
    "\n",
    "conter=Counter()\n",
    "\n",
    "with open(\"all_data.txt\",'r') as f:\n",
    "    text = f.readlines()\n",
    "    for idx,txt in enumerate(text):\n",
    "        # if idx>100:\n",
    "        #     break\n",
    "        for char in txt.split():\n",
    "            conter[char]+=1\n",
    "\n",
    "most_common=conter.most_common(1000000) \n",
    "\n",
    "cont=0\n",
    "for idx,x in enumerate(most_common):\n",
    "    if x[1]>0:\n",
    "        dic[x[0]]=len(dic)\n",
    "    cont+=1\n",
    "    if cont<10:\n",
    "        print(x[0],dic[x[0]])\n",
    "print(cont)\n",
    "\n",
    "\n",
    "import json \n",
    "\n",
    "try:\n",
    "    os.mkdir(\"bert_token\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dic = sorted(dic.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "print(len(dic))\n",
    "\n",
    "# BERTè¯é¢‘\n",
    "import json\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_PATH = 'NEZHA_BASE_PRETRAIN_100epoch'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(tokenizer.vocab))\n",
    "print(len(dic))\n",
    "diff = len(tokenizer.vocab)-len(dic)\n",
    "print(diff)\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"bert_token\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "with open(\"bert_token/vocab.txt\",'w') as f:\n",
    "    for idx,key in enumerate(dic):\n",
    "        f.write(key[0]+u\"\\n\")\n",
    "        if idx<10:\n",
    "            print(key[0])\n",
    "        \n",
    "    for i in range(422):\n",
    "        \n",
    "        f.write(\"[unused%d]\\n\"%i)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert_token')\n",
    "\n",
    "from transformers import BertConfig\n",
    "from configuration_nezha import NeZhaConfig\n",
    "from modeling_nezha import NeZhaForMaskedLM\n",
    "\n",
    "\n",
    "BertConfig = NeZhaConfig.from_pretrained(MODEL_PATH)\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "    \n",
    "\n",
    "model = NeZhaForMaskedLM.from_pretrained(MODEL_PATH)\n",
    "# model.bert.word_embedding=torch.nn.Embedding(len(tokenizer.vocab),768) \n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./all_data.txt\",\n",
    "    block_size=64,\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from  transformers.file_utils import PaddingStrategy\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding, PreTrainedTokenizerBase\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForLanguageModeling:\n",
    "    \"\"\"\n",
    "    Data collator used for language modeling. Inputs are dynamically padded to the maximum length of a batch if they\n",
    "    are not all of the same length.\n",
    "\n",
    "    Args:\n",
    "        tokenizer (:class:`~transformers.PreTrainedTokenizer` or :class:`~transformers.PreTrainedTokenizerFast`):\n",
    "            The tokenizer used for encoding the data.\n",
    "        mlm (:obj:`bool`, `optional`, defaults to :obj:`True`):\n",
    "            Whether or not to use masked language modeling. If set to :obj:`False`, the labels are the same as the\n",
    "            inputs with the padding tokens ignored (by setting them to -100). Otherwise, the labels are -100 for\n",
    "            non-masked tokens and the value to predict for the masked token.\n",
    "        mlm_probability (:obj:`float`, `optional`, defaults to 0.15):\n",
    "            The probability with which to (randomly) mask tokens in the input, when :obj:`mlm` is set to :obj:`True`.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For best performance, this data collator should be used with a dataset having items that are dictionaries or\n",
    "        BatchEncoding, with the :obj:`\"special_tokens_mask\"` key, as returned by a\n",
    "        :class:`~transformers.PreTrainedTokenizer` or a :class:`~transformers.PreTrainedTokenizerFast` with the\n",
    "        argument :obj:`return_special_tokens_mask=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    mlm: bool = True\n",
    "    mlm_probability: float = 0.15\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.mlm and self.tokenizer.mask_token is None:\n",
    "            raise ValueError(\n",
    "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. \"\n",
    "                \"You should pass `mlm=False` to train on causal language modeling instead.\"\n",
    "            )\n",
    "\n",
    "    def __call__(\n",
    "        self, examples: List[Union[List[int], torch.Tensor, Dict[str, torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # Handle dict or lists with proper padding and conversion to tensor.\n",
    "        if isinstance(examples[0], (dict, BatchEncoding)):\n",
    "            batch = self.tokenizer.pad(examples, return_tensors=\"pt\")\n",
    "        else:\n",
    "            batch = {\"input_ids\": _collate_batch(examples, self.tokenizer)}\n",
    "\n",
    "        # If special token mask has been preprocessed, pop it from the dict.\n",
    "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
    "        if self.mlm:\n",
    "            batch[\"input_ids\"], batch[\"labels\"] = self.mask_tokens(\n",
    "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
    "            )\n",
    "        else:\n",
    "            labels = batch[\"input_ids\"].clone()\n",
    "            if self.tokenizer.pad_token_id is not None:\n",
    "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "            batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "    def mask_tokens(\n",
    "        self, inputs: torch.Tensor, special_tokens_mask: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "        \"\"\"\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
    "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
    "        if special_tokens_mask is None:\n",
    "            special_tokens_mask = [\n",
    "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "            ]\n",
    "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            special_tokens_mask = special_tokens_mask.bool()\n",
    "\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForWholeWordMask(DataCollatorForLanguageModeling):\n",
    "    \"\"\"\n",
    "    Data collator used for language modeling.\n",
    "\n",
    "    - collates batches of tensors, honoring their tokenizer's pad_token\n",
    "    - preprocesses batches for masked language modeling\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self, examples: List[Union[List[int], torch.Tensor, Dict[str, torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        if isinstance(examples[0], (dict, BatchEncoding)):\n",
    "            input_ids = [e[\"input_ids\"] for e in examples]\n",
    "        else:\n",
    "            input_ids = examples\n",
    "            examples = [{\"input_ids\": e} for e in examples]\n",
    "\n",
    "        batch_input = _collate_batch(input_ids, self.tokenizer)\n",
    "\n",
    "        mask_labels = []\n",
    "        for e in examples:\n",
    "            ref_tokens = []\n",
    "            for id in tolist(e[\"input_ids\"]):\n",
    "                token = self.tokenizer._convert_id_to_token(id)\n",
    "                ref_tokens.append(token)\n",
    "\n",
    "            # For Chinese tokens, we need extra inf to mark sub-word, e.g [å–œ,æ¬¢]-> [å–œï¼Œ##æ¬¢]\n",
    "            if \"chinese_ref\" in e:\n",
    "                ref_pos = tolist(e[\"chinese_ref\"])\n",
    "                len_seq = len(e[\"input_ids\"])\n",
    "                for i in range(len_seq):\n",
    "                    if i in ref_pos:\n",
    "                        ref_tokens[i] = \"##\" + ref_tokens[i]\n",
    "            mask_labels.append(self._whole_word_mask(ref_tokens))\n",
    "        batch_mask = _collate_batch(mask_labels, self.tokenizer)\n",
    "        inputs, labels = self.mask_tokens(batch_input, batch_mask)\n",
    "        return {\"input_ids\": inputs, \"labels\": labels}\n",
    "\n",
    "    def _whole_word_mask(self, input_tokens: List[str], max_predictions=512):\n",
    "        \"\"\"\n",
    "        Get 0/1 labels for masked tokens with whole word mask proxy\n",
    "        \"\"\"\n",
    "\n",
    "        cand_indexes = []\n",
    "        for (i, token) in enumerate(input_tokens):\n",
    "            if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "                continue\n",
    "\n",
    "            if len(cand_indexes) >= 1 and token.startswith(\"##\"):\n",
    "                cand_indexes[-1].append(i)\n",
    "            else:\n",
    "                cand_indexes.append([i])\n",
    "\n",
    "        random.shuffle(cand_indexes)\n",
    "        num_to_predict = min(max_predictions, max(1, int(round(len(input_tokens) * self.mlm_probability))))\n",
    "        masked_lms = []\n",
    "        covered_indexes = set()\n",
    "        for index_set in cand_indexes:\n",
    "            if len(masked_lms) >= num_to_predict:\n",
    "                break\n",
    "            # If adding a whole-word mask would exceed the maximum number of\n",
    "            # predictions, then just skip this candidate.\n",
    "            if len(masked_lms) + len(index_set) > num_to_predict:\n",
    "                continue\n",
    "            is_any_index_covered = False\n",
    "            for index in index_set:\n",
    "                if index in covered_indexes:\n",
    "                    is_any_index_covered = True\n",
    "                    break\n",
    "            if is_any_index_covered:\n",
    "                continue\n",
    "            for index in index_set:\n",
    "                covered_indexes.add(index)\n",
    "                masked_lms.append(index)\n",
    "\n",
    "        assert len(covered_indexes) == len(masked_lms)\n",
    "        mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\n",
    "        return mask_labels\n",
    "\n",
    "    def mask_tokens(self, inputs: torch.Tensor, mask_labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set\n",
    "        'mask_labels' means we use whole word mask (wwm), we directly mask idxs according to it's ref.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.tokenizer.mask_token is None:\n",
    "            raise ValueError(\n",
    "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\n",
    "            )\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "\n",
    "        probability_matrix = mask_labels\n",
    "\n",
    "        special_tokens_mask = [\n",
    "            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "        ]\n",
    "        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "        if self.tokenizer._pad_token is not None:\n",
    "            padding_mask = labels.eq(self.tokenizer.pad_token_id)\n",
    "            probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "\n",
    "        masked_indices = probability_matrix.bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:34:05.392575Z",
     "start_time": "2021-03-27T05:34:01.271842Z"
    },
    "id": "LSjrsRM321w9"
   },
   "outputs": [],
   "source": [
    " \n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./NEZHA_BASE_PRETRAIN_200epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=100,\n",
    "    per_gpu_train_batch_size=220,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    warmup_ratio=0.1\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-27T05:33:39.595Z"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1614765383143,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "b92c08nCujoH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3919' max='11900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3919/11900 33:45 < 1:08:47, 1.93 it/s, Epoch 32.92/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMoFPrnPSCnF8qzSzxWhs3n",
   "collapsed_sections": [],
   "name": "run_lm_pretraining_V2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
