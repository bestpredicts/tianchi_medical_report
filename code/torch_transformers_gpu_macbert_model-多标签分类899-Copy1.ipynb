{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:35.514764Z",
     "start_time": "2021-03-20T22:50:35.390649Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11830,
     "status": "ok",
     "timestamp": 1614770513449,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "O7WFLSg4DPma",
    "outputId": "76c70351-b51f-436e-d398-da17cceb9fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            251           8         129           0         113         241\r\n",
      "Swap:             1           0           1\r\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:35.522759Z",
     "start_time": "2021-03-20T22:50:35.519009Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19379,
     "status": "ok",
     "timestamp": 1614770521007,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3SjuHYnRDkWK",
    "outputId": "9443626d-a88c-49f7-8391-9cd5766d1017"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install transformers==2.5.0 -q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:36.140054Z",
     "start_time": "2021-03-20T22:50:35.524868Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19372,
     "status": "ok",
     "timestamp": 1614770521008,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "N7G6OGVfgvbt",
    "outputId": "23889a4a-3654-4474-b87e-1ede6897138c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 20 18:50:35 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  PH402 SKU 200       On   | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   58C    P0    43W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  PH402 SKU 200       On   | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    38W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  PH402 SKU 200       On   | 00000000:21:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    38W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  PH402 SKU 200       On   | 00000000:22:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    36W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  PH402 SKU 200       On   | 00000000:25:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    38W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  PH402 SKU 200       On   | 00000000:26:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    36W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  PH402 SKU 200       On   | 00000000:29:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    42W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  PH402 SKU 200       On   | 00000000:2A:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    38W / 140W |      6MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 3090    On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8    29W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 3090    On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 64%   63C    P2   302W / 350W |  20909MiB / 24268MiB |     34%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|  10  GeForce RTX 3090    On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8    23W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|  11  GeForce RTX 3090    On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   35C    P8    20W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    8   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    9   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    9   N/A  N/A     56449      C   ...oot1/anaconda3/bin/python    20901MiB |\n",
      "|   10   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|   11   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:36.148339Z",
     "start_time": "2021-03-20T22:50:36.144608Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39911,
     "status": "ok",
     "timestamp": 1614770541554,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "MmMivBRyDbtO",
    "outputId": "35305dcd-c1d0-454c-a173-e8042a4efc30"
   },
   "outputs": [],
   "source": [
    "#  #colab setting \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Competitions/医学影像报告异常检测/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.023492Z",
     "start_time": "2021-03-20T22:50:36.150019Z"
    },
    "executionInfo": {
     "elapsed": 54243,
     "status": "ok",
     "timestamp": 1614770555888,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "9yok51vCDoWl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.027009Z",
     "start_time": "2021-03-20T22:50:39.024999Z"
    },
    "executionInfo": {
     "elapsed": 54249,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "bQxQDR630SCm"
   },
   "outputs": [],
   "source": [
    "# !mkdir chinese-macbert-base\n",
    "\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json  -P  chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/added_tokens.json  -P   chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/pytorch_model.bin  -P  chinese-macbert-base/\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/special_tokens_map.json    -P chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer_config.json  -P  chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/vocab.txt -P chinese-macbert-base/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.211511Z",
     "start_time": "2021-03-20T22:50:39.028311Z"
    },
    "executionInfo": {
     "elapsed": 54246,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "VpFla5NVPayv"
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/track1_round1_train_20210222.csv\"\n",
    "test_path = \"../input/track1_round1_testA_20210222.csv\"\n",
    "train_df = pd.read_csv(train_path,sep=',',header=None)\n",
    "test_df = pd.read_csv(test_path,sep=',',header=None)\n",
    "\n",
    "train_df[1]=train_df[1].apply(lambda x:x[1:-1])\n",
    "train_df[2]=train_df[2].apply(lambda x:x[1:])\n",
    "\n",
    "test_df[1] = test_df[1].apply(lambda x:x[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.222520Z",
     "start_time": "2021-03-20T22:50:39.213695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "train_df.drop_duplicates(subset=[1,2],inplace=True)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.235757Z",
     "start_time": "2021-03-20T22:50:39.224047Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 54241,
     "status": "ok",
     "timestamp": 1614770555897,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "f1GQc7JFDz46",
    "outputId": "d7609944-c200-4d73-8906-f31cb906c7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6|</td>\n",
       "      <td>48 322 795 856 374 439 48 328 443 380 597 172 ...</td>\n",
       "      <td>4 11 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8|</td>\n",
       "      <td>852 328 471 585 117 458 399 607 693 380 522 62...</td>\n",
       "      <td>6 12 14 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9|</td>\n",
       "      <td>229 172 200 737 437 547 651 693 623 328 355 65...</td>\n",
       "      <td>1 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10|</td>\n",
       "      <td>852 328 305 461 71 413 728 479 122 693 697 382...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11|</td>\n",
       "      <td>697 582 439 48 328 755 355 582 617 265 478 162...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12|</td>\n",
       "      <td>380 315 177 415 145 755 693 698 521 177 415 38...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13|</td>\n",
       "      <td>811 328 538 845 832 122 693 788 579 460 787 95...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15|</td>\n",
       "      <td>111 328 213 661 542 265 363 145 424 490 693 66...</td>\n",
       "      <td>10 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16|</td>\n",
       "      <td>543 328 328 380 197 320 698 160 338 14 177 415...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17|</td>\n",
       "      <td>380 172 551 737 221 290 480 171 514 569 231 11...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18|</td>\n",
       "      <td>623 328 204 461 851 842 698 549 81 832 122 693...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19|</td>\n",
       "      <td>358 380 616 363 399 556 698 313 66 432 449 133...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1            2\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...           2 \n",
       "1    1|  48 328 538 382 809 623 434 355 382 382 363 145...             \n",
       "2    2|  623 656 293 851 636 842 698 493 338 266 369 69...          15 \n",
       "3    3|  48 328 380 259 439 107 380 265 172 470 290 693...             \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...          16 \n",
       "5    5|  80 328 328 54 172 439 741 380 172 842 698 177 ...          15 \n",
       "6    6|  48 322 795 856 374 439 48 328 443 380 597 172 ...     4 11 15 \n",
       "7    7|  623 328 659 486 582 162 711 289 606 405 809 78...             \n",
       "8    8|  852 328 471 585 117 458 399 607 693 380 522 62...  6 12 14 15 \n",
       "9    9|  229 172 200 737 437 547 651 693 623 328 355 65...         1 3 \n",
       "10  10|  852 328 305 461 71 413 728 479 122 693 697 382...             \n",
       "11  11|  697 582 439 48 328 755 355 582 617 265 478 162...          15 \n",
       "12  12|  380 315 177 415 145 755 693 698 521 177 415 38...          14 \n",
       "13  13|  811 328 538 845 832 122 693 788 579 460 787 95...             \n",
       "14  14|  623 328 697 661 809 48 46 355 661 414 852 328 ...    0 1 8 10 \n",
       "15  15|  111 328 213 661 542 265 363 145 424 490 693 66...       10 15 \n",
       "16  16|  543 328 328 380 197 320 698 160 338 14 177 415...          15 \n",
       "17  17|  380 172 551 737 221 290 480 171 514 569 231 11...             \n",
       "18  18|  623 328 204 461 851 842 698 549 81 832 122 693...          16 \n",
       "19  19|  358 380 616 363 399 556 698 313 66 432 449 133...             "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.242151Z",
     "start_time": "2021-03-20T22:50:39.237020Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 54233,
     "status": "ok",
     "timestamp": 1614770555898,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "ESC_TLmo236c",
    "outputId": "c6dbcd8b-794b-49bc-a0fc-b4d7b8dfab44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1\n",
       "0  0|  852 328 697 538 142 355 582 800 728 4 647 169 ...\n",
       "1  1|  380 358 343 654 171 832 47 832 690 693 48 563 ...\n",
       "2  2|  751 335 834 582 717 583 585 693 623 328 107 38...\n",
       "3  3|  623 328 649 582 488 12 578 623 538 382 382 265...\n",
       "4  4|  83 293 398 797 382 363 145 424 693 698 800 691..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.245759Z",
     "start_time": "2021-03-20T22:50:39.243541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.252338Z",
     "start_time": "2021-03-20T22:50:39.247036Z"
    },
    "executionInfo": {
     "elapsed": 54231,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AP7PUpB6FjDo"
   },
   "outputs": [],
   "source": [
    "def data_aug(df):\n",
    "    \n",
    "    import random\n",
    "    df = df.copy()\n",
    "    df[2]=df[2].apply(lambda x:x.split())\n",
    "    new_df = df.copy()\n",
    "    m =  shuffle(df)\n",
    "    m.reset_index(drop=True,inplace=True)\n",
    "    new_df[0]=100000\n",
    "    new_df[1] = new_df[1]+m[1]\n",
    "    new_df[2] = new_df[2]+m[2]\n",
    "    new_df[2]=new_df[2].apply(lambda x:\" \".join(list(set(x))))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.287963Z",
     "start_time": "2021-03-20T22:50:39.253637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>8 0 7 5 2 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td>15 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>9 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100000</td>\n",
       "      <td>48 322 795 856 374 439 48 328 443 380 597 172 ...</td>\n",
       "      <td>15 2 4 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>852 328 471 585 117 458 399 607 693 380 522 62...</td>\n",
       "      <td>6 16 15 12 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>229 172 200 737 437 547 651 693 623 328 355 65...</td>\n",
       "      <td>4 15 5 3 12 11 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>852 328 305 461 71 413 728 479 122 693 697 382...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100000</td>\n",
       "      <td>697 582 439 48 328 755 355 582 617 265 478 162...</td>\n",
       "      <td>15 4 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>380 315 177 415 145 755 693 698 521 177 415 38...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100000</td>\n",
       "      <td>811 328 538 845 832 122 693 788 579 460 787 95...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>8 10 0 15 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100000</td>\n",
       "      <td>111 328 213 661 542 265 363 145 424 490 693 66...</td>\n",
       "      <td>15 10 0 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100000</td>\n",
       "      <td>543 328 328 380 197 320 698 160 338 14 177 415...</td>\n",
       "      <td>15 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100000</td>\n",
       "      <td>380 172 551 737 221 290 480 171 514 569 231 11...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100000</td>\n",
       "      <td>623 328 204 461 851 842 698 549 81 832 122 693...</td>\n",
       "      <td>13 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100000</td>\n",
       "      <td>358 380 616 363 399 556 698 313 66 432 449 133...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0   100000  623 328 538 382 399 400 478 842 698 137 492 26...   \n",
       "1   100000  48 328 538 382 809 623 434 355 382 382 363 145...   \n",
       "2   100000  623 656 293 851 636 842 698 493 338 266 369 69...   \n",
       "3   100000  48 328 380 259 439 107 380 265 172 470 290 693...   \n",
       "4   100000  623 328 399 698 493 338 266 14 177 415 511 647...   \n",
       "5   100000  80 328 328 54 172 439 741 380 172 842 698 177 ...   \n",
       "6   100000  48 322 795 856 374 439 48 328 443 380 597 172 ...   \n",
       "7   100000  623 328 659 486 582 162 711 289 606 405 809 78...   \n",
       "8   100000  852 328 471 585 117 458 399 607 693 380 522 62...   \n",
       "9   100000  229 172 200 737 437 547 651 693 623 328 355 65...   \n",
       "10  100000  852 328 305 461 71 413 728 479 122 693 697 382...   \n",
       "11  100000  697 582 439 48 328 755 355 582 617 265 478 162...   \n",
       "12  100000  380 315 177 415 145 755 693 698 521 177 415 38...   \n",
       "13  100000  811 328 538 845 832 122 693 788 579 460 787 95...   \n",
       "14  100000  623 328 697 661 809 48 46 355 661 414 852 328 ...   \n",
       "15  100000  111 328 213 661 542 265 363 145 424 490 693 66...   \n",
       "16  100000  543 328 328 380 197 320 698 160 338 14 177 415...   \n",
       "17  100000  380 172 551 737 221 290 480 171 514 569 231 11...   \n",
       "18  100000  623 328 204 461 851 842 698 549 81 832 122 693...   \n",
       "19  100000  358 380 616 363 399 556 698 313 66 432 449 133...   \n",
       "\n",
       "                   2  \n",
       "0        8 0 7 5 2 1  \n",
       "1                     \n",
       "2                 15  \n",
       "3              15 10  \n",
       "4               9 16  \n",
       "5               15 7  \n",
       "6          15 2 4 11  \n",
       "7                 14  \n",
       "8      6 16 15 12 14  \n",
       "9   4 15 5 3 12 11 1  \n",
       "10                10  \n",
       "11           15 4 11  \n",
       "12                14  \n",
       "13                    \n",
       "14       8 10 0 15 1  \n",
       "15         15 10 0 4  \n",
       "16             15 16  \n",
       "17                 9  \n",
       "18             13 16  \n",
       "19                16  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = data_aug(train_df)\n",
    "m.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ3gBoKgvOMd"
   },
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.293751Z",
     "start_time": "2021-03-20T22:50:39.289138Z"
    },
    "executionInfo": {
     "elapsed": 54229,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "01VWaoAiFsbE"
   },
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "\n",
    "import transformers\n",
    "\n",
    "class config:\n",
    "    DEVICE = \"cuda\"\n",
    "    MAX_LEN = 200\n",
    "    TRAIN_BATCH_SIZE = 30\n",
    "    VALID_BATCH_SIZE = 30\n",
    "    MODEL_PATH = \"model.bin\"\n",
    "    EPOCHS = 10\n",
    "    BERT_PATH = \"n_gram_mask_bert_v2\"\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "\n",
    "\n",
    "save_path = config.BERT_PATH+'_weight_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUcAWkrbpmWI"
   },
   "source": [
    "## SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.300164Z",
     "start_time": "2021-03-20T22:50:39.294868Z"
    },
    "executionInfo": {
     "elapsed": 54226,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "Erl9-n_upohh"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import torch  \n",
    "import numpy as np\n",
    "import os\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5Wra6TtssOb"
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.311300Z",
     "start_time": "2021-03-20T22:50:39.301532Z"
    },
    "executionInfo": {
     "elapsed": 54225,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "JteBD9p1oxxp"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self,text1,text2, target):\n",
    "        self.text1 = text1\n",
    "        self.text2 = text2\n",
    "        self.target = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_length = config.MAX_LEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text1)\n",
    "\n",
    "    def get_dumm(self,s):\n",
    "        # print(\"print s\",s)\n",
    "        # print(\"s split\",s.split(' '))\n",
    "\n",
    "        re=[0]*17\n",
    "        if s=='' or s==\" \":\n",
    "            return re\n",
    "        else:\n",
    "            tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "            for i in tmp:\n",
    "                re[i]=1\n",
    "        return re\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text1 = str(self.text1[item])\n",
    "        text1 = \" \".join(text1.split())\n",
    "        text2 = None\n",
    "        # text2 = str(self.text2[item])\n",
    "        # text2 = \" \".join(text2.split())\n",
    "\n",
    "        # inputs = self.tokenizer.encode_plus(\n",
    "        #     text1,\n",
    "        #     text2,\n",
    "        #     # add_special_tokens=True,\n",
    "        #     max_length=self.max_len,\n",
    "        #     pad_to_max_length=True,\n",
    "        #     truncation=True\n",
    "        # )\n",
    "\n",
    "        # ids = inputs[\"input_ids\"]\n",
    "        # mask = inputs[\"attention_mask\"]\n",
    "        # token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text1,\n",
    "            text2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length\n",
    "#             truncate_first_sequence=True  # We're truncating the first sequence in priority\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        mask_padding_with_zero=True\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        pad_on_left = False\n",
    "        pad_token=0\n",
    "        pad_token_segment_id=0\n",
    "\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] )* padding_length\n",
    "                                               \n",
    "        label = self.target[item]\n",
    "        # print(\"label\",label)\n",
    "        #print(label,[i for i in label])\n",
    "        label=self.get_dumm(label)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(label, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54222,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "hOZTjExbUVZP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.315159Z",
     "start_time": "2021-03-20T22:50:39.312468Z"
    },
    "executionInfo": {
     "elapsed": 54221,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AlmOklJ1JPb7"
   },
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel,BertModel\n",
    "# from transformers.modeling_roberta import RobertaModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSl04MfxtWup"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.324751Z",
     "start_time": "2021-03-20T22:50:39.316424Z"
    },
    "executionInfo": {
     "elapsed": 54219,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "CJQFASGKswVR"
   },
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBert(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        config.output_hidden_states = True\n",
    "        config.num_labels = 17\n",
    "\n",
    "        super(CustomBert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        n_weights = config.num_hidden_layers + 1+13\n",
    "        weights_init = torch.zeros(n_weights).float()\n",
    "        weights_init.data[:-1] = -3\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    "\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                ):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids\n",
    "                            )\n",
    "\n",
    "        hidden_layers = outputs[2]\n",
    "        \n",
    "        add_embeds = [torch.mean(layer,axis=1) for layer in hidden_layers]\n",
    "\n",
    "        cls_outputs = torch.stack([self.dropout(layer[:, 0, :]) for layer in hidden_layers]+add_embeds,\n",
    "                                  dim=2)\n",
    "        \n",
    "        cls_output = (torch.softmax(self.layer_weights, dim=0) * cls_outputs).sum(-1)\n",
    "\n",
    "        # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
    "        logits = torch.mean(torch.stack([\n",
    "            self.classifier(self.high_dropout(cls_output))\n",
    "            for _ in range(5)\n",
    "        ], dim=0), dim=0)\n",
    "\n",
    "        outputs = logits\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.331845Z",
     "start_time": "2021-03-20T22:50:39.325942Z"
    },
    "executionInfo": {
     "elapsed": 54217,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "DxTdZUYgwr57"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FGM():\n",
    "    \"\"\"\n",
    "    对抗训练方法类\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.5, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s5vuD5dtqRJ"
   },
   "source": [
    "## train units && eval units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.343703Z",
     "start_time": "2021-03-20T22:50:39.333264Z"
    },
    "executionInfo": {
     "elapsed": 54215,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "sW_BcT4ltgxX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    fgm = FGM(model)\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        fgm.attack() # 在embedding上添加对抗扰动\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "        loss_adv = loss_fn(outputs, targets)\n",
    "        # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "        loss_adv.backward() \n",
    "        # 恢复embedding参数\n",
    "        fgm.restore() \n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.347440Z",
     "start_time": "2021-03-20T22:50:39.344791Z"
    },
    "executionInfo": {
     "elapsed": 54214,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "H1UmKtbj1n-E"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "# def threshold_search(y_true, y_proba, plot=False):\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "#     thresholds = np.append(thresholds, 1.001) \n",
    "#     F = 2 / (1/precision + 1/recall)\n",
    "#     best_score = np.max(F)\n",
    "#     best_th = thresholds[np.argmax(F)]\n",
    "#     if plot:\n",
    "#         plt.plot(thresholds, F, '-b')\n",
    "#         plt.plot([best_th], [best_score], '*r')\n",
    "#         plt.show()\n",
    "#     search_result = {'threshold': best_th , 'f1': best_score}\n",
    "#     return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.351859Z",
     "start_time": "2021-03-20T22:50:39.348554Z"
    },
    "executionInfo": {
     "elapsed": 54213,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "2Y5yWlJ1JU8T"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df[2]=''\n",
    "test_dataset = BERTDataset(text1=test_df[1].values,text2=None,target=test_df[2].values)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:50:39.363312Z",
     "start_time": "2021-03-20T22:50:39.354465Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54207,
     "status": "ok",
     "timestamp": 1614770555905,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3o9ESVHNveHE",
    "outputId": "41172ca1-a855-49cb-eda9-08d5e15b0a5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': tensor([101, 118, 105, 134, 139, 249, 137, 126, 310, 190, 594, 295, 177, 300,\n",
      "        314, 186, 947, 174, 106, 118, 105, 134, 126, 112, 139, 678, 285, 413,\n",
      "        373, 190, 159, 251, 122, 164, 102,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'targets': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.094046Z",
     "start_time": "2021-03-20T22:50:39.364809Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "To_m5aPptg0s",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 1 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at n_gram_mask_bert_v2 were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at n_gram_mask_bert_v2 and are newly initialized: ['layer_weights', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 266/266 [01:35<00:00,  2.78it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.720056414604187, score is 0.9576437473297119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:36<00:00,  2.77it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6931259632110596, score is 0.9592278599739075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6842209696769714, score is 0.9597517251968384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6800771355628967, score is 0.959995448589325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6771162152290344, score is 0.9601696133613586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6756076216697693, score is 0.9602583646774292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6743636131286621, score is 0.9603315591812134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6734921336174011, score is 0.9603828191757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6728994846343994, score is 0.9604176878929138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6727234721183777, score is 0.96042799949646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:04<00:00, 16.67it/s]\n",
      "/home/root1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 2 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at n_gram_mask_bert_v2 were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at n_gram_mask_bert_v2 and are newly initialized: ['layer_weights', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 266/266 [01:36<00:00,  2.75it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7223297953605652, score is 0.9575099945068359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:37<00:00,  2.73it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.692114531993866, score is 0.9592874050140381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.682935893535614, score is 0.9598273038864136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:35<00:00,  2.77it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6788407564163208, score is 0.9600681662559509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:35<00:00,  2.77it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6760948896408081, score is 0.9602296948432922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6742134690284729, score is 0.9603403806686401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.67302405834198, score is 0.9604103565216064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6721582412719727, score is 0.9604612588882446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6717308759689331, score is 0.9604864120483398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6716470122337341, score is 0.9604913592338562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:04<00:00, 16.56it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 3 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at n_gram_mask_bert_v2 were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at n_gram_mask_bert_v2 and are newly initialized: ['layer_weights', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 267/267 [01:38<00:00,  2.71it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7168459296226501, score is 0.9578325748443604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:39<00:00,  2.68it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6926255226135254, score is 0.9592573046684265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:42<00:00,  2.60it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6837910413742065, score is 0.9597769975662231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:36<00:00,  2.77it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6798204183578491, score is 0.9600105881690979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6774230003356934, score is 0.9601516127586365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6754963994026184, score is 0.9602649211883545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6742859482765198, score is 0.9603360891342163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:37<00:00,  2.75it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6735079884529114, score is 0.9603818655014038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6728799939155579, score is 0.9604188203811646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6727498769760132, score is 0.9604264497756958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:04<00:00, 16.47it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 4 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at n_gram_mask_bert_v2 were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at n_gram_mask_bert_v2 and are newly initialized: ['layer_weights', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 268/268 [01:39<00:00,  2.69it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7153664827346802, score is 0.9579195976257324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:36<00:00,  2.78it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.691474974155426, score is 0.9593250155448914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6831820011138916, score is 0.9598128199577332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6793248653411865, score is 0.9600397348403931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:37<00:00,  2.75it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6774373054504395, score is 0.9601507186889648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:36<00:00,  2.78it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6756608486175537, score is 0.9602552652359009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6742358207702637, score is 0.9603390693664551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6734249591827393, score is 0.9603867530822754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:44<00:00,  2.56it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.672967255115509, score is 0.9604136943817139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:44<00:00,  2.56it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6728990077972412, score is 0.9604176878929138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:04<00:00, 16.40it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 5 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at n_gram_mask_bert_v2 were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at n_gram_mask_bert_v2 and are newly initialized: ['layer_weights', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 269/269 [01:39<00:00,  2.71it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7204191088676453, score is 0.9576224088668823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:39<00:00,  2.71it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6930490732192993, score is 0.9592323899269104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:44<00:00,  2.56it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6842923760414124, score is 0.9597474932670593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.67it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6798800230026245, score is 0.9600070714950562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.67it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6765338778495789, score is 0.9602038860321045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6751380562782288, score is 0.960286021232605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.67it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6743007302284241, score is 0.9603352546691895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6728211641311646, score is 0.9604222774505615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6726914644241333, score is 0.9604299068450928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:03<00:00, 16.61it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,GroupKFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score , recall_score\t, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold,GroupKFold\n",
    "# gkf =  GroupKFold(n_splits=5)\n",
    "# groups_by_text_id_list = train['qid'].tolist()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=4590, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "oof_df_list = []\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "oof_train_list = []\n",
    "pred = [] \n",
    "\n",
    "# score\n",
    "\n",
    "def ss_score(targets,outputs):\n",
    "    \n",
    "    targets = torch.tensor(targets,dtype=torch.float)\n",
    "    outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "    loss = nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "    score = 1- loss/17\n",
    "    return loss.cpu().detach().numpy(),score\n",
    "\n",
    "\n",
    "for idx,(trn_idx,val_idx) in enumerate(skf.split(train_df,train_df[2])):\n",
    "    \n",
    "\n",
    "#     if idx<1:\n",
    "#         continue\n",
    "    print(\"开始第 %d 折训练\"%(idx+1))\n",
    "    \n",
    "\n",
    "    \n",
    "    model_path = \"%s/bert_wwm_model_%d.bin\"%(save_path,idx)\n",
    "    config.MODEL_PATH = model_path\n",
    "    tr_df = train_df.iloc[trn_idx]\n",
    "    va_df = train_df.iloc[val_idx]\n",
    "    \n",
    "    tr_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #data aug\n",
    "    \n",
    "#     aug_tr_df = data_aug(tr_df)\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "    \n",
    "#     tr_df = pd.concat([tr_df,aug_tr_df])\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    train_dataset = BERTDataset(\n",
    "        text1=tr_df[1].tolist(),text2=None,target=tr_df[2].tolist()\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4,shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDataset(\n",
    "     text1= va_df[1].tolist(),text2=None,target=va_df[2].tolist()\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n",
    "\n",
    "    device = torch.device(config.DEVICE)\n",
    "    model = CustomBert.from_pretrained(config.BERT_PATH,num_labels=1)\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    num_train_steps = int(len(tr_df) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    warmup_steps = int(num_train_steps*0.1)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,num_warmup_steps=warmup_steps,num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    min_loss = 100000\n",
    "    best_score =0\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "#         loss= torch.nn.BCEWithLogitsLoss()(torch.tensor(outputs),torch.tensor(targets))\n",
    "        loss,score = ss_score(targets,outputs)\n",
    "\n",
    "        # result =  threshold_search(targets,outputs)\n",
    "        # thr = result['threshold']\n",
    "        # f1 = result['f1']\n",
    "        # outputs = (outputs>thr).astype(int)\n",
    "        # f1 = f1_score(targets,outputs)\n",
    "        # precision = precision_score(targets, outputs)\n",
    "        # recall =  recall_score(targets,outputs)\n",
    "\n",
    "        print(f\"loss = {loss}, score is {score}\")\n",
    "\n",
    "\n",
    "#         if loss<min_loss:\n",
    "#             torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "#             min_loss = loss\n",
    "\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(),config.MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load( config.MODEL_PATH))\n",
    "    outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "    va_df['prob'] = outputs\n",
    "    oof_train_list.append(va_df)\n",
    "\n",
    "    outputs, targets = eval_fn(test_data_loader, model, device)\n",
    "    pred.append(np.array(outputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.110108Z",
     "start_time": "2021-03-21T00:20:58.095907Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "TVCqxmfaHHro"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0073624164797365665, 0.009764820337295532, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0066406819969415665, 0.012338452972471714, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.006021423730999231, 0.00625133141875267, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0.003780707949772477, 0.0022696598898619413, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[0.9012470245361328, 0.9200030565261841, 0.138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1          2  \\\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...         2    \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...        16    \n",
       "5    5|  80 328 328 54 172 439 741 380 172 842 698 177 ...        15    \n",
       "7    7|  623 328 659 486 582 162 711 289 606 405 809 78...              \n",
       "14  14|  623 328 697 661 809 48 46 355 661 414 852 328 ...  0 1 8 10    \n",
       "\n",
       "                                                 prob  \n",
       "0   [0.0073624164797365665, 0.009764820337295532, ...  \n",
       "4   [0.0066406819969415665, 0.012338452972471714, ...  \n",
       "5   [0.006021423730999231, 0.00625133141875267, 0....  \n",
       "7   [0.003780707949772477, 0.0022696598898619413, ...  \n",
       "14  [0.9012470245361328, 0.9200030565261841, 0.138...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = pd.concat(oof_train_list)\n",
    "oof_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.190990Z",
     "start_time": "2021-03-21T00:20:58.111295Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "S1svWP3sJPmb"
   },
   "outputs": [],
   "source": [
    "sub = np.average(pred, axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.201434Z",
     "start_time": "2021-03-21T00:20:58.193320Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "xMYQOboMMx5a"
   },
   "outputs": [],
   "source": [
    "m = sub.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.218866Z",
     "start_time": "2021-03-21T00:20:58.202629Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "lNKLriwIL5YP"
   },
   "outputs": [],
   "source": [
    "def get_dumm(s):\n",
    "    re=[0]*17\n",
    "    if s=='' or s==\" \":\n",
    "        return re\n",
    "    else:\n",
    "        tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "        for i in tmp:\n",
    "            re[i]=1\n",
    "    return re\n",
    "\n",
    "oof_train['label'] = oof_train[2].apply(lambda x:get_dumm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:58.260486Z",
     "start_time": "2021-03-21T00:20:58.220050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0073624164797365665, 0.009764820337295532, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0066406819969415665, 0.012338452972471714, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.006021423730999231, 0.00625133141875267, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0.003780707949772477, 0.0022696598898619413, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[0.9012470245361328, 0.9200030565261841, 0.138...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21|</td>\n",
       "      <td>380 172 200 791 470 753 693 256 514 569 231 11...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0018210123525932431, 0.003105448791757226, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27|</td>\n",
       "      <td>852 328 501 355 360 265 478 162 498 289 169 40...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.006496835965663195, 0.008982159197330475, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31|</td>\n",
       "      <td>91 380 488 12 591 487 197 852 328 538 501 382 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0014628305798396468, 0.0017630878137424588,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35|</td>\n",
       "      <td>380 315 809 623 328 160 380 419 789 439 852 81...</td>\n",
       "      <td>6 12 14 15</td>\n",
       "      <td>[0.02823447249829769, 0.03760896250605583, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41|</td>\n",
       "      <td>48 718 328 419 571 769 256 100 809 328 380 172...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.034585777670145035, 0.02986907958984375, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48|</td>\n",
       "      <td>48 231 419 571 769 256 524 809 328 380 373 320...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.027813483029603958, 0.029243502765893936, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51|</td>\n",
       "      <td>852 328 3 697 483 582 582 717 382 363 397 834 ...</td>\n",
       "      <td>7 9</td>\n",
       "      <td>[0.023494675755500793, 0.00797018688172102, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59|</td>\n",
       "      <td>623 328 538 661 698 493 338 266 177 415 832 38...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.006149108987301588, 0.011302648112177849, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61|</td>\n",
       "      <td>852 328 383 538 661 22 698 338 266 521 177 415...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.00990294385701418, 0.0077509284019470215, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62|</td>\n",
       "      <td>328 22 290 380 398 851 728 636 851 636 70 628 ...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.03099634125828743, 0.032249096781015396, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69|</td>\n",
       "      <td>48 328 290 380 419 789 523 532 50 693 556 698 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.001440047170035541, 0.0019045041408389807, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72|</td>\n",
       "      <td>328 697 661 19 363 737 698 785 504 493 338 266...</td>\n",
       "      <td>0 7</td>\n",
       "      <td>[0.8989684581756592, 0.02898901142179966, 0.00...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75|</td>\n",
       "      <td>852 328 160 380 439 679 63 541 848 698 510 838...</td>\n",
       "      <td>13 14</td>\n",
       "      <td>[0.024697259068489075, 0.014124431647360325, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76|</td>\n",
       "      <td>623 164 305 204 204 399 698 641 794 779 437 17...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0015811108751222491, 0.0027407840825617313,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90|</td>\n",
       "      <td>725 471 453 162 684 289 462 405 788 177 232 23...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0012133561540395021, 0.002118887845426798, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91|</td>\n",
       "      <td>48 328 697 243 19 363 842 698 627 504 493 338 ...</td>\n",
       "      <td>0 7</td>\n",
       "      <td>[0.9516443610191345, 0.05709005519747734, 0.01...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97|</td>\n",
       "      <td>290 351 380 99 809 813 380 786 287 515 305 654...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0056503331288695335, 0.007839363068342209, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98|</td>\n",
       "      <td>623 328 380 834 809 343 809 362 840 556 698 42...</td>\n",
       "      <td>4 11</td>\n",
       "      <td>[0.01596214808523655, 0.014767366461455822, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101|</td>\n",
       "      <td>380 172 200 737 300 78 448 290 693 380 834 343...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.003974598366767168, 0.006092192139476538, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107|</td>\n",
       "      <td>623 328 697 69 698 33 735 382 327 514 381 693 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.010534129105508327, 0.0056863948702812195, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115|</td>\n",
       "      <td>48 328 328 380 172 320 380 19 363 399 352 494 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.00622712355107069, 0.006254027597606182, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116|</td>\n",
       "      <td>623 328 538 582 842 698 641 769 779 177 166 16...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.007794946897774935, 0.017553061246871948, 0...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120|</td>\n",
       "      <td>380 136 363 399 556 438 313 149 713 432 768 11...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.009751756675541401, 0.015822475776076317, 0...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124|</td>\n",
       "      <td>623 328 697 538 355 27 386 728 478 647 169 750...</td>\n",
       "      <td></td>\n",
       "      <td>[0.004562287591397762, 0.003774755634367466, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128|</td>\n",
       "      <td>48 328 697 355 766 809 623 328 538 661 265 470...</td>\n",
       "      <td>0 1 2 7 8</td>\n",
       "      <td>[0.9543319344520569, 0.9728000164031982, 0.915...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>9869|</td>\n",
       "      <td>623 328 538 582 439 81 661 374 842 698 78 638 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.017229264602065086, 0.01185424905270338, 0....</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>9871|</td>\n",
       "      <td>478 333 390 636 276 698 116 71 712 620 381 693...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0023045067209750414, 0.0023339930921792984,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>9882|</td>\n",
       "      <td>91 382 569 231 556 698 313 66 432 449 693 664 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.002071332186460495, 0.0022505426313728094, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>9883|</td>\n",
       "      <td>623 657 320 786 399 851 636 374 698 516 149 26...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.006626322399824858, 0.008924114517867565, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9895|</td>\n",
       "      <td>48 328 380 834 809 343 698 177 415 832 468 25 ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.00640856521204114, 0.007233656942844391, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900|</td>\n",
       "      <td>623 328 328 380 172 470 651 394 596 502 340 37...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0018049620557576418, 0.0020070213358849287,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>9905|</td>\n",
       "      <td>247 305 461 204 698 162 498 289 177 415 381</td>\n",
       "      <td></td>\n",
       "      <td>[0.0020793115254491568, 0.0020858601201325655,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>9908|</td>\n",
       "      <td>623 328 290 380 372 236 636 90 735 374 698 14 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.007794463075697422, 0.009489189833402634, 0...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9914</th>\n",
       "      <td>9914|</td>\n",
       "      <td>290 380 582 809 160 380 786 809 244 328 550 32...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.007128006312996149, 0.006584024056792259, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>9921|</td>\n",
       "      <td>91 380 769 12 591 423 487 693 623 79 328 380 2...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.004456941969692707, 0.007409438956528902, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>9923|</td>\n",
       "      <td>623 328 355 661 698 338 266 437 521 254 415 38...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.014676619321107864, 0.9151479005813599, 0.0...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>9924|</td>\n",
       "      <td>852 328 380 172 54 823 391 693 380 654 439 380...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0019426745129749179, 0.0019934694282710552,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>9925|</td>\n",
       "      <td>139 81 200 737 556 698 313 326 432 449 693 852...</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.004985215608030558, 0.004881452303379774, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>9929|</td>\n",
       "      <td>256 514 38 582 623 34 693 91 382 556 698 432 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.022301726043224335, 0.9288431406021118, 0.0...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>9930|</td>\n",
       "      <td>380 172 439 380 654 200 737 779 59 655 798 693...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.006554802879691124, 0.01906195655465126, 0....</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>9931|</td>\n",
       "      <td>48 328 733 777 204 549 728 832 131 693 623 328...</td>\n",
       "      <td>1 3</td>\n",
       "      <td>[0.0227990560233593, 0.8369438052177429, 0.016...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>9934|</td>\n",
       "      <td>623 727 697 538 382 397 455 693 411 204 439 62...</td>\n",
       "      <td></td>\n",
       "      <td>[0.002090367255732417, 0.00189387914724648, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9935|</td>\n",
       "      <td>162 498 289 169 405 693 623 328 357 661 822 33...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.015583692118525505, 0.8955259919166565, 0.0...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>9946|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 189 832 14 381 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.005684535019099712, 0.006190387066453695, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>9952|</td>\n",
       "      <td>48 673 545 784 856 374 439 379 328 717 172 320...</td>\n",
       "      <td>4 11 15</td>\n",
       "      <td>[0.016759909689426422, 0.017765581607818604, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>9953|</td>\n",
       "      <td>623 328 697 582 17 501 382 400 434 439 380 136...</td>\n",
       "      <td>0 3</td>\n",
       "      <td>[0.6636802554130554, 0.03876490518450737, 0.03...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>9957|</td>\n",
       "      <td>135 328 776 355 616 38 91 382 698 514 408 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.007941449992358685, 0.008131571114063263, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9964|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 177 415 381 644...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0059925164096057415, 0.006003549788147211, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>9965|</td>\n",
       "      <td>380 136 783 16 556 698 313 66 432 449 208 415 ...</td>\n",
       "      <td>6 13</td>\n",
       "      <td>[0.015614680014550686, 0.010516609996557236, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9972|</td>\n",
       "      <td>852 328 328 380 172 487 391 693 210 514 569 71...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0018719665240496397, 0.001898608054034412, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9975|</td>\n",
       "      <td>623 328 697 661 182 698 17 49 486 548 601 818 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9689434170722961, 0.08691457659006119, 0.01...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>9976|</td>\n",
       "      <td>852 328 647 461 755 549 170 549 728 832 122</td>\n",
       "      <td></td>\n",
       "      <td>[0.0022815545089542866, 0.0017592625226825476,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9983|</td>\n",
       "      <td>48 328 733 777 204 549 728 394 832 122 693 852...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.0062341210432350636, 0.0062971874140203, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9985|</td>\n",
       "      <td>623 328 697 204 809 623 328 357 471 672 328 45...</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.007813726551830769, 0.007169671822339296, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9988|</td>\n",
       "      <td>623 328 538 582 91 400 698 10 177 415 569 856 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.007077145390212536, 0.006866710260510445, 0...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1              2  \\\n",
       "0        0|  623 328 538 382 399 400 478 842 698 137 492 26...             2    \n",
       "4        4|  623 328 399 698 493 338 266 14 177 415 511 647...            16    \n",
       "5        5|  80 328 328 54 172 439 741 380 172 842 698 177 ...            15    \n",
       "7        7|  623 328 659 486 582 162 711 289 606 405 809 78...                  \n",
       "14      14|  623 328 697 661 809 48 46 355 661 414 852 328 ...      0 1 8 10    \n",
       "21      21|  380 172 200 791 470 753 693 256 514 569 231 11...                  \n",
       "27      27|  852 328 501 355 360 265 478 162 498 289 169 40...            15    \n",
       "31      31|  91 380 488 12 591 487 197 852 328 538 501 382 ...                  \n",
       "35      35|  380 315 809 623 328 160 380 419 789 439 852 81...    6 12 14 15    \n",
       "41      41|  48 718 328 419 571 769 256 100 809 328 380 172...  4 5 11 12 15    \n",
       "48      48|  48 231 419 571 769 256 524 809 328 380 373 320...  4 5 11 12 15    \n",
       "51      51|  852 328 3 697 483 582 582 717 382 363 397 834 ...           7 9    \n",
       "59      59|  623 328 538 661 698 493 338 266 177 415 832 38...            16    \n",
       "61      61|  852 328 383 538 661 22 698 338 266 521 177 415...             9    \n",
       "62      62|  328 22 290 380 398 851 728 636 851 636 70 628 ...  4 5 11 12 15    \n",
       "69      69|  48 328 290 380 419 789 523 532 50 693 556 698 ...                  \n",
       "72      72|  328 697 661 19 363 737 698 785 504 493 338 266...           0 7    \n",
       "75      75|  852 328 160 380 439 679 63 541 848 698 510 838...         13 14    \n",
       "76      76|  623 164 305 204 204 399 698 641 794 779 437 17...                  \n",
       "90      90|  725 471 453 162 684 289 462 405 788 177 232 23...                  \n",
       "91      91|  48 328 697 243 19 363 842 698 627 504 493 338 ...           0 7    \n",
       "97      97|  290 351 380 99 809 813 380 786 287 515 305 654...            16    \n",
       "98      98|  623 328 380 834 809 343 809 362 840 556 698 42...          4 11    \n",
       "101    101|  380 172 200 737 300 78 448 290 693 380 834 343...             9    \n",
       "107    107|  623 328 697 69 698 33 735 382 327 514 381 693 ...                  \n",
       "115    115|  48 328 328 380 172 320 380 19 363 399 352 494 ...            15    \n",
       "116    116|  623 328 538 582 842 698 641 769 779 177 166 16...             2    \n",
       "120    120|  380 136 363 399 556 438 313 149 713 432 768 11...             2    \n",
       "124    124|  623 328 697 538 355 27 386 728 478 647 169 750...                  \n",
       "128    128|  48 328 697 355 766 809 623 328 538 661 265 470...     0 1 2 7 8    \n",
       "...     ...                                                ...            ...   \n",
       "9869  9869|  623 328 538 582 439 81 661 374 842 698 78 638 ...             2    \n",
       "9871  9871|  478 333 390 636 276 698 116 71 712 620 381 693...                  \n",
       "9882  9882|  91 382 569 231 556 698 313 66 432 449 693 664 ...                  \n",
       "9883  9883|  623 657 320 786 399 851 636 374 698 516 149 26...            15    \n",
       "9895  9895|  48 328 380 834 809 343 698 177 415 832 468 25 ...            16    \n",
       "9900  9900|  623 328 328 380 172 470 651 394 596 502 340 37...                  \n",
       "9905  9905|       247 305 461 204 698 162 498 289 177 415 381                   \n",
       "9908  9908|  623 328 290 380 372 236 636 90 735 374 698 14 ...             3    \n",
       "9914  9914|  290 380 582 809 160 380 786 809 244 328 550 32...            16    \n",
       "9921  9921|  91 380 769 12 591 423 487 693 623 79 328 380 2...            15    \n",
       "9923  9923|  623 328 355 661 698 338 266 437 521 254 415 38...             1    \n",
       "9924  9924|  852 328 380 172 54 823 391 693 380 654 439 380...                  \n",
       "9925  9925|  139 81 200 737 556 698 313 326 432 449 693 852...            11    \n",
       "9929  9929|  256 514 38 582 623 34 693 91 382 556 698 432 4...             1    \n",
       "9930  9930|  380 172 439 380 654 200 737 779 59 655 798 693...             2    \n",
       "9931  9931|  48 328 733 777 204 549 728 832 131 693 623 328...           1 3    \n",
       "9934  9934|  623 727 697 538 382 397 455 693 411 204 439 62...                  \n",
       "9935  9935|  162 498 289 169 405 693 623 328 357 661 822 33...             1    \n",
       "9946  9946|  160 380 786 439 26 343 654 399 189 832 14 381 ...            15    \n",
       "9952  9952|  48 673 545 784 856 374 439 379 328 717 172 320...       4 11 15    \n",
       "9953  9953|  623 328 697 582 17 501 382 400 434 439 380 136...           0 3    \n",
       "9957  9957|  135 328 776 355 616 38 91 382 698 514 408 177 ...            15    \n",
       "9964  9964|  160 380 786 439 26 343 654 399 177 415 381 644...            15    \n",
       "9965  9965|  380 136 783 16 556 698 313 66 432 449 208 415 ...          6 13    \n",
       "9972  9972|  852 328 328 380 172 487 391 693 210 514 569 71...                  \n",
       "9975  9975|  623 328 697 661 182 698 17 49 486 548 601 818 ...             0    \n",
       "9976  9976|       852 328 647 461 755 549 170 549 728 832 122                   \n",
       "9983  9983|  48 328 733 777 204 549 728 394 832 122 693 852...             9    \n",
       "9985  9985|  623 328 697 204 809 623 328 357 471 672 328 45...            11    \n",
       "9988  9988|  623 328 538 582 91 400 698 10 177 415 569 856 ...             2    \n",
       "\n",
       "                                                   prob  \\\n",
       "0     [0.0073624164797365665, 0.009764820337295532, ...   \n",
       "4     [0.0066406819969415665, 0.012338452972471714, ...   \n",
       "5     [0.006021423730999231, 0.00625133141875267, 0....   \n",
       "7     [0.003780707949772477, 0.0022696598898619413, ...   \n",
       "14    [0.9012470245361328, 0.9200030565261841, 0.138...   \n",
       "21    [0.0018210123525932431, 0.003105448791757226, ...   \n",
       "27    [0.006496835965663195, 0.008982159197330475, 0...   \n",
       "31    [0.0014628305798396468, 0.0017630878137424588,...   \n",
       "35    [0.02823447249829769, 0.03760896250605583, 0.0...   \n",
       "41    [0.034585777670145035, 0.02986907958984375, 0....   \n",
       "48    [0.027813483029603958, 0.029243502765893936, 0...   \n",
       "51    [0.023494675755500793, 0.00797018688172102, 0....   \n",
       "59    [0.006149108987301588, 0.011302648112177849, 0...   \n",
       "61    [0.00990294385701418, 0.0077509284019470215, 0...   \n",
       "62    [0.03099634125828743, 0.032249096781015396, 0....   \n",
       "69    [0.001440047170035541, 0.0019045041408389807, ...   \n",
       "72    [0.8989684581756592, 0.02898901142179966, 0.00...   \n",
       "75    [0.024697259068489075, 0.014124431647360325, 0...   \n",
       "76    [0.0015811108751222491, 0.0027407840825617313,...   \n",
       "90    [0.0012133561540395021, 0.002118887845426798, ...   \n",
       "91    [0.9516443610191345, 0.05709005519747734, 0.01...   \n",
       "97    [0.0056503331288695335, 0.007839363068342209, ...   \n",
       "98    [0.01596214808523655, 0.014767366461455822, 0....   \n",
       "101   [0.003974598366767168, 0.006092192139476538, 0...   \n",
       "107   [0.010534129105508327, 0.0056863948702812195, ...   \n",
       "115   [0.00622712355107069, 0.006254027597606182, 0....   \n",
       "116   [0.007794946897774935, 0.017553061246871948, 0...   \n",
       "120   [0.009751756675541401, 0.015822475776076317, 0...   \n",
       "124   [0.004562287591397762, 0.003774755634367466, 0...   \n",
       "128   [0.9543319344520569, 0.9728000164031982, 0.915...   \n",
       "...                                                 ...   \n",
       "9869  [0.017229264602065086, 0.01185424905270338, 0....   \n",
       "9871  [0.0023045067209750414, 0.0023339930921792984,...   \n",
       "9882  [0.002071332186460495, 0.0022505426313728094, ...   \n",
       "9883  [0.006626322399824858, 0.008924114517867565, 0...   \n",
       "9895  [0.00640856521204114, 0.007233656942844391, 0....   \n",
       "9900  [0.0018049620557576418, 0.0020070213358849287,...   \n",
       "9905  [0.0020793115254491568, 0.0020858601201325655,...   \n",
       "9908  [0.007794463075697422, 0.009489189833402634, 0...   \n",
       "9914  [0.007128006312996149, 0.006584024056792259, 0...   \n",
       "9921  [0.004456941969692707, 0.007409438956528902, 0...   \n",
       "9923  [0.014676619321107864, 0.9151479005813599, 0.0...   \n",
       "9924  [0.0019426745129749179, 0.0019934694282710552,...   \n",
       "9925  [0.004985215608030558, 0.004881452303379774, 0...   \n",
       "9929  [0.022301726043224335, 0.9288431406021118, 0.0...   \n",
       "9930  [0.006554802879691124, 0.01906195655465126, 0....   \n",
       "9931  [0.0227990560233593, 0.8369438052177429, 0.016...   \n",
       "9934  [0.002090367255732417, 0.00189387914724648, 0....   \n",
       "9935  [0.015583692118525505, 0.8955259919166565, 0.0...   \n",
       "9946  [0.005684535019099712, 0.006190387066453695, 0...   \n",
       "9952  [0.016759909689426422, 0.017765581607818604, 0...   \n",
       "9953  [0.6636802554130554, 0.03876490518450737, 0.03...   \n",
       "9957  [0.007941449992358685, 0.008131571114063263, 0...   \n",
       "9964  [0.0059925164096057415, 0.006003549788147211, ...   \n",
       "9965  [0.015614680014550686, 0.010516609996557236, 0...   \n",
       "9972  [0.0018719665240496397, 0.001898608054034412, ...   \n",
       "9975  [0.9689434170722961, 0.08691457659006119, 0.01...   \n",
       "9976  [0.0022815545089542866, 0.0017592625226825476,...   \n",
       "9983  [0.0062341210432350636, 0.0062971874140203, 0....   \n",
       "9985  [0.007813726551830769, 0.007169671822339296, 0...   \n",
       "9988  [0.007077145390212536, 0.006866710260510445, 0...   \n",
       "\n",
       "                                                  label  \n",
       "0     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "14    [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n",
       "21    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "27    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "31    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "35    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n",
       "41    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "48    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "51    [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "59    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "61    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "62    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "69    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "72    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "75    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "76    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "90    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "91    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "97    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "98    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "101   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "107   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "115   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "120   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "124   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "128   [1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "9869  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9871  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9882  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9883  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9895  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9905  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9908  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9914  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9921  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9923  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9924  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9925  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9929  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9930  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9931  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9934  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9935  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9946  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9952  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9953  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9957  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9964  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9965  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "9972  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9975  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9976  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9983  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "9985  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9988  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:59.768912Z",
     "start_time": "2021-03-21T00:20:58.261652Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_train['score'] = oof_train.apply(lambda x:ss_score(x.label,x.prob)[1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:59.799664Z",
     "start_time": "2021-03-21T00:20:59.770541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96040595703125\n"
     ]
    }
   ],
   "source": [
    "oof_score = oof_train.score.mean()\n",
    "print(oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:59.810377Z",
     "start_time": "2021-03-21T00:20:59.800883Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "h7Mv4gKCDBfx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>[0.012090771738439799, 0.005923829087987542, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>[0.0017855744576081634, 0.002484714472666383, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>[0.007298107258975506, 0.007080304622650147, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>[0.01401490531861782, 0.00508544840849936, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>[0.00969548262655735, 0.01638804133981466, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1  \\\n",
       "0  0|  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1  1|  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2  2|  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3  3|  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4  4|  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "                                                   2  \n",
       "0  [0.012090771738439799, 0.005923829087987542, 0...  \n",
       "1  [0.0017855744576081634, 0.002484714472666383, ...  \n",
       "2  [0.007298107258975506, 0.007080304622650147, 0...  \n",
       "3  [0.01401490531861782, 0.00508544840849936, 0.0...  \n",
       "4  [0.00969548262655735, 0.01638804133981466, 0.0...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[2] = m\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:59.822413Z",
     "start_time": "2021-03-21T00:20:59.811593Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "IybR8dA8N1I4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>[0.012090771738439799, 0.005923829087987542, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>[0.0017855744576081634, 0.002484714472666383, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>[0.007298107258975506, 0.007080304622650147, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>[0.01401490531861782, 0.00508544840849936, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>[0.00969548262655735, 0.01638804133981466, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  0  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1  1  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2  2  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3  3  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4  4  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "                                                   2  \n",
       "0  [0.012090771738439799, 0.005923829087987542, 0...  \n",
       "1  [0.0017855744576081634, 0.002484714472666383, ...  \n",
       "2  [0.007298107258975506, 0.007080304622650147, 0...  \n",
       "3  [0.01401490531861782, 0.00508544840849936, 0.0...  \n",
       "4  [0.00969548262655735, 0.01638804133981466, 0.0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[0]=test_df[0].apply(lambda x:x[:-1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:20:59.866827Z",
     "start_time": "2021-03-21T00:20:59.823644Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "awVBkOVKPRNE"
   },
   "outputs": [],
   "source": [
    "sub_id=test_df[0].values\n",
    "pres_all = sub.tolist()\n",
    "str_w=''\n",
    "with open(f'{save_path}/submit_{oof_score}.csv','w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        pres_fold = pres_all[i]\n",
    "        pres_fold=[str(p) for p in pres_fold]\n",
    "        prob = \" \".join(pres_fold)\n",
    "        str_w+=sub_id[i]+'|'+','+'|'+prob+'\\n'\n",
    "    str_w=str_w.strip('\\n')\n",
    "    f.write(str_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T00:21:01.788698Z",
     "start_time": "2021-03-21T00:20:59.868052Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "mirMQlPPmHNI"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(f\"{save_path}/oof_test_{score}.csv\")\n",
    "oof_train.to_csv(f\"{save_path}/oof_train_{score}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BMxuk94uvEhw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_transformers_gpu_macbert_model-多标签分类v2.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
