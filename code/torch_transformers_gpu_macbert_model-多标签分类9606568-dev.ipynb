{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:43.905886Z",
     "start_time": "2021-03-27T02:17:43.902241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39911,
     "status": "ok",
     "timestamp": 1614770541554,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "MmMivBRyDbtO",
    "outputId": "35305dcd-c1d0-454c-a173-e8042a4efc30"
   },
   "outputs": [],
   "source": [
    "#  #colab setting \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Competitions/医学影像报告异常检测/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.280480Z",
     "start_time": "2021-03-27T02:17:43.909202Z"
    },
    "executionInfo": {
     "elapsed": 54243,
     "status": "ok",
     "timestamp": 1614770555888,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "9yok51vCDoWl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.327365Z",
     "start_time": "2021-03-27T02:17:46.282112Z"
    },
    "executionInfo": {
     "elapsed": 54246,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "VpFla5NVPayv"
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/track1_round1_train_20210222.csv\"\n",
    "test_path = \"../input/track1_round1_testA_20210222.csv\"\n",
    "train_df = pd.read_csv(train_path,sep=',',header=None)\n",
    "test_df = pd.read_csv(test_path,sep=',',header=None)\n",
    "\n",
    "train_df[1]=train_df[1].apply(lambda x:x[1:-1])\n",
    "train_df[2]=train_df[2].apply(lambda x:x[1:])\n",
    "\n",
    "test_df[1] = test_df[1].apply(lambda x:x[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.337223Z",
     "start_time": "2021-03-27T02:17:46.328729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "train_df.drop_duplicates(subset=[1,2],inplace=True)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.350345Z",
     "start_time": "2021-03-27T02:17:46.338457Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 54241,
     "status": "ok",
     "timestamp": 1614770555897,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "f1GQc7JFDz46",
    "outputId": "d7609944-c200-4d73-8906-f31cb906c7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6|</td>\n",
       "      <td>48 322 795 856 374 439 48 328 443 380 597 172 ...</td>\n",
       "      <td>4 11 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8|</td>\n",
       "      <td>852 328 471 585 117 458 399 607 693 380 522 62...</td>\n",
       "      <td>6 12 14 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9|</td>\n",
       "      <td>229 172 200 737 437 547 651 693 623 328 355 65...</td>\n",
       "      <td>1 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10|</td>\n",
       "      <td>852 328 305 461 71 413 728 479 122 693 697 382...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11|</td>\n",
       "      <td>697 582 439 48 328 755 355 582 617 265 478 162...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12|</td>\n",
       "      <td>380 315 177 415 145 755 693 698 521 177 415 38...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13|</td>\n",
       "      <td>811 328 538 845 832 122 693 788 579 460 787 95...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15|</td>\n",
       "      <td>111 328 213 661 542 265 363 145 424 490 693 66...</td>\n",
       "      <td>10 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16|</td>\n",
       "      <td>543 328 328 380 197 320 698 160 338 14 177 415...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17|</td>\n",
       "      <td>380 172 551 737 221 290 480 171 514 569 231 11...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18|</td>\n",
       "      <td>623 328 204 461 851 842 698 549 81 832 122 693...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19|</td>\n",
       "      <td>358 380 616 363 399 556 698 313 66 432 449 133...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text        label\n",
       "0     0|  623 328 538 382 399 400 478 842 698 137 492 26...           2 \n",
       "1     1|  48 328 538 382 809 623 434 355 382 382 363 145...             \n",
       "2     2|  623 656 293 851 636 842 698 493 338 266 369 69...          15 \n",
       "3     3|  48 328 380 259 439 107 380 265 172 470 290 693...             \n",
       "4     4|  623 328 399 698 493 338 266 14 177 415 511 647...          16 \n",
       "5     5|  80 328 328 54 172 439 741 380 172 842 698 177 ...          15 \n",
       "6     6|  48 322 795 856 374 439 48 328 443 380 597 172 ...     4 11 15 \n",
       "7     7|  623 328 659 486 582 162 711 289 606 405 809 78...             \n",
       "8     8|  852 328 471 585 117 458 399 607 693 380 522 62...  6 12 14 15 \n",
       "9     9|  229 172 200 737 437 547 651 693 623 328 355 65...         1 3 \n",
       "10   10|  852 328 305 461 71 413 728 479 122 693 697 382...             \n",
       "11   11|  697 582 439 48 328 755 355 582 617 265 478 162...          15 \n",
       "12   12|  380 315 177 415 145 755 693 698 521 177 415 38...          14 \n",
       "13   13|  811 328 538 845 832 122 693 788 579 460 787 95...             \n",
       "14   14|  623 328 697 661 809 48 46 355 661 414 852 328 ...    0 1 8 10 \n",
       "15   15|  111 328 213 661 542 265 363 145 424 490 693 66...       10 15 \n",
       "16   16|  543 328 328 380 197 320 698 160 338 14 177 415...          15 \n",
       "17   17|  380 172 551 737 221 290 480 171 514 569 231 11...             \n",
       "18   18|  623 328 204 461 851 842 698 549 81 832 122 693...          16 \n",
       "19   19|  358 380 616 363 399 556 698 313 66 432 449 133...             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns = ['index','text','label']\n",
    "\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.444789Z",
     "start_time": "2021-03-27T02:17:46.351672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text label  \\\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...    2    \n",
       "1    1|  48 328 538 382 809 623 434 355 382 382 363 145...         \n",
       "2    2|  623 656 293 851 636 842 698 493 338 266 369 69...   15    \n",
       "3    3|  48 328 380 259 439 107 380 265 172 470 290 693...         \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...   16    \n",
       "\n",
       "                                              label2  \n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dumm(s):\n",
    "    re=[0]*17\n",
    "    if s=='' or s==\" \":\n",
    "        return re\n",
    "    else:\n",
    "        tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "        for i in tmp:\n",
    "            re[i]=1\n",
    "    return re\n",
    "\n",
    "train_df['label2'] = train_df.label.apply(lambda x:get_dumm(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.505614Z",
     "start_time": "2021-03-27T02:17:46.446168Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(17):\n",
    "    train_df['label_onehot_%d'%(i+1)] = train_df.label2.apply(lambda x:x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.520409Z",
     "start_time": "2021-03-27T02:17:46.507396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>label_onehot_1</th>\n",
       "      <th>label_onehot_2</th>\n",
       "      <th>label_onehot_3</th>\n",
       "      <th>label_onehot_4</th>\n",
       "      <th>label_onehot_5</th>\n",
       "      <th>label_onehot_6</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_8</th>\n",
       "      <th>label_onehot_9</th>\n",
       "      <th>label_onehot_10</th>\n",
       "      <th>label_onehot_11</th>\n",
       "      <th>label_onehot_12</th>\n",
       "      <th>label_onehot_13</th>\n",
       "      <th>label_onehot_14</th>\n",
       "      <th>label_onehot_15</th>\n",
       "      <th>label_onehot_16</th>\n",
       "      <th>label_onehot_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text label  \\\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...    2    \n",
       "1    1|  48 328 538 382 809 623 434 355 382 382 363 145...         \n",
       "2    2|  623 656 293 851 636 842 698 493 338 266 369 69...   15    \n",
       "3    3|  48 328 380 259 439 107 380 265 172 470 290 693...         \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...   16    \n",
       "\n",
       "                                              label2  label_onehot_1  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "\n",
       "   label_onehot_2  label_onehot_3  label_onehot_4  label_onehot_5  \\\n",
       "0               0               1               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   label_onehot_6  ...  label_onehot_8  label_onehot_9  label_onehot_10  \\\n",
       "0               0  ...               0               0                0   \n",
       "1               0  ...               0               0                0   \n",
       "2               0  ...               0               0                0   \n",
       "3               0  ...               0               0                0   \n",
       "4               0  ...               0               0                0   \n",
       "\n",
       "   label_onehot_11  label_onehot_12  label_onehot_13  label_onehot_14  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   label_onehot_15  label_onehot_16  label_onehot_17  \n",
       "0                0                0                0  \n",
       "1                0                0                0  \n",
       "2                0                1                0  \n",
       "3                0                0                0  \n",
       "4                0                0                1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:46.527077Z",
     "start_time": "2021-03-27T02:17:46.521957Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 54233,
     "status": "ok",
     "timestamp": 1614770555898,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "ESC_TLmo236c",
    "outputId": "c6dbcd8b-794b-49bc-a0fc-b4d7b8dfab44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text\n",
       "0    0|  852 328 697 538 142 355 582 800 728 4 647 169 ...\n",
       "1    1|  380 358 343 654 171 832 47 832 690 693 48 563 ...\n",
       "2    2|  751 335 834 582 717 583 585 693 623 328 107 38...\n",
       "3    3|  623 328 649 582 488 12 578 623 538 382 382 265...\n",
       "4    4|  83 293 398 797 382 363 145 424 693 698 800 691..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns = ['index','text']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:54.968986Z",
     "start_time": "2021-03-27T02:17:46.528245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_onehot_1_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_min_fea</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>0.393008</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>4.122316</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.058020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167549</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>2.555291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>3.501624</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>6.358730</td>\n",
       "      <td>0.087905</td>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>2.725062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>0.124938</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>2.373818</td>\n",
       "      <td>0.131235</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199417</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>3.788926</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>0.241986</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>1.783205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.423272</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>8.067832</td>\n",
       "      <td>0.131398</td>\n",
       "      <td>0.338954</td>\n",
       "      <td>0.046332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203535</td>\n",
       "      <td>0.492278</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.069743</td>\n",
       "      <td>12.619198</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.152263</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>4.690812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>0.230356</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>5.039707</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176610</td>\n",
       "      <td>0.331435</td>\n",
       "      <td>0.054931</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>7.241030</td>\n",
       "      <td>0.078502</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>3.218583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text  \\\n",
       "0    0|  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1    1|  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2    2|  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3    3|  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4    4|  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_mean_fea  \\\n",
       "0                               0.124919   \n",
       "1                               0.112956   \n",
       "2                               0.124938   \n",
       "3                               0.130126   \n",
       "4                               0.122920   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_max_fea  label_onehot_1_word_ctr_list_min_fea  \\\n",
       "0                              0.393008                              0.054608   \n",
       "1                              0.197067                              0.079536   \n",
       "2                              0.224359                              0.062696   \n",
       "3                              0.423272                              0.052124   \n",
       "4                              0.230356                              0.045000   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_std_fea  label_onehot_1_word_ctr_list_sum_fea  \\\n",
       "0                              0.079149                              4.122316   \n",
       "1                              0.021437                              3.501624   \n",
       "2                              0.039191                              2.373818   \n",
       "3                              0.051302                              8.067832   \n",
       "4                              0.041414                              5.039707   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_mean_fea  \\\n",
       "0                               0.127946   \n",
       "1                               0.108086   \n",
       "2                               0.131235   \n",
       "3                               0.131398   \n",
       "4                               0.137787   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_max_fea  label_onehot_2_word_ctr_list_min_fea  \\\n",
       "0                              0.403226                              0.058020   \n",
       "1                              0.158730                              0.064725   \n",
       "2                              0.224359                              0.078652   \n",
       "3                              0.338954                              0.046332   \n",
       "4                              0.403226                              0.071305   \n",
       "\n",
       "   ...  label_onehot_16_word_ctr_list_mean_fea  \\\n",
       "0  ...                                0.167549   \n",
       "1  ...                                0.205120   \n",
       "2  ...                                0.199417   \n",
       "3  ...                                0.203535   \n",
       "4  ...                                0.176610   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_max_fea  \\\n",
       "0                               0.285714   \n",
       "1                               0.303226   \n",
       "2                               0.566116   \n",
       "3                               0.492278   \n",
       "4                               0.331435   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0                               0.089904   \n",
       "1                               0.159265   \n",
       "2                               0.100313   \n",
       "3                               0.089904   \n",
       "4                               0.054931   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                               0.042000   \n",
       "1                               0.034133   \n",
       "2                               0.092820   \n",
       "3                               0.069743   \n",
       "4                               0.057410   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                               5.529130   \n",
       "1                               6.358730   \n",
       "2                               3.788926   \n",
       "3                              12.619198   \n",
       "4                               7.241030   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                0.077433   \n",
       "1                                0.087905   \n",
       "2                                0.093853   \n",
       "3                                0.075658   \n",
       "4                                0.078502   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                               0.147368   \n",
       "1                               0.156806   \n",
       "2                               0.241986   \n",
       "3                               0.152263   \n",
       "4                               0.147368   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                               0.038760   \n",
       "1                               0.041667   \n",
       "2                               0.029197   \n",
       "3                               0.015444   \n",
       "4                               0.017427   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                               0.028777   \n",
       "1                               0.030928   \n",
       "2                               0.044474   \n",
       "3                               0.025709   \n",
       "4                               0.023886   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_sum_fea  \n",
       "0                               2.555291  \n",
       "1                               2.725062  \n",
       "2                               1.783205  \n",
       "3                               4.690812  \n",
       "4                               3.218583  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_words_probs(df_a,df_b,label_name):\n",
    "    df_b = df_b.copy()\n",
    "    m_data = df_a.copy()\n",
    "    m_data['text'] = m_data['text'].apply(lambda x:x.split())\n",
    "    \n",
    "    word_ctr = {}\n",
    "    word_count = {}\n",
    "\n",
    "    for idx,i in enumerate(range(len(m_data))):\n",
    "        words = m_data.text.values[i]\n",
    "        words = [i for i in set(words)]\n",
    "        label = m_data[label_name].values[i]\n",
    "        for w in words:\n",
    "            word_count[w]=word_count.get(w,0)+1\n",
    "            if label==1 :  #词频大于3\n",
    "                word_ctr[w]=word_ctr.get(w,0)+1\n",
    "                \n",
    "    for k  in  word_ctr.keys():\n",
    "        word_ctr[k] = word_ctr[k]/word_count[k]\n",
    "\n",
    "    df_b['text'] =  df_b['text'].apply(lambda x:x.split())\n",
    "    df_b['word_count_list'] = df_b.text.apply(lambda x:[word_count.get(i,0) for i in x ])\n",
    "    df_b['word_ctr_list'] = df_b.text.apply(lambda x:[word_ctr.get(i,0) for i in x ])\n",
    "\n",
    "    import numpy as np\n",
    "    df_b['%s_word_ctr_list_mean_fea'%label_name] = df_b['word_ctr_list'].apply(lambda x:np.mean(x))\n",
    "    df_b['%s_word_ctr_list_max_fea'%label_name] = df_b['word_ctr_list'].apply(lambda x:np.max(x))\n",
    "    df_b['%s_word_ctr_list_min_fea'%label_name] = df_b['word_ctr_list'].apply(lambda x:np.min(x))\n",
    "    df_b['%s_word_ctr_list_std_fea'%label_name] = df_b['word_ctr_list'].apply(lambda x:np.std(x))\n",
    "    df_b['%s_word_ctr_list_sum_fea'%label_name] = df_b['word_ctr_list'].apply(lambda x:np.sum(x))\n",
    "    df_b['text'] =  df_b['text'].apply(lambda x:\" \".join(x))\n",
    "    \n",
    "    del df_b['word_count_list'],df_b['word_ctr_list']\n",
    "\n",
    "    return df_b\n",
    "\n",
    "for i in range(17):\n",
    "    label_name = 'label_onehot_%d'%(i+1)\n",
    "    test_df = get_words_probs(train_df,test_df,label_name)\n",
    "    \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:54.974062Z",
     "start_time": "2021-03-27T02:17:54.970517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "['label_onehot_1_word_ctr_list_mean_fea', 'label_onehot_1_word_ctr_list_max_fea', 'label_onehot_1_word_ctr_list_min_fea', 'label_onehot_1_word_ctr_list_std_fea', 'label_onehot_1_word_ctr_list_sum_fea', 'label_onehot_2_word_ctr_list_mean_fea', 'label_onehot_2_word_ctr_list_max_fea', 'label_onehot_2_word_ctr_list_min_fea', 'label_onehot_2_word_ctr_list_std_fea', 'label_onehot_2_word_ctr_list_sum_fea', 'label_onehot_3_word_ctr_list_mean_fea', 'label_onehot_3_word_ctr_list_max_fea', 'label_onehot_3_word_ctr_list_min_fea', 'label_onehot_3_word_ctr_list_std_fea', 'label_onehot_3_word_ctr_list_sum_fea', 'label_onehot_4_word_ctr_list_mean_fea', 'label_onehot_4_word_ctr_list_max_fea', 'label_onehot_4_word_ctr_list_min_fea', 'label_onehot_4_word_ctr_list_std_fea', 'label_onehot_4_word_ctr_list_sum_fea', 'label_onehot_5_word_ctr_list_mean_fea', 'label_onehot_5_word_ctr_list_max_fea', 'label_onehot_5_word_ctr_list_min_fea', 'label_onehot_5_word_ctr_list_std_fea', 'label_onehot_5_word_ctr_list_sum_fea', 'label_onehot_6_word_ctr_list_mean_fea', 'label_onehot_6_word_ctr_list_max_fea', 'label_onehot_6_word_ctr_list_min_fea', 'label_onehot_6_word_ctr_list_std_fea', 'label_onehot_6_word_ctr_list_sum_fea', 'label_onehot_7_word_ctr_list_mean_fea', 'label_onehot_7_word_ctr_list_max_fea', 'label_onehot_7_word_ctr_list_min_fea', 'label_onehot_7_word_ctr_list_std_fea', 'label_onehot_7_word_ctr_list_sum_fea', 'label_onehot_8_word_ctr_list_mean_fea', 'label_onehot_8_word_ctr_list_max_fea', 'label_onehot_8_word_ctr_list_min_fea', 'label_onehot_8_word_ctr_list_std_fea', 'label_onehot_8_word_ctr_list_sum_fea', 'label_onehot_9_word_ctr_list_mean_fea', 'label_onehot_9_word_ctr_list_max_fea', 'label_onehot_9_word_ctr_list_min_fea', 'label_onehot_9_word_ctr_list_std_fea', 'label_onehot_9_word_ctr_list_sum_fea', 'label_onehot_10_word_ctr_list_mean_fea', 'label_onehot_10_word_ctr_list_max_fea', 'label_onehot_10_word_ctr_list_min_fea', 'label_onehot_10_word_ctr_list_std_fea', 'label_onehot_10_word_ctr_list_sum_fea', 'label_onehot_11_word_ctr_list_mean_fea', 'label_onehot_11_word_ctr_list_max_fea', 'label_onehot_11_word_ctr_list_min_fea', 'label_onehot_11_word_ctr_list_std_fea', 'label_onehot_11_word_ctr_list_sum_fea', 'label_onehot_12_word_ctr_list_mean_fea', 'label_onehot_12_word_ctr_list_max_fea', 'label_onehot_12_word_ctr_list_min_fea', 'label_onehot_12_word_ctr_list_std_fea', 'label_onehot_12_word_ctr_list_sum_fea', 'label_onehot_13_word_ctr_list_mean_fea', 'label_onehot_13_word_ctr_list_max_fea', 'label_onehot_13_word_ctr_list_min_fea', 'label_onehot_13_word_ctr_list_std_fea', 'label_onehot_13_word_ctr_list_sum_fea', 'label_onehot_14_word_ctr_list_mean_fea', 'label_onehot_14_word_ctr_list_max_fea', 'label_onehot_14_word_ctr_list_min_fea', 'label_onehot_14_word_ctr_list_std_fea', 'label_onehot_14_word_ctr_list_sum_fea', 'label_onehot_15_word_ctr_list_mean_fea', 'label_onehot_15_word_ctr_list_max_fea', 'label_onehot_15_word_ctr_list_min_fea', 'label_onehot_15_word_ctr_list_std_fea', 'label_onehot_15_word_ctr_list_sum_fea', 'label_onehot_16_word_ctr_list_mean_fea', 'label_onehot_16_word_ctr_list_max_fea', 'label_onehot_16_word_ctr_list_min_fea', 'label_onehot_16_word_ctr_list_std_fea', 'label_onehot_16_word_ctr_list_sum_fea', 'label_onehot_17_word_ctr_list_mean_fea', 'label_onehot_17_word_ctr_list_max_fea', 'label_onehot_17_word_ctr_list_min_fea', 'label_onehot_17_word_ctr_list_std_fea', 'label_onehot_17_word_ctr_list_sum_fea']\n"
     ]
    }
   ],
   "source": [
    "features = [i for i in test_df.columns if i not in ['index','text']]\n",
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:17:55.400468Z",
     "start_time": "2021-03-27T02:17:54.975375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, random_state=4590, shuffle=True)\n",
    "for fold, (trn_, val_) in enumerate(skf.split(X=train_df, y=train_df.label.values)):\n",
    "    train_df.loc[val_, 'kfold'] = fold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:25.890056Z",
     "start_time": "2021-03-27T02:17:55.402017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>label_onehot_1</th>\n",
       "      <th>label_onehot_2</th>\n",
       "      <th>label_onehot_3</th>\n",
       "      <th>label_onehot_4</th>\n",
       "      <th>label_onehot_5</th>\n",
       "      <th>label_onehot_6</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164440</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>0.061719</td>\n",
       "      <td>7.893109</td>\n",
       "      <td>0.069383</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>3.330386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189166</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>0.069841</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>4.161647</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>1.863055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195058</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>7.022088</td>\n",
       "      <td>0.079598</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>2.865540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.398872</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.061147</td>\n",
       "      <td>7.747219</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>3.559021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187897</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>7.891675</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>2.759523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text      label  \\\n",
       "0     0|  623 328 538 382 399 400 478 842 698 137 492 26...         2    \n",
       "4     4|  623 328 399 698 493 338 266 14 177 415 511 647...        16    \n",
       "5     5|  80 328 328 54 172 439 741 380 172 842 698 177 ...        15    \n",
       "7     7|  623 328 659 486 582 162 711 289 606 405 809 78...              \n",
       "14   14|  623 328 697 661 809 48 46 355 661 414 852 328 ...  0 1 8 10    \n",
       "\n",
       "                                               label2  label_onehot_1  \\\n",
       "0   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "14  [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...               1   \n",
       "\n",
       "    label_onehot_2  label_onehot_3  label_onehot_4  label_onehot_5  \\\n",
       "0                0               1               0               0   \n",
       "4                0               0               0               0   \n",
       "5                0               0               0               0   \n",
       "7                0               0               0               0   \n",
       "14               1               0               0               0   \n",
       "\n",
       "    label_onehot_6  ...  label_onehot_16_word_ctr_list_mean_fea  \\\n",
       "0                0  ...                                0.164440   \n",
       "4                0  ...                                0.189166   \n",
       "5                0  ...                                0.195058   \n",
       "7                0  ...                                0.180168   \n",
       "14               0  ...                                0.187897   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_max_fea  \\\n",
       "0                                0.316399   \n",
       "4                                0.334732   \n",
       "5                                0.316399   \n",
       "7                                0.398872   \n",
       "14                               0.325301   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0                                0.053208   \n",
       "4                                0.069841   \n",
       "5                                0.064815   \n",
       "7                                0.078740   \n",
       "14                               0.088875   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                                0.061719   \n",
       "4                                0.060036   \n",
       "5                                0.054437   \n",
       "7                                0.061147   \n",
       "14                               0.056875   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                                7.893109   \n",
       "4                                4.161647   \n",
       "5                                7.022088   \n",
       "7                                7.747219   \n",
       "14                               7.891675   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                 0.069383   \n",
       "4                                 0.084684   \n",
       "5                                 0.079598   \n",
       "7                                 0.082768   \n",
       "14                                0.065703   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                                0.153386   \n",
       "4                                0.129310   \n",
       "5                                0.135647   \n",
       "7                                0.135647   \n",
       "14                               0.147959   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                                0.009756   \n",
       "4                                0.040923   \n",
       "5                                0.038522   \n",
       "7                                0.029412   \n",
       "14                               0.020346   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                                0.029972   \n",
       "4                                0.023791   \n",
       "5                                0.024237   \n",
       "7                                0.028315   \n",
       "14                               0.026922   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_sum_fea  \n",
       "0                                3.330386  \n",
       "4                                1.863055  \n",
       "5                                2.865540  \n",
       "7                                3.559021  \n",
       "14                               2.759523  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df = []\n",
    "\n",
    "for fold in range(5):\n",
    "    df_a = train_df[train_df.kfold!=fold]\n",
    "    df_b = train_df[train_df.kfold==fold]\n",
    "    for i in range(17):\n",
    "        label_name = 'label_onehot_%d'%(i+1)\n",
    "        df_b = get_words_probs(df_a,df_b,label_name)\n",
    "    new_train_df.append(df_b)\n",
    "    \n",
    "train_df = pd.concat(new_train_df,axis=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:25.893305Z",
     "start_time": "2021-03-27T02:18:25.891366Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:25.945891Z",
     "start_time": "2021-03-27T02:18:25.894504Z"
    },
    "executionInfo": {
     "elapsed": 54231,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AP7PUpB6FjDo"
   },
   "outputs": [],
   "source": [
    "def data_aug(df):\n",
    "    \n",
    "    import random\n",
    "    df = df.copy()\n",
    "    df[2]=df[2].apply(lambda x:x.split())\n",
    "    new_df = df.copy()\n",
    "    m =  shuffle(df)\n",
    "    m.reset_index(drop=True,inplace=True)\n",
    "    new_df[0]=100000\n",
    "    new_df[1] = new_df[1]+m[1]\n",
    "    new_df[2] = new_df[2]+m[2]\n",
    "    new_df[2]=new_df[2].apply(lambda x:\" \".join(list(set(x))))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ3gBoKgvOMd"
   },
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:25.993606Z",
     "start_time": "2021-03-27T02:18:25.947481Z"
    },
    "executionInfo": {
     "elapsed": 54229,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "01VWaoAiFsbE"
   },
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "\n",
    "import transformers\n",
    "\n",
    "class config:\n",
    "    DEVICE = \"cuda\"\n",
    "    MAX_LEN = 200\n",
    "    TRAIN_BATCH_SIZE = 30\n",
    "    VALID_BATCH_SIZE = 30\n",
    "    MODEL_PATH = \"model.bin\"\n",
    "    EPOCHS = 10\n",
    "    BERT_PATH = \"new_bert\"\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "\n",
    "\n",
    "save_path = config.BERT_PATH+'_weight_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUcAWkrbpmWI"
   },
   "source": [
    "## SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.145980Z",
     "start_time": "2021-03-27T02:18:25.994959Z"
    },
    "executionInfo": {
     "elapsed": 54226,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "Erl9-n_upohh"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import torch  \n",
    "import numpy as np\n",
    "import os\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5Wra6TtssOb"
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.158480Z",
     "start_time": "2021-03-27T02:18:26.147362Z"
    },
    "executionInfo": {
     "elapsed": 54225,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "JteBD9p1oxxp"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self,num_features,text1,text2, target):\n",
    "        self.text1 = text1\n",
    "        self.text2 = text2\n",
    "        self.target = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_length = config.MAX_LEN\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text1)\n",
    "    def get_dumm(self,s):\n",
    "        # print(\"print s\",s)\n",
    "        # print(\"s split\",s.split(' '))\n",
    "\n",
    "        re=[0]*17\n",
    "        if s=='' or s==\" \":\n",
    "            return re\n",
    "        else:\n",
    "            tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "            for i in tmp:\n",
    "                re[i]=1\n",
    "        return re\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text1 = str(self.text1[item])\n",
    "        text1 = \" \".join(text1.split())\n",
    "        text2 = None\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text1,\n",
    "            text2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        mask_padding_with_zero=True\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        pad_on_left = False\n",
    "        pad_token=0\n",
    "        pad_token_segment_id=0\n",
    "\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] )* padding_length\n",
    "                                               \n",
    "        label = self.target[item]\n",
    "        # print(\"label\",label)\n",
    "        #print(label,[i for i in label])\n",
    "        label=self.get_dumm(label)\n",
    "#         print(label)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(label, dtype=torch.float),\n",
    "            \"num_features\":torch.from_numpy(self.num_features[item]).float()\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "# class BERTDataset:\n",
    "#     def __init__(self,text1,text2, target):\n",
    "#         self.text1 = text1\n",
    "#         self.text2 = text2\n",
    "#         self.target = target\n",
    "#         self.tokenizer = config.TOKENIZER\n",
    "#         self.max_length = config.MAX_LEN\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.text1)\n",
    "\n",
    "#     def get_dumm(self,s):\n",
    "#         # print(\"print s\",s)\n",
    "#         # print(\"s split\",s.split(' '))\n",
    "\n",
    "#         re=[0]*17\n",
    "#         if s=='' or s==\" \":\n",
    "#             return re\n",
    "#         else:\n",
    "#             tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "#             for i in tmp:\n",
    "#                 re[i]=1\n",
    "#         return re\n",
    "\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         text1 = str(self.text1[item])\n",
    "#         text1 = \" \".join(text1.split())\n",
    "#         text2 = None\n",
    "#         # text2 = str(self.text2[item])\n",
    "#         # text2 = \" \".join(text2.split())\n",
    "\n",
    "#         # inputs = self.tokenizer.encode_plus(\n",
    "#         #     text1,\n",
    "#         #     text2,\n",
    "#         #     # add_special_tokens=True,\n",
    "#         #     max_length=self.max_len,\n",
    "#         #     pad_to_max_length=True,\n",
    "#         #     truncation=True\n",
    "#         # )\n",
    "\n",
    "#         # ids = inputs[\"input_ids\"]\n",
    "#         # mask = inputs[\"attention_mask\"]\n",
    "#         # token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "#         inputs = self.tokenizer.encode_plus(\n",
    "#             text1,\n",
    "#             text2,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length,\n",
    "#             truncate_first_sequence=True  # We're truncating the first sequence in priority\n",
    "#         )\n",
    "#         input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "#         # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "#         # tokens are attended to.\n",
    "#         mask_padding_with_zero=True\n",
    "#         attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "#         # Zero-pad up to the sequence length.\n",
    "#         padding_length = self.max_length - len(input_ids)\n",
    "#         pad_on_left = False\n",
    "#         pad_token=0\n",
    "#         pad_token_segment_id=0\n",
    "\n",
    "#         if pad_on_left:\n",
    "#             input_ids = ([pad_token] * padding_length) + input_ids\n",
    "#             attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "#             token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "#         else:\n",
    "#             input_ids = input_ids + ([pad_token] * padding_length)\n",
    "#             attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "#             token_type_ids = token_type_ids + ([pad_token_segment_id] )* padding_length\n",
    "                                               \n",
    "#         label = self.target[item]\n",
    "#         # print(\"label\",label)\n",
    "#         #print(label,[i for i in label])\n",
    "#         label=self.get_dumm(label)\n",
    "\n",
    "\n",
    "#         return {\n",
    "#             \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "#             \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "#             \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "#             \"targets\": torch.tensor(label, dtype=torch.float),\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54222,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "hOZTjExbUVZP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.220035Z",
     "start_time": "2021-03-27T02:18:26.159692Z"
    },
    "executionInfo": {
     "elapsed": 54221,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AlmOklJ1JPb7"
   },
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel,BertModel\n",
    "# from transformers.modeling_roberta import RobertaModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSl04MfxtWup"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.231209Z",
     "start_time": "2021-03-27T02:18:26.221549Z"
    },
    "executionInfo": {
     "elapsed": 54219,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "CJQFASGKswVR"
   },
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBert(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        config.output_hidden_states = True\n",
    "        config.num_labels = 2\n",
    "\n",
    "        super(CustomBert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = transformers.BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        n_weights = config.num_hidden_layers + 1+13\n",
    "        weights_init = torch.zeros(n_weights).float()\n",
    "        weights_init.data[:-1] = -3\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    "\n",
    "#         self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "        self.one_classifier = nn.Linear(1024, 17)\n",
    "    \n",
    "        self.line2 = nn.Linear(768+85,1024)\n",
    "\n",
    "\n",
    "        self.dp1 = nn.Dropout(0.4)\n",
    "        self.bn1 = nn.BatchNorm1d(17)\n",
    "        self.bn2 = nn.BatchNorm1d(768+85)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                num_features=None\n",
    "                ):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids\n",
    "                            )\n",
    "\n",
    "        hidden_layers = outputs[2]\n",
    "        last_layers = outputs[0]\n",
    "#         print(len(hidden_layers))\n",
    "\n",
    "        add_emb =[ torch.mean(layer,dim=1) for layer in hidden_layers] #14\n",
    "        \n",
    "        cls_outputs = torch.stack([self.dropout(layer[:, 0, :]) for layer in hidden_layers]+add_emb,\n",
    "                                  dim=2)\n",
    "#         print(cls_outputs.size())\n",
    "#         print(self.layer_weights.size())\n",
    "        cls_output = (torch.softmax(self.layer_weights, dim=0) * cls_outputs).sum(-1)\n",
    "        \n",
    "#         linear_out = F.relu(self.line1(num_features))\n",
    "#         linear_out = self.dp1(linear_out)\n",
    "#         linear_out = self.bn1(linear_out)\n",
    "        \n",
    "\n",
    "        cls_output =  torch.cat((cls_output,num_features),axis=1)\n",
    "        cls_output = self.bn2(cls_output)\n",
    "        \n",
    "        cls_output = F.relu(self.line2(cls_output))\n",
    "        cls_output = self.bn3(cls_output)\n",
    "        \n",
    "\n",
    "        \n",
    "            # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
    "        logits2 = torch.mean(torch.stack([\n",
    "            self.one_classifier(self.high_dropout(cls_output))\n",
    "            for _ in range(5)\n",
    "        ], dim=0), dim=0)\n",
    "        \n",
    "\n",
    "        return logits2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.238208Z",
     "start_time": "2021-03-27T02:18:26.232435Z"
    },
    "executionInfo": {
     "elapsed": 54217,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "DxTdZUYgwr57"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FGM():\n",
    "    \"\"\"\n",
    "    对抗训练方法类\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.5, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s5vuD5dtqRJ"
   },
   "source": [
    "## train units && eval units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.253458Z",
     "start_time": "2021-03-27T02:18:26.239710Z"
    },
    "executionInfo": {
     "elapsed": 54215,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "sW_BcT4ltgxX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    fgm = FGM(model)\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "        num_feas = d['num_features']\n",
    "\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        num_feas = num_feas.to(device, dtype=torch.float)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids,num_features=num_feas)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        fgm.attack() # 在embedding上添加对抗扰动\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids,num_features=num_feas)\n",
    "        loss_adv = loss_fn(outputs, targets)\n",
    "        # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "        loss_adv.backward() \n",
    "        # 恢复embedding参数\n",
    "        fgm.restore() \n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "            num_feas = d['num_features']\n",
    "\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            num_feas = num_feas.to(device, dtype=torch.float)\n",
    "\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids,num_features=num_feas)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.258479Z",
     "start_time": "2021-03-27T02:18:26.256190Z"
    },
    "executionInfo": {
     "elapsed": 54214,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "H1UmKtbj1n-E"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "# def threshold_search(y_true, y_proba, plot=False):\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "#     thresholds = np.append(thresholds, 1.001) \n",
    "#     F = 2 / (1/precision + 1/recall)\n",
    "#     best_score = np.max(F)\n",
    "#     best_th = thresholds[np.argmax(F)]\n",
    "#     if plot:\n",
    "#         plt.plot(thresholds, F, '-b')\n",
    "#         plt.plot([best_th], [best_score], '*r')\n",
    "#         plt.show()\n",
    "#     search_result = {'threshold': best_th , 'f1': best_score}\n",
    "#     return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.281299Z",
     "start_time": "2021-03-27T02:18:26.260064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_onehot_1_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_min_fea</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>0.393008</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>4.122316</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.058020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167549</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>2.555291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>3.501624</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>6.358730</td>\n",
       "      <td>0.087905</td>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>2.725062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>0.124938</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>2.373818</td>\n",
       "      <td>0.131235</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199417</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>3.788926</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>0.241986</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>1.783205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.423272</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>8.067832</td>\n",
       "      <td>0.131398</td>\n",
       "      <td>0.338954</td>\n",
       "      <td>0.046332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203535</td>\n",
       "      <td>0.492278</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.069743</td>\n",
       "      <td>12.619198</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.152263</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>4.690812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>0.230356</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>5.039707</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176610</td>\n",
       "      <td>0.331435</td>\n",
       "      <td>0.054931</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>7.241030</td>\n",
       "      <td>0.078502</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>3.218583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text  \\\n",
       "0    0|  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1    1|  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2    2|  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3    3|  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4    4|  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_mean_fea  \\\n",
       "0                               0.124919   \n",
       "1                               0.112956   \n",
       "2                               0.124938   \n",
       "3                               0.130126   \n",
       "4                               0.122920   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_max_fea  label_onehot_1_word_ctr_list_min_fea  \\\n",
       "0                              0.393008                              0.054608   \n",
       "1                              0.197067                              0.079536   \n",
       "2                              0.224359                              0.062696   \n",
       "3                              0.423272                              0.052124   \n",
       "4                              0.230356                              0.045000   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_std_fea  label_onehot_1_word_ctr_list_sum_fea  \\\n",
       "0                              0.079149                              4.122316   \n",
       "1                              0.021437                              3.501624   \n",
       "2                              0.039191                              2.373818   \n",
       "3                              0.051302                              8.067832   \n",
       "4                              0.041414                              5.039707   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_mean_fea  \\\n",
       "0                               0.127946   \n",
       "1                               0.108086   \n",
       "2                               0.131235   \n",
       "3                               0.131398   \n",
       "4                               0.137787   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_max_fea  label_onehot_2_word_ctr_list_min_fea  \\\n",
       "0                              0.403226                              0.058020   \n",
       "1                              0.158730                              0.064725   \n",
       "2                              0.224359                              0.078652   \n",
       "3                              0.338954                              0.046332   \n",
       "4                              0.403226                              0.071305   \n",
       "\n",
       "   ...  label_onehot_16_word_ctr_list_mean_fea  \\\n",
       "0  ...                                0.167549   \n",
       "1  ...                                0.205120   \n",
       "2  ...                                0.199417   \n",
       "3  ...                                0.203535   \n",
       "4  ...                                0.176610   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_max_fea  \\\n",
       "0                               0.285714   \n",
       "1                               0.303226   \n",
       "2                               0.566116   \n",
       "3                               0.492278   \n",
       "4                               0.331435   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0                               0.089904   \n",
       "1                               0.159265   \n",
       "2                               0.100313   \n",
       "3                               0.089904   \n",
       "4                               0.054931   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                               0.042000   \n",
       "1                               0.034133   \n",
       "2                               0.092820   \n",
       "3                               0.069743   \n",
       "4                               0.057410   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                               5.529130   \n",
       "1                               6.358730   \n",
       "2                               3.788926   \n",
       "3                              12.619198   \n",
       "4                               7.241030   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                0.077433   \n",
       "1                                0.087905   \n",
       "2                                0.093853   \n",
       "3                                0.075658   \n",
       "4                                0.078502   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                               0.147368   \n",
       "1                               0.156806   \n",
       "2                               0.241986   \n",
       "3                               0.152263   \n",
       "4                               0.147368   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                               0.038760   \n",
       "1                               0.041667   \n",
       "2                               0.029197   \n",
       "3                               0.015444   \n",
       "4                               0.017427   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                               0.028777   \n",
       "1                               0.030928   \n",
       "2                               0.044474   \n",
       "3                               0.025709   \n",
       "4                               0.023886   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_sum_fea  \n",
       "0                               2.555291  \n",
       "1                               2.725062  \n",
       "2                               1.783205  \n",
       "3                               4.690812  \n",
       "4                               3.218583  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.292221Z",
     "start_time": "2021-03-27T02:18:26.282743Z"
    },
    "executionInfo": {
     "elapsed": 54213,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "2Y5yWlJ1JU8T"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df['label']=''\n",
    "\n",
    "\n",
    "test_num_features = test_df[features].values\n",
    "\n",
    "test_dataset = BERTDataset(num_features=test_num_features,text1=test_df.text.values,text2=None,target=test_df.label.values)\n",
    "\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T02:18:26.306230Z",
     "start_time": "2021-03-27T02:18:26.293669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54207,
     "status": "ok",
     "timestamp": 1614770555905,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3o9ESVHNveHE",
    "outputId": "41172ca1-a855-49cb-eda9-08d5e15b0a5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': tensor([101, 118, 106, 136, 140, 239, 138, 125, 312, 192, 604, 294, 180, 304,\n",
      "        311, 187, 959, 174, 105, 118, 106, 136, 125, 112, 140, 621, 291, 414,\n",
      "        379, 192, 160, 253, 119, 161, 102,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'targets': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'num_features': tensor([1.2492e-01, 3.9301e-01, 5.4608e-02, 7.9149e-02, 4.1223e+00, 1.2795e-01,\n",
      "        4.0323e-01, 5.8020e-02, 6.8453e-02, 4.2222e+00, 1.2013e-01, 3.8173e-01,\n",
      "        4.7101e-02, 7.3254e-02, 3.9643e+00, 5.3626e-02, 1.1834e-01, 3.0101e-02,\n",
      "        2.0308e-02, 1.7697e+00, 9.8463e-02, 1.8385e-01, 4.4379e-02, 3.6670e-02,\n",
      "        3.2493e+00, 3.4056e-02, 7.2464e-02, 1.1029e-02, 1.5192e-02, 1.1239e+00,\n",
      "        2.0934e-02, 9.8765e-02, 4.4379e-03, 1.6370e-02, 6.9083e-01, 1.3056e-01,\n",
      "        3.8543e-01, 3.0717e-02, 7.3545e-02, 4.3084e+00, 1.2463e-01, 3.7262e-01,\n",
      "        5.8824e-02, 6.1480e-02, 4.1128e+00, 1.1897e-01, 3.3942e-01, 2.0672e-02,\n",
      "        6.6546e-02, 3.9260e+00, 4.6604e-02, 8.6420e-02, 1.9355e-02, 1.7091e-02,\n",
      "        1.5379e+00, 8.4604e-02, 1.6659e-01, 3.1065e-02, 3.4874e-02, 2.7919e+00,\n",
      "        3.9883e-02, 7.4074e-02, 1.0989e-02, 1.6226e-02, 1.3161e+00, 2.1673e-02,\n",
      "        4.6385e-02, 0.0000e+00, 9.2203e-03, 7.1521e-01, 4.7758e-02, 7.1587e-02,\n",
      "        1.4493e-02, 1.5644e-02, 1.5760e+00, 1.6755e-01, 2.8571e-01, 8.9904e-02,\n",
      "        4.2000e-02, 5.5291e+00, 7.7433e-02, 1.4737e-01, 3.8760e-02, 2.8777e-02,\n",
      "        2.5553e+00])}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T03:49:04.732957Z",
     "start_time": "2021-03-27T02:18:26.307609Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "To_m5aPptg0s",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 1 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at new_bert were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at new_bert and are newly initialized: ['layer_weights', 'one_classifier.weight', 'one_classifier.bias', 'line2.weight', 'line2.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 266/266 [01:39<00:00,  2.68it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.827002763748169, score is 0.9513527750968933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7685548067092896, score is 0.9547908902168274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7306185364723206, score is 0.9570224285125732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7108911871910095, score is 0.9581828713417053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:34<00:00,  2.81it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7056679129600525, score is 0.9584901332855225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:34<00:00,  2.81it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.695443332195282, score is 0.9590915441513062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:38<00:00,  2.70it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6948860287666321, score is 0.9591243267059326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6902704238891602, score is 0.9593958854675293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6914454102516174, score is 0.9593267440795898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 266/266 [01:37<00:00,  2.74it/s]\n",
      "100%|██████████| 69/69 [00:04<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6908352375030518, score is 0.9593626260757446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:04<00:00, 16.57it/s]\n",
      "/home/root1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 2 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at new_bert were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at new_bert and are newly initialized: ['layer_weights', 'one_classifier.weight', 'one_classifier.bias', 'line2.weight', 'line2.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8281863927841187, score is 0.9512831568717957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7707324624061584, score is 0.9546627998352051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7310232520103455, score is 0.9569986462593079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7174004316329956, score is 0.9577999711036682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7028180360794067, score is 0.9586577415466309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:38<00:00,  2.70it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6966249346733093, score is 0.959022045135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:41<00:00,  2.63it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6931130290031433, score is 0.9592286348342896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6882416605949402, score is 0.9595152139663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6902779340744019, score is 0.9593954086303711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 266/266 [01:41<00:00,  2.63it/s]\n",
      "100%|██████████| 68/68 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6902791261672974, score is 0.9593953490257263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:04<00:00, 16.57it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 3 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at new_bert were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at new_bert and are newly initialized: ['layer_weights', 'one_classifier.weight', 'one_classifier.bias', 'line2.weight', 'line2.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 267/267 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8304091095924377, score is 0.9511523842811584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7597329616546631, score is 0.9553098082542419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.73989337682724, score is 0.9564768671989441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:39<00:00,  2.67it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7184802293777466, score is 0.9577364325523376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7084943056106567, score is 0.9583238363265991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.65it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6949262619018555, score is 0.9591220021247864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6956345438957214, score is 0.9590803384780884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:37<00:00,  2.75it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6907532811164856, score is 0.9593674540519714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6905400156974792, score is 0.959380030632019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [01:40<00:00,  2.64it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6869368553161621, score is 0.9595919251441956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:04<00:00, 16.36it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 4 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at new_bert were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at new_bert and are newly initialized: ['layer_weights', 'one_classifier.weight', 'one_classifier.bias', 'line2.weight', 'line2.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 268/268 [01:37<00:00,  2.76it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8346675634384155, score is 0.9509019255638123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7647748589515686, score is 0.9550132751464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7243238091468811, score is 0.957392692565918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7140198349952698, score is 0.9579988121986389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.68it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.708477258682251, score is 0.9583248496055603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6974489688873291, score is 0.9589735865592957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6959986090660095, score is 0.9590588808059692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:40<00:00,  2.66it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6913599371910095, score is 0.959331750869751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6908541321754456, score is 0.9593615531921387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:41<00:00,  2.64it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6874920129776001, score is 0.9595593214035034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:03<00:00, 16.52it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 5 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at new_bert were not used when initializing CustomBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing CustomBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBert were not initialized from the model checkpoint at new_bert and are newly initialized: ['layer_weights', 'one_classifier.weight', 'one_classifier.bias', 'line2.weight', 'line2.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 269/269 [01:40<00:00,  2.69it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8266870379447937, score is 0.9513713717460632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:45<00:00,  2.55it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7808566093444824, score is 0.9540672302246094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:45<00:00,  2.54it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7397829294204712, score is 0.9564833641052246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:45<00:00,  2.55it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7286184430122375, score is 0.9571400880813599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7172415256500244, score is 0.957809329032898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7127739787101746, score is 0.9580721259117126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7069233059883118, score is 0.9584162831306458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:04<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7068960666656494, score is 0.9584178924560547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:41<00:00,  2.65it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7054612040519714, score is 0.9585022926330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:40<00:00,  2.67it/s]\n",
      "100%|██████████| 66/66 [00:03<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7066102027893066, score is 0.9584347009658813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:03<00:00, 16.77it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,GroupKFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score , recall_score\t, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold,GroupKFold\n",
    "# gkf =  GroupKFold(n_splits=5)\n",
    "# groups_by_text_id_list = train['qid'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oof_df_list = []\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "oof_train_list = []\n",
    "pred = [] \n",
    "\n",
    "# score\n",
    "\n",
    "def ss_score(targets,outputs):\n",
    "    \n",
    "    targets = torch.tensor(targets,dtype=torch.float)\n",
    "    outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "    loss = nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "    score = 1- loss/17\n",
    "    return loss.cpu().detach().numpy(),score\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    \n",
    "\n",
    "    print(\"开始第 %d 折训练\"%(fold+1))\n",
    "    \n",
    "\n",
    "    \n",
    "    model_path = \"%s/bert_wwm_model_%d.bin\"%(save_path,fold)\n",
    "    config.MODEL_PATH = model_path\n",
    "#     tr_df = train_df.iloc[trn_idx]\n",
    "#     va_df = train_df.iloc[val_idx]\n",
    "\n",
    "    tr_df = train_df[train_df.kfold!=fold]\n",
    "    va_df = train_df[train_df.kfold==fold]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    tr_df_num_feas = tr_df[features].values\n",
    "    va_df_num_feas = va_df[features].values\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = BERTDataset(num_features=tr_df_num_feas,\n",
    "        text1=tr_df.text.values,text2=None,target=tr_df.label.values\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4,shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDataset(num_features=va_df_num_feas,\n",
    "     text1= va_df.text.values,text2=None,target=va_df.label.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n",
    "\n",
    "    device = torch.device(config.DEVICE)\n",
    "    model = CustomBert.from_pretrained(config.BERT_PATH,num_labels=1)\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    # pretrain model param\n",
    "    param_pre = [(n, p) for n, p in param_optimizer if 'bert' in n]\n",
    "    # dym param\n",
    "    param_dym = [(n, p) for n, p in param_optimizer if 'layer_weights' in n ]\n",
    "    # funsion layer param\n",
    "    param_line = [p for n, p in param_optimizer if 'one_classifier' in n or 'line1' in n or 'line2' in n]\n",
    "    # 不进行衰减的权重\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "         # pretrain model param\n",
    "        # 衰减\n",
    "        {'params': [p for n, p in param_pre if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01, 'lr': 2e-5\n",
    "         },\n",
    "        # 不衰减\n",
    "        {'params': [p for n, p in param_pre if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0, 'lr': 2e-5\n",
    "         },\n",
    "        # dym  layer\n",
    "        # 衰减\n",
    "        {'params': [p for n, p in param_dym if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01, 'lr': 1e-3\n",
    "         },\n",
    "        # 不衰减\n",
    "        {'params': [p for n, p in param_dym if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0, 'lr':1e-3\n",
    "         },\n",
    " \n",
    "        # linear  layer\n",
    "        # 衰减\n",
    "        {'params': [p for p in param_line ],\n",
    "         'weight_decay': 0.0, 'lr': 1e-3\n",
    "         }\n",
    "    ]\n",
    "\n",
    "\n",
    "    num_train_steps = int(len(tr_df) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    warmup_steps = int(num_train_steps*0.1)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,num_warmup_steps=warmup_steps,num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    min_loss = 100000\n",
    "    best_score =0\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "#         loss= torch.nn.BCEWithLogitsLoss()(torch.tensor(outputs),torch.tensor(targets))\n",
    "        loss,score = ss_score(targets,outputs)\n",
    "\n",
    "        # result =  threshold_search(targets,outputs)\n",
    "        # thr = result['threshold']\n",
    "        # f1 = result['f1']\n",
    "        # outputs = (outputs>thr).astype(int)\n",
    "        # f1 = f1_score(targets,outputs)\n",
    "        # precision = precision_score(targets, outputs)\n",
    "        # recall =  recall_score(targets,outputs)\n",
    "\n",
    "        print(f\"loss = {loss}, score is {score}\")\n",
    "\n",
    "\n",
    "#         if loss<min_loss:\n",
    "#             torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "#             min_loss = loss\n",
    "\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(),config.MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load( config.MODEL_PATH))\n",
    "    outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "    va_df['prob'] = outputs\n",
    "    oof_train_list.append(va_df)\n",
    "\n",
    "    outputs, targets = eval_fn(test_data_loader, model, device)\n",
    "    pred.append(np.array(outputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T03:49:04.769249Z",
     "start_time": "2021-03-27T03:49:04.734721Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "TVCqxmfaHHro"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>label_onehot_1</th>\n",
       "      <th>label_onehot_2</th>\n",
       "      <th>label_onehot_3</th>\n",
       "      <th>label_onehot_4</th>\n",
       "      <th>label_onehot_5</th>\n",
       "      <th>label_onehot_6</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>0.061719</td>\n",
       "      <td>7.893109</td>\n",
       "      <td>0.069383</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>3.330386</td>\n",
       "      <td>[0.0028005423955619335, 0.0076747918501496315,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>0.069841</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>4.161647</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>1.863055</td>\n",
       "      <td>[0.0012862442526966333, 0.007899697870016098, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>7.022088</td>\n",
       "      <td>0.079598</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>2.865540</td>\n",
       "      <td>[0.004175003618001938, 0.004221336916089058, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398872</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.061147</td>\n",
       "      <td>7.747219</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>3.559021</td>\n",
       "      <td>[0.00320462416857481, 0.0036855146754533052, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>7.891675</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>2.759523</td>\n",
       "      <td>[0.9999947547912598, 1.0, 0.009344044141471386...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text      label  \\\n",
       "0     0|  623 328 538 382 399 400 478 842 698 137 492 26...         2    \n",
       "4     4|  623 328 399 698 493 338 266 14 177 415 511 647...        16    \n",
       "5     5|  80 328 328 54 172 439 741 380 172 842 698 177 ...        15    \n",
       "7     7|  623 328 659 486 582 162 711 289 606 405 809 78...              \n",
       "14   14|  623 328 697 661 809 48 46 355 661 414 852 328 ...  0 1 8 10    \n",
       "\n",
       "                                               label2  label_onehot_1  \\\n",
       "0   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "14  [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...               1   \n",
       "\n",
       "    label_onehot_2  label_onehot_3  label_onehot_4  label_onehot_5  \\\n",
       "0                0               1               0               0   \n",
       "4                0               0               0               0   \n",
       "5                0               0               0               0   \n",
       "7                0               0               0               0   \n",
       "14               1               0               0               0   \n",
       "\n",
       "    label_onehot_6  ...  label_onehot_16_word_ctr_list_max_fea  \\\n",
       "0                0  ...                               0.316399   \n",
       "4                0  ...                               0.334732   \n",
       "5                0  ...                               0.316399   \n",
       "7                0  ...                               0.398872   \n",
       "14               0  ...                               0.325301   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0                                0.053208   \n",
       "4                                0.069841   \n",
       "5                                0.064815   \n",
       "7                                0.078740   \n",
       "14                               0.088875   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                                0.061719   \n",
       "4                                0.060036   \n",
       "5                                0.054437   \n",
       "7                                0.061147   \n",
       "14                               0.056875   \n",
       "\n",
       "    label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                                7.893109   \n",
       "4                                4.161647   \n",
       "5                                7.022088   \n",
       "7                                7.747219   \n",
       "14                               7.891675   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                 0.069383   \n",
       "4                                 0.084684   \n",
       "5                                 0.079598   \n",
       "7                                 0.082768   \n",
       "14                                0.065703   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                                0.153386   \n",
       "4                                0.129310   \n",
       "5                                0.135647   \n",
       "7                                0.135647   \n",
       "14                               0.147959   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                                0.009756   \n",
       "4                                0.040923   \n",
       "5                                0.038522   \n",
       "7                                0.029412   \n",
       "14                               0.020346   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                                0.029972   \n",
       "4                                0.023791   \n",
       "5                                0.024237   \n",
       "7                                0.028315   \n",
       "14                               0.026922   \n",
       "\n",
       "    label_onehot_17_word_ctr_list_sum_fea  \\\n",
       "0                                3.330386   \n",
       "4                                1.863055   \n",
       "5                                2.865540   \n",
       "7                                3.559021   \n",
       "14                               2.759523   \n",
       "\n",
       "                                                 prob  \n",
       "0   [0.0028005423955619335, 0.0076747918501496315,...  \n",
       "4   [0.0012862442526966333, 0.007899697870016098, ...  \n",
       "5   [0.004175003618001938, 0.004221336916089058, 0...  \n",
       "7   [0.00320462416857481, 0.0036855146754533052, 0...  \n",
       "14  [0.9999947547912598, 1.0, 0.009344044141471386...  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = pd.concat(oof_train_list)\n",
    "oof_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T03:49:04.774647Z",
     "start_time": "2021-03-27T03:49:04.770519Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "S1svWP3sJPmb"
   },
   "outputs": [],
   "source": [
    "sub = np.average(pred, axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T03:49:04.781754Z",
     "start_time": "2021-03-27T03:49:04.775918Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "xMYQOboMMx5a"
   },
   "outputs": [],
   "source": [
    "m = sub.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:03.679243Z",
     "start_time": "2021-03-27T04:08:03.655755Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "lNKLriwIL5YP"
   },
   "outputs": [],
   "source": [
    "def get_dumm(s):\n",
    "    re=[0]*17\n",
    "    if s=='' or s==\" \":\n",
    "        return re\n",
    "    else:\n",
    "        tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "        for i in tmp:\n",
    "            re[i]=1\n",
    "    return re\n",
    "\n",
    "\n",
    "oof_train['label'] = oof_train['label'].apply(lambda x:get_dumm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:04.648236Z",
     "start_time": "2021-03-27T04:08:04.564581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>label_onehot_1</th>\n",
       "      <th>label_onehot_2</th>\n",
       "      <th>label_onehot_3</th>\n",
       "      <th>label_onehot_4</th>\n",
       "      <th>label_onehot_5</th>\n",
       "      <th>label_onehot_6</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>0.061719</td>\n",
       "      <td>7.893109</td>\n",
       "      <td>0.069383</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>3.330386</td>\n",
       "      <td>[0.0028005423955619335, 0.0076747918501496315,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>0.069841</td>\n",
       "      <td>0.060036</td>\n",
       "      <td>4.161647</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>1.863055</td>\n",
       "      <td>[0.0012862442526966333, 0.007899697870016098, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.054437</td>\n",
       "      <td>7.022088</td>\n",
       "      <td>0.079598</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.024237</td>\n",
       "      <td>2.865540</td>\n",
       "      <td>[0.004175003618001938, 0.004221336916089058, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398872</td>\n",
       "      <td>0.078740</td>\n",
       "      <td>0.061147</td>\n",
       "      <td>7.747219</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>3.559021</td>\n",
       "      <td>[0.00320462416857481, 0.0036855146754533052, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>7.891675</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>2.759523</td>\n",
       "      <td>[0.9999947547912598, 1.0, 0.009344044141471386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21|</td>\n",
       "      <td>380 172 200 791 470 753 693 256 514 569 231 11...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.108533</td>\n",
       "      <td>7.688602</td>\n",
       "      <td>0.083780</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.027059</td>\n",
       "      <td>0.036084</td>\n",
       "      <td>3.267410</td>\n",
       "      <td>[0.003285845974460244, 0.004417122341692448, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27|</td>\n",
       "      <td>852 328 501 355 360 265 478 162 498 289 169 40...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316399</td>\n",
       "      <td>0.089118</td>\n",
       "      <td>0.052943</td>\n",
       "      <td>10.974305</td>\n",
       "      <td>0.082929</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.042620</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>4.561104</td>\n",
       "      <td>[0.0022288879845291376, 0.002418902702629566, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31|</td>\n",
       "      <td>91 380 488 12 591 487 197 852 328 538 501 382 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>6.645423</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>3.105038</td>\n",
       "      <td>[0.0037080259062349796, 0.003557736985385418, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35|</td>\n",
       "      <td>380 315 809 623 328 160 380 419 789 439 852 81...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.091041</td>\n",
       "      <td>11.624503</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>3.722838</td>\n",
       "      <td>[0.0013001956976950169, 0.004078374244272709, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41|</td>\n",
       "      <td>48 718 328 419 571 769 256 100 809 328 380 172...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493888</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.072358</td>\n",
       "      <td>13.445610</td>\n",
       "      <td>0.077398</td>\n",
       "      <td>0.159763</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.026776</td>\n",
       "      <td>4.798670</td>\n",
       "      <td>[0.00013342891179490834, 0.0001463307853555306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48|</td>\n",
       "      <td>48 231 419 571 769 256 524 809 328 380 373 320...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.134315</td>\n",
       "      <td>12.774244</td>\n",
       "      <td>0.075250</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.034215</td>\n",
       "      <td>3.611987</td>\n",
       "      <td>[0.00019667034212034196, 0.0001271027722395956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51|</td>\n",
       "      <td>852 328 3 697 483 582 582 717 382 363 397 834 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.120192</td>\n",
       "      <td>0.073687</td>\n",
       "      <td>9.570769</td>\n",
       "      <td>0.084620</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>4.061775</td>\n",
       "      <td>[0.0017424769466742873, 0.009933008812367916, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59|</td>\n",
       "      <td>623 328 538 661 698 493 338 266 177 415 832 38...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352657</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.051193</td>\n",
       "      <td>12.648152</td>\n",
       "      <td>0.098406</td>\n",
       "      <td>0.420354</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.062467</td>\n",
       "      <td>6.199551</td>\n",
       "      <td>[0.0023305437061935663, 0.0031611761078238487,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61|</td>\n",
       "      <td>852 328 383 538 661 22 698 338 266 521 177 415...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.047915</td>\n",
       "      <td>10.361616</td>\n",
       "      <td>0.076567</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.023959</td>\n",
       "      <td>4.058066</td>\n",
       "      <td>[0.003944179508835077, 0.007959757931530476, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62|</td>\n",
       "      <td>328 22 290 380 398 851 728 636 851 636 70 628 ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.091417</td>\n",
       "      <td>15.931742</td>\n",
       "      <td>0.078171</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>5.081112</td>\n",
       "      <td>[0.00015689046995248646, 0.0001928202545968815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69|</td>\n",
       "      <td>48 328 290 380 419 789 523 532 50 693 556 698 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343124</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.055671</td>\n",
       "      <td>3.674850</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.052069</td>\n",
       "      <td>0.032770</td>\n",
       "      <td>1.628966</td>\n",
       "      <td>[0.0021400004625320435, 0.0035199911799281836,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72|</td>\n",
       "      <td>328 697 661 19 363 737 698 785 504 493 338 266...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.074819</td>\n",
       "      <td>21.411595</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.164964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028204</td>\n",
       "      <td>8.116511</td>\n",
       "      <td>[1.0, 0.001229653600603342, 0.0036125583574175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75|</td>\n",
       "      <td>852 328 160 380 439 679 63 541 848 698 510 838...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304364</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.047428</td>\n",
       "      <td>7.930532</td>\n",
       "      <td>0.093953</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>3.664183</td>\n",
       "      <td>[0.0002591898664832115, 0.0007651884225197136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76|</td>\n",
       "      <td>623 164 305 204 204 399 698 641 794 779 437 17...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.049546</td>\n",
       "      <td>6.996279</td>\n",
       "      <td>0.079554</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>3.023063</td>\n",
       "      <td>[0.0025879545137286186, 0.0039453040808439255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90|</td>\n",
       "      <td>725 471 453 162 684 289 462 405 788 177 232 23...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.055776</td>\n",
       "      <td>7.087144</td>\n",
       "      <td>0.080650</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>2.984046</td>\n",
       "      <td>[0.002920850645750761, 0.0044312505051493645, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91|</td>\n",
       "      <td>48 328 697 243 19 363 842 698 627 504 493 338 ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.117378</td>\n",
       "      <td>0.071979</td>\n",
       "      <td>18.239018</td>\n",
       "      <td>0.081869</td>\n",
       "      <td>0.164964</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>7.204490</td>\n",
       "      <td>[1.0, 0.008882715366780758, 0.0032057776115834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97|</td>\n",
       "      <td>290 351 380 99 809 813 380 786 287 515 305 654...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304364</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.042193</td>\n",
       "      <td>11.667557</td>\n",
       "      <td>0.110150</td>\n",
       "      <td>0.420354</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>6.168415</td>\n",
       "      <td>[0.001932140439748764, 0.003069933271035552, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98|</td>\n",
       "      <td>623 328 380 834 809 343 809 362 840 556 698 42...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.086580</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>12.099090</td>\n",
       "      <td>0.071605</td>\n",
       "      <td>0.164964</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.032687</td>\n",
       "      <td>4.296322</td>\n",
       "      <td>[0.004211496561765671, 0.005881054326891899, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101|</td>\n",
       "      <td>380 172 200 737 300 78 448 290 693 380 834 343...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.099237</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>14.445808</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.164964</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.025905</td>\n",
       "      <td>5.373257</td>\n",
       "      <td>[0.011942751705646515, 0.014644548296928406, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107|</td>\n",
       "      <td>623 328 697 69 698 33 735 382 327 514 381 693 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304364</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.042955</td>\n",
       "      <td>3.853609</td>\n",
       "      <td>0.078262</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>1.721771</td>\n",
       "      <td>[0.003337035421282053, 0.0033456122037023306, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115|</td>\n",
       "      <td>48 328 328 380 172 320 380 19 363 399 352 494 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.167109</td>\n",
       "      <td>5.888011</td>\n",
       "      <td>0.083228</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.027059</td>\n",
       "      <td>0.029516</td>\n",
       "      <td>1.581325</td>\n",
       "      <td>[0.002847346942871809, 0.00308043509721756, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116|</td>\n",
       "      <td>623 328 538 582 842 698 641 769 779 177 166 16...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362429</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.051910</td>\n",
       "      <td>19.765167</td>\n",
       "      <td>0.088272</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>8.827220</td>\n",
       "      <td>[0.001564481994137168, 0.00918856542557478, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120|</td>\n",
       "      <td>380 136 363 399 556 438 313 149 713 432 768 11...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.054618</td>\n",
       "      <td>11.443663</td>\n",
       "      <td>0.078072</td>\n",
       "      <td>0.146924</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.027093</td>\n",
       "      <td>4.372006</td>\n",
       "      <td>[0.0021932879462838173, 0.0056733014062047005,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124|</td>\n",
       "      <td>623 328 697 538 355 27 386 728 478 647 169 750...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>3.808311</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.042842</td>\n",
       "      <td>0.032418</td>\n",
       "      <td>1.888649</td>\n",
       "      <td>[0.0043333470821380615, 0.0035896128974854946,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128|</td>\n",
       "      <td>48 328 697 355 766 809 623 328 538 661 265 470...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398872</td>\n",
       "      <td>0.088875</td>\n",
       "      <td>0.071236</td>\n",
       "      <td>9.033472</td>\n",
       "      <td>0.064186</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>2.888355</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.14246928691864014, 0.0012420...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>9869|</td>\n",
       "      <td>623 328 538 582 439 81 661 374 842 698 78 638 381</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337484</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.061312</td>\n",
       "      <td>2.401540</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.112306</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>[0.1602904498577118, 0.022107252851128578, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>9871|</td>\n",
       "      <td>478 333 390 636 276 698 116 71 712 620 381 693...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301375</td>\n",
       "      <td>0.094270</td>\n",
       "      <td>0.047305</td>\n",
       "      <td>3.644913</td>\n",
       "      <td>0.069964</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>1.469235</td>\n",
       "      <td>[0.03574756905436516, 0.026403557509183884, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>9882|</td>\n",
       "      <td>91 382 569 231 556 698 313 66 432 449 693 664 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297806</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.038020</td>\n",
       "      <td>3.647454</td>\n",
       "      <td>0.072669</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>1.526059</td>\n",
       "      <td>[0.038853686302900314, 0.02297392673790455, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>9883|</td>\n",
       "      <td>623 657 320 786 399 851 636 374 698 516 149 26...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812925</td>\n",
       "      <td>0.094270</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>6.511711</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.058396</td>\n",
       "      <td>2.558946</td>\n",
       "      <td>[0.024663055315613747, 0.017592065036296844, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9895|</td>\n",
       "      <td>48 328 380 834 809 343 698 177 415 832 468 25 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.103865</td>\n",
       "      <td>0.048809</td>\n",
       "      <td>4.413894</td>\n",
       "      <td>0.078093</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>1.718037</td>\n",
       "      <td>[0.007288849446922541, 0.01736750826239586, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900|</td>\n",
       "      <td>623 328 328 380 172 470 651 394 596 502 340 37...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321239</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>5.287198</td>\n",
       "      <td>0.072548</td>\n",
       "      <td>0.120835</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>1.958801</td>\n",
       "      <td>[0.04298226907849312, 0.038915395736694336, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>9905|</td>\n",
       "      <td>247 305 461 204 698 162 498 289 177 415 381</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0.120027</td>\n",
       "      <td>0.038412</td>\n",
       "      <td>1.946140</td>\n",
       "      <td>0.092536</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>1.017899</td>\n",
       "      <td>[0.04486940801143646, 0.03844381868839264, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>9908|</td>\n",
       "      <td>623 328 290 380 372 236 636 90 735 374 698 14 ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337484</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>7.235424</td>\n",
       "      <td>0.076459</td>\n",
       "      <td>0.310734</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.050948</td>\n",
       "      <td>2.752540</td>\n",
       "      <td>[0.04112799093127251, 0.0010431066621094942, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9914</th>\n",
       "      <td>9914|</td>\n",
       "      <td>290 380 582 809 160 380 786 809 244 328 550 32...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311203</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.035254</td>\n",
       "      <td>5.703665</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>2.962808</td>\n",
       "      <td>[0.0027669889386743307, 0.0056350030936300755,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>9921|</td>\n",
       "      <td>91 380 769 12 591 423 487 693 623 79 328 380 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337484</td>\n",
       "      <td>0.084079</td>\n",
       "      <td>0.060276</td>\n",
       "      <td>7.282553</td>\n",
       "      <td>0.070658</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>2.826317</td>\n",
       "      <td>[0.061021022498607635, 0.13621199131011963, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>9923|</td>\n",
       "      <td>623 328 355 661 698 338 266 437 521 254 415 38...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609890</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.075584</td>\n",
       "      <td>8.637974</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.161725</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.031984</td>\n",
       "      <td>3.014622</td>\n",
       "      <td>[0.040380824357271194, 1.0, 0.0296803265810012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>9924|</td>\n",
       "      <td>852 328 380 172 54 823 391 693 380 654 439 380...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321239</td>\n",
       "      <td>0.084848</td>\n",
       "      <td>0.050796</td>\n",
       "      <td>7.271281</td>\n",
       "      <td>0.078499</td>\n",
       "      <td>0.139394</td>\n",
       "      <td>0.040925</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>3.061474</td>\n",
       "      <td>[0.03418154641985893, 0.028990620747208595, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>9925|</td>\n",
       "      <td>139 81 200 737 556 698 313 326 432 449 693 852...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332155</td>\n",
       "      <td>0.134109</td>\n",
       "      <td>0.043066</td>\n",
       "      <td>3.924656</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.037456</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>1.436946</td>\n",
       "      <td>[0.03763478994369507, 0.03385389596223831, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>9929|</td>\n",
       "      <td>256 514 38 582 623 34 693 91 382 556 698 432 4...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291737</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.041160</td>\n",
       "      <td>7.606663</td>\n",
       "      <td>0.067378</td>\n",
       "      <td>0.136228</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>2.560350</td>\n",
       "      <td>[0.191211998462677, 1.0, 0.014529337175190449,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>9930|</td>\n",
       "      <td>380 172 439 380 654 200 737 779 59 655 798 693...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337484</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.054445</td>\n",
       "      <td>15.292929</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>5.789292</td>\n",
       "      <td>[0.010188275016844273, 0.006628052331507206, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>9931|</td>\n",
       "      <td>48 328 733 777 204 549 728 832 131 693 623 328...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321239</td>\n",
       "      <td>0.106173</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>7.498455</td>\n",
       "      <td>0.072123</td>\n",
       "      <td>0.115896</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>2.740680</td>\n",
       "      <td>[0.06826052814722061, 1.0, 0.00065556756453588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>9934|</td>\n",
       "      <td>623 727 697 538 382 397 455 693 411 204 439 62...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237473</td>\n",
       "      <td>0.092317</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>3.087932</td>\n",
       "      <td>0.078314</td>\n",
       "      <td>0.127413</td>\n",
       "      <td>0.045762</td>\n",
       "      <td>0.022859</td>\n",
       "      <td>1.566289</td>\n",
       "      <td>[0.043339379131793976, 0.03707332909107208, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9935|</td>\n",
       "      <td>162 498 289 169 405 693 623 328 357 661 822 33...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291737</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.044624</td>\n",
       "      <td>6.002796</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>2.185532</td>\n",
       "      <td>[0.26044851541519165, 0.23536370694637299, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>9946|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 189 832 14 381 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>6.805980</td>\n",
       "      <td>0.099039</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>3.466371</td>\n",
       "      <td>[0.03880390152335167, 0.018888194113969803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>9952|</td>\n",
       "      <td>48 673 545 784 856 374 439 379 328 717 172 320...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812925</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>16.259537</td>\n",
       "      <td>0.077958</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.032525</td>\n",
       "      <td>5.535034</td>\n",
       "      <td>[0.019613750278949738, 0.009316817857325077, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>9953|</td>\n",
       "      <td>623 328 697 582 17 501 382 400 434 439 380 136...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.056748</td>\n",
       "      <td>0.059975</td>\n",
       "      <td>7.202407</td>\n",
       "      <td>0.086589</td>\n",
       "      <td>0.310734</td>\n",
       "      <td>0.045762</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>3.290368</td>\n",
       "      <td>[0.9999983310699463, 0.006364456843584776, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>9957|</td>\n",
       "      <td>135 328 776 355 616 38 91 382 698 514 408 177 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321239</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.054198</td>\n",
       "      <td>7.889937</td>\n",
       "      <td>0.084184</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>3.030628</td>\n",
       "      <td>[0.018360840156674385, 0.049435317516326904, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9964|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 177 415 381 644...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.082883</td>\n",
       "      <td>0.067429</td>\n",
       "      <td>3.959921</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.080921</td>\n",
       "      <td>2.189551</td>\n",
       "      <td>[0.0339277908205986, 0.015157333575189114, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>9965|</td>\n",
       "      <td>380 136 783 16 556 698 313 66 432 449 208 415 ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322397</td>\n",
       "      <td>0.123913</td>\n",
       "      <td>0.044825</td>\n",
       "      <td>9.067583</td>\n",
       "      <td>0.073472</td>\n",
       "      <td>0.169565</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>3.232763</td>\n",
       "      <td>[0.04536737501621246, 0.04386813938617706, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9972|</td>\n",
       "      <td>852 328 328 380 172 487 391 693 210 514 569 71...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321239</td>\n",
       "      <td>0.084848</td>\n",
       "      <td>0.060129</td>\n",
       "      <td>5.022497</td>\n",
       "      <td>0.075687</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.025596</td>\n",
       "      <td>2.043555</td>\n",
       "      <td>[0.03291209787130356, 0.033716049045324326, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9975|</td>\n",
       "      <td>623 328 697 661 182 698 17 49 486 548 601 818 ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271722</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.045748</td>\n",
       "      <td>6.011042</td>\n",
       "      <td>0.073899</td>\n",
       "      <td>0.133903</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>2.586449</td>\n",
       "      <td>[1.0, 0.16065192222595215, 0.09659413248300552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>9976|</td>\n",
       "      <td>852 328 647 461 755 549 170 549 728 832 122</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200511</td>\n",
       "      <td>0.106173</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>1.526351</td>\n",
       "      <td>0.078597</td>\n",
       "      <td>0.142259</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.864563</td>\n",
       "      <td>[0.02550085075199604, 0.03326879441738129, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9983|</td>\n",
       "      <td>48 328 733 777 204 549 728 394 832 122 693 852...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>0.057386</td>\n",
       "      <td>8.565177</td>\n",
       "      <td>0.071617</td>\n",
       "      <td>0.161725</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>3.795677</td>\n",
       "      <td>[0.01746930181980133, 0.04129023477435112, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9985|</td>\n",
       "      <td>623 328 697 204 809 623 328 357 471 672 328 45...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066244</td>\n",
       "      <td>11.685032</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>0.024497</td>\n",
       "      <td>3.963548</td>\n",
       "      <td>[0.020824184641242027, 0.031393904238939285, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9988|</td>\n",
       "      <td>623 328 538 582 91 400 698 10 177 415 569 856 ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>8.592983</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.117192</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.024625</td>\n",
       "      <td>3.504436</td>\n",
       "      <td>[0.016151729971170425, 0.006156772840768099, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  \\\n",
       "0        0|  623 328 538 382 399 400 478 842 698 137 492 26...   \n",
       "4        4|  623 328 399 698 493 338 266 14 177 415 511 647...   \n",
       "5        5|  80 328 328 54 172 439 741 380 172 842 698 177 ...   \n",
       "7        7|  623 328 659 486 582 162 711 289 606 405 809 78...   \n",
       "14      14|  623 328 697 661 809 48 46 355 661 414 852 328 ...   \n",
       "21      21|  380 172 200 791 470 753 693 256 514 569 231 11...   \n",
       "27      27|  852 328 501 355 360 265 478 162 498 289 169 40...   \n",
       "31      31|  91 380 488 12 591 487 197 852 328 538 501 382 ...   \n",
       "35      35|  380 315 809 623 328 160 380 419 789 439 852 81...   \n",
       "41      41|  48 718 328 419 571 769 256 100 809 328 380 172...   \n",
       "48      48|  48 231 419 571 769 256 524 809 328 380 373 320...   \n",
       "51      51|  852 328 3 697 483 582 582 717 382 363 397 834 ...   \n",
       "59      59|  623 328 538 661 698 493 338 266 177 415 832 38...   \n",
       "61      61|  852 328 383 538 661 22 698 338 266 521 177 415...   \n",
       "62      62|  328 22 290 380 398 851 728 636 851 636 70 628 ...   \n",
       "69      69|  48 328 290 380 419 789 523 532 50 693 556 698 ...   \n",
       "72      72|  328 697 661 19 363 737 698 785 504 493 338 266...   \n",
       "75      75|  852 328 160 380 439 679 63 541 848 698 510 838...   \n",
       "76      76|  623 164 305 204 204 399 698 641 794 779 437 17...   \n",
       "90      90|  725 471 453 162 684 289 462 405 788 177 232 23...   \n",
       "91      91|  48 328 697 243 19 363 842 698 627 504 493 338 ...   \n",
       "97      97|  290 351 380 99 809 813 380 786 287 515 305 654...   \n",
       "98      98|  623 328 380 834 809 343 809 362 840 556 698 42...   \n",
       "101    101|  380 172 200 737 300 78 448 290 693 380 834 343...   \n",
       "107    107|  623 328 697 69 698 33 735 382 327 514 381 693 ...   \n",
       "115    115|  48 328 328 380 172 320 380 19 363 399 352 494 ...   \n",
       "116    116|  623 328 538 582 842 698 641 769 779 177 166 16...   \n",
       "120    120|  380 136 363 399 556 438 313 149 713 432 768 11...   \n",
       "124    124|  623 328 697 538 355 27 386 728 478 647 169 750...   \n",
       "128    128|  48 328 697 355 766 809 623 328 538 661 265 470...   \n",
       "...     ...                                                ...   \n",
       "9869  9869|  623 328 538 582 439 81 661 374 842 698 78 638 381   \n",
       "9871  9871|  478 333 390 636 276 698 116 71 712 620 381 693...   \n",
       "9882  9882|  91 382 569 231 556 698 313 66 432 449 693 664 ...   \n",
       "9883  9883|  623 657 320 786 399 851 636 374 698 516 149 26...   \n",
       "9895  9895|  48 328 380 834 809 343 698 177 415 832 468 25 ...   \n",
       "9900  9900|  623 328 328 380 172 470 651 394 596 502 340 37...   \n",
       "9905  9905|        247 305 461 204 698 162 498 289 177 415 381   \n",
       "9908  9908|  623 328 290 380 372 236 636 90 735 374 698 14 ...   \n",
       "9914  9914|  290 380 582 809 160 380 786 809 244 328 550 32...   \n",
       "9921  9921|  91 380 769 12 591 423 487 693 623 79 328 380 2...   \n",
       "9923  9923|  623 328 355 661 698 338 266 437 521 254 415 38...   \n",
       "9924  9924|  852 328 380 172 54 823 391 693 380 654 439 380...   \n",
       "9925  9925|  139 81 200 737 556 698 313 326 432 449 693 852...   \n",
       "9929  9929|  256 514 38 582 623 34 693 91 382 556 698 432 4...   \n",
       "9930  9930|  380 172 439 380 654 200 737 779 59 655 798 693...   \n",
       "9931  9931|  48 328 733 777 204 549 728 832 131 693 623 328...   \n",
       "9934  9934|  623 727 697 538 382 397 455 693 411 204 439 62...   \n",
       "9935  9935|  162 498 289 169 405 693 623 328 357 661 822 33...   \n",
       "9946  9946|  160 380 786 439 26 343 654 399 189 832 14 381 ...   \n",
       "9952  9952|  48 673 545 784 856 374 439 379 328 717 172 320...   \n",
       "9953  9953|  623 328 697 582 17 501 382 400 434 439 380 136...   \n",
       "9957  9957|  135 328 776 355 616 38 91 382 698 514 408 177 ...   \n",
       "9964  9964|  160 380 786 439 26 343 654 399 177 415 381 644...   \n",
       "9965  9965|  380 136 783 16 556 698 313 66 432 449 208 415 ...   \n",
       "9972  9972|  852 328 328 380 172 487 391 693 210 514 569 71...   \n",
       "9975  9975|  623 328 697 661 182 698 17 49 486 548 601 818 ...   \n",
       "9976  9976|        852 328 647 461 755 549 170 549 728 832 122   \n",
       "9983  9983|  48 328 733 777 204 549 728 394 832 122 693 852...   \n",
       "9985  9985|  623 328 697 204 809 623 328 357 471 672 328 45...   \n",
       "9988  9988|  623 328 538 582 91 400 698 10 177 415 569 856 ...   \n",
       "\n",
       "                                                  label  \\\n",
       "0     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "14    [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...   \n",
       "21    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "27    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "31    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "35    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "41    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "48    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "51    [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "59    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "61    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "62    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "69    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "72    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "75    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "76    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "90    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "91    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "97    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "98    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "101   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "107   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "115   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "116   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "120   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "124   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "128   [1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "9869  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9871  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9882  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9883  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9895  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9905  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9908  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9914  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9921  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9923  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9924  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9925  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "9929  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9930  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9931  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9934  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9935  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9946  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9952  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "9953  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9957  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9964  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9965  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "9972  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9975  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9976  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9983  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "9985  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "9988  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 label2  label_onehot_1  \\\n",
       "0     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "5     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "7     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "14    [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...               1   \n",
       "21    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "27    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "31    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "35    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...               0   \n",
       "41    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...               0   \n",
       "48    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...               0   \n",
       "51    [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...               0   \n",
       "59    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "61    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...               0   \n",
       "62    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...               0   \n",
       "69    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "72    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...               1   \n",
       "75    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...               0   \n",
       "76    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "90    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "91    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...               1   \n",
       "97    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "98    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...               0   \n",
       "101   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...               0   \n",
       "107   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "115   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "116   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "120   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "124   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "128   [1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...               1   \n",
       "...                                                 ...             ...   \n",
       "9869  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9871  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9882  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9883  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9895  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9905  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9908  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9914  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9921  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9923  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9924  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9925  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...               0   \n",
       "9929  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9930  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9931  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9934  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9935  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9946  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9952  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...               0   \n",
       "9953  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1   \n",
       "9957  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9964  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9965  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...               0   \n",
       "9972  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9975  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               1   \n",
       "9976  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "9983  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...               0   \n",
       "9985  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...               0   \n",
       "9988  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...               0   \n",
       "\n",
       "      label_onehot_2  label_onehot_3  label_onehot_4  label_onehot_5  \\\n",
       "0                  0               1               0               0   \n",
       "4                  0               0               0               0   \n",
       "5                  0               0               0               0   \n",
       "7                  0               0               0               0   \n",
       "14                 1               0               0               0   \n",
       "21                 0               0               0               0   \n",
       "27                 0               0               0               0   \n",
       "31                 0               0               0               0   \n",
       "35                 0               0               0               0   \n",
       "41                 0               0               0               1   \n",
       "48                 0               0               0               1   \n",
       "51                 0               0               0               0   \n",
       "59                 0               0               0               0   \n",
       "61                 0               0               0               0   \n",
       "62                 0               0               0               1   \n",
       "69                 0               0               0               0   \n",
       "72                 0               0               0               0   \n",
       "75                 0               0               0               0   \n",
       "76                 0               0               0               0   \n",
       "90                 0               0               0               0   \n",
       "91                 0               0               0               0   \n",
       "97                 0               0               0               0   \n",
       "98                 0               0               0               1   \n",
       "101                0               0               0               0   \n",
       "107                0               0               0               0   \n",
       "115                0               0               0               0   \n",
       "116                0               1               0               0   \n",
       "120                0               1               0               0   \n",
       "124                0               0               0               0   \n",
       "128                1               1               0               0   \n",
       "...              ...             ...             ...             ...   \n",
       "9869               0               1               0               0   \n",
       "9871               0               0               0               0   \n",
       "9882               0               0               0               0   \n",
       "9883               0               0               0               0   \n",
       "9895               0               0               0               0   \n",
       "9900               0               0               0               0   \n",
       "9905               0               0               0               0   \n",
       "9908               0               0               1               0   \n",
       "9914               0               0               0               0   \n",
       "9921               0               0               0               0   \n",
       "9923               1               0               0               0   \n",
       "9924               0               0               0               0   \n",
       "9925               0               0               0               0   \n",
       "9929               1               0               0               0   \n",
       "9930               0               1               0               0   \n",
       "9931               1               0               1               0   \n",
       "9934               0               0               0               0   \n",
       "9935               1               0               0               0   \n",
       "9946               0               0               0               0   \n",
       "9952               0               0               0               1   \n",
       "9953               0               0               1               0   \n",
       "9957               0               0               0               0   \n",
       "9964               0               0               0               0   \n",
       "9965               0               0               0               0   \n",
       "9972               0               0               0               0   \n",
       "9975               0               0               0               0   \n",
       "9976               0               0               0               0   \n",
       "9983               0               0               0               0   \n",
       "9985               0               0               0               0   \n",
       "9988               0               1               0               0   \n",
       "\n",
       "      label_onehot_6  ...  label_onehot_16_word_ctr_list_max_fea  \\\n",
       "0                  0  ...                               0.316399   \n",
       "4                  0  ...                               0.334732   \n",
       "5                  0  ...                               0.316399   \n",
       "7                  0  ...                               0.398872   \n",
       "14                 0  ...                               0.325301   \n",
       "21                 0  ...                               0.817647   \n",
       "27                 0  ...                               0.316399   \n",
       "31                 0  ...                               0.305085   \n",
       "35                 0  ...                               0.546296   \n",
       "41                 1  ...                               0.493888   \n",
       "48                 1  ...                               0.817647   \n",
       "51                 0  ...                               0.606383   \n",
       "59                 0  ...                               0.352657   \n",
       "61                 0  ...                               0.325301   \n",
       "62                 1  ...                               0.683656   \n",
       "69                 0  ...                               0.343124   \n",
       "72                 0  ...                               0.683656   \n",
       "75                 0  ...                               0.304364   \n",
       "76                 0  ...                               0.300000   \n",
       "90                 0  ...                               0.333333   \n",
       "91                 0  ...                               0.683656   \n",
       "97                 0  ...                               0.304364   \n",
       "98                 0  ...                               0.377049   \n",
       "101                0  ...                               0.391892   \n",
       "107                0  ...                               0.304364   \n",
       "115                0  ...                               0.817647   \n",
       "116                0  ...                               0.362429   \n",
       "120                0  ...                               0.334732   \n",
       "124                0  ...                               0.237288   \n",
       "128                0  ...                               0.398872   \n",
       "...              ...  ...                                    ...   \n",
       "9869               0  ...                               0.337484   \n",
       "9871               0  ...                               0.301375   \n",
       "9882               0  ...                               0.297806   \n",
       "9883               0  ...                               0.812925   \n",
       "9895               0  ...                               0.305085   \n",
       "9900               0  ...                               0.321239   \n",
       "9905               0  ...                               0.252688   \n",
       "9908               0  ...                               0.337484   \n",
       "9914               0  ...                               0.311203   \n",
       "9921               0  ...                               0.337484   \n",
       "9923               0  ...                               0.609890   \n",
       "9924               0  ...                               0.321239   \n",
       "9925               0  ...                               0.332155   \n",
       "9929               0  ...                               0.291737   \n",
       "9930               0  ...                               0.337484   \n",
       "9931               0  ...                               0.321239   \n",
       "9934               0  ...                               0.237473   \n",
       "9935               0  ...                               0.291737   \n",
       "9946               0  ...                               0.386792   \n",
       "9952               0  ...                               0.812925   \n",
       "9953               0  ...                               0.365854   \n",
       "9957               0  ...                               0.321239   \n",
       "9964               0  ...                               0.386792   \n",
       "9965               0  ...                               0.322397   \n",
       "9972               0  ...                               0.321239   \n",
       "9975               0  ...                               0.271722   \n",
       "9976               0  ...                               0.200511   \n",
       "9983               0  ...                               0.371163   \n",
       "9985               0  ...                               0.371163   \n",
       "9988               0  ...                               0.492754   \n",
       "\n",
       "      label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0                                  0.053208   \n",
       "4                                  0.069841   \n",
       "5                                  0.064815   \n",
       "7                                  0.078740   \n",
       "14                                 0.088875   \n",
       "21                                 0.088235   \n",
       "27                                 0.089118   \n",
       "31                                 0.088875   \n",
       "35                                 0.099237   \n",
       "41                                 0.053254   \n",
       "48                                 0.111111   \n",
       "51                                 0.120192   \n",
       "59                                 0.088875   \n",
       "61                                 0.088875   \n",
       "62                                 0.107692   \n",
       "69                                 0.125000   \n",
       "72                                 0.107692   \n",
       "75                                 0.062893   \n",
       "76                                 0.099237   \n",
       "90                                 0.062893   \n",
       "91                                 0.117378   \n",
       "97                                 0.095745   \n",
       "98                                 0.086580   \n",
       "101                                0.099237   \n",
       "107                                0.121429   \n",
       "115                                0.125000   \n",
       "116                                0.077151   \n",
       "120                                0.064815   \n",
       "124                                0.088875   \n",
       "128                                0.088875   \n",
       "...                                     ...   \n",
       "9869                               0.092010   \n",
       "9871                               0.094270   \n",
       "9882                               0.114410   \n",
       "9883                               0.094270   \n",
       "9895                               0.103865   \n",
       "9900                               0.095745   \n",
       "9905                               0.120027   \n",
       "9908                               0.112500   \n",
       "9914                               0.138889   \n",
       "9921                               0.084079   \n",
       "9923                               0.096354   \n",
       "9924                               0.084848   \n",
       "9925                               0.134109   \n",
       "9929                               0.114410   \n",
       "9930                               0.089147   \n",
       "9931                               0.106173   \n",
       "9934                               0.092317   \n",
       "9935                               0.131579   \n",
       "9946                               0.080756   \n",
       "9952                               0.114410   \n",
       "9953                               0.056748   \n",
       "9957                               0.114410   \n",
       "9964                               0.082883   \n",
       "9965                               0.123913   \n",
       "9972                               0.084848   \n",
       "9975                               0.089147   \n",
       "9976                               0.106173   \n",
       "9983                               0.062780   \n",
       "9985                               0.083333   \n",
       "9988                               0.053254   \n",
       "\n",
       "      label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                                  0.061719   \n",
       "4                                  0.060036   \n",
       "5                                  0.054437   \n",
       "7                                  0.061147   \n",
       "14                                 0.056875   \n",
       "21                                 0.108533   \n",
       "27                                 0.052943   \n",
       "31                                 0.052519   \n",
       "35                                 0.091041   \n",
       "41                                 0.072358   \n",
       "48                                 0.134315   \n",
       "51                                 0.073687   \n",
       "59                                 0.051193   \n",
       "61                                 0.047915   \n",
       "62                                 0.091417   \n",
       "69                                 0.055671   \n",
       "72                                 0.074819   \n",
       "75                                 0.047428   \n",
       "76                                 0.049546   \n",
       "90                                 0.055776   \n",
       "91                                 0.071979   \n",
       "97                                 0.042193   \n",
       "98                                 0.061702   \n",
       "101                                0.049861   \n",
       "107                                0.042955   \n",
       "115                                0.167109   \n",
       "116                                0.051910   \n",
       "120                                0.054618   \n",
       "124                                0.043072   \n",
       "128                                0.071236   \n",
       "...                                     ...   \n",
       "9869                               0.061312   \n",
       "9871                               0.047305   \n",
       "9882                               0.038020   \n",
       "9883                               0.131727   \n",
       "9895                               0.048809   \n",
       "9900                               0.051189   \n",
       "9905                               0.038412   \n",
       "9908                               0.050072   \n",
       "9914                               0.035254   \n",
       "9921                               0.060276   \n",
       "9923                               0.075584   \n",
       "9924                               0.050796   \n",
       "9925                               0.043066   \n",
       "9929                               0.041160   \n",
       "9930                               0.054445   \n",
       "9931                               0.048773   \n",
       "9934                               0.036079   \n",
       "9935                               0.044624   \n",
       "9946                               0.065845   \n",
       "9952                               0.091403   \n",
       "9953                               0.059975   \n",
       "9957                               0.054198   \n",
       "9964                               0.067429   \n",
       "9965                               0.044825   \n",
       "9972                               0.060129   \n",
       "9975                               0.045748   \n",
       "9976                               0.028885   \n",
       "9983                               0.057386   \n",
       "9985                               0.066244   \n",
       "9988                               0.073785   \n",
       "\n",
       "      label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                                  7.893109   \n",
       "4                                  4.161647   \n",
       "5                                  7.022088   \n",
       "7                                  7.747219   \n",
       "14                                 7.891675   \n",
       "21                                 7.688602   \n",
       "27                                10.974305   \n",
       "31                                 6.645423   \n",
       "35                                11.624503   \n",
       "41                                13.445610   \n",
       "48                                12.774244   \n",
       "51                                 9.570769   \n",
       "59                                12.648152   \n",
       "61                                10.361616   \n",
       "62                                15.931742   \n",
       "69                                 3.674850   \n",
       "72                                21.411595   \n",
       "75                                 7.930532   \n",
       "76                                 6.996279   \n",
       "90                                 7.087144   \n",
       "91                                18.239018   \n",
       "97                                11.667557   \n",
       "98                                12.099090   \n",
       "101                               14.445808   \n",
       "107                                3.853609   \n",
       "115                                5.888011   \n",
       "116                               19.765167   \n",
       "120                               11.443663   \n",
       "124                                3.808311   \n",
       "128                                9.033472   \n",
       "...                                     ...   \n",
       "9869                               2.401540   \n",
       "9871                               3.644913   \n",
       "9882                               3.647454   \n",
       "9883                               6.511711   \n",
       "9895                               4.413894   \n",
       "9900                               5.287198   \n",
       "9905                               1.946140   \n",
       "9908                               7.235424   \n",
       "9914                               5.703665   \n",
       "9921                               7.282553   \n",
       "9923                               8.637974   \n",
       "9924                               7.271281   \n",
       "9925                               3.924656   \n",
       "9929                               7.606663   \n",
       "9930                              15.292929   \n",
       "9931                               7.498455   \n",
       "9934                               3.087932   \n",
       "9935                               6.002796   \n",
       "9946                               6.805980   \n",
       "9952                              16.259537   \n",
       "9953                               7.202407   \n",
       "9957                               7.889937   \n",
       "9964                               3.959921   \n",
       "9965                               9.067583   \n",
       "9972                               5.022497   \n",
       "9975                               6.011042   \n",
       "9976                               1.526351   \n",
       "9983                               8.565177   \n",
       "9985                              11.685032   \n",
       "9988                               8.592983   \n",
       "\n",
       "      label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                   0.069383   \n",
       "4                                   0.084684   \n",
       "5                                   0.079598   \n",
       "7                                   0.082768   \n",
       "14                                  0.065703   \n",
       "21                                  0.083780   \n",
       "27                                  0.082929   \n",
       "31                                  0.086251   \n",
       "35                                  0.071593   \n",
       "41                                  0.077398   \n",
       "48                                  0.075250   \n",
       "51                                  0.084620   \n",
       "59                                  0.098406   \n",
       "61                                  0.076567   \n",
       "62                                  0.078171   \n",
       "69                                  0.101810   \n",
       "72                                  0.082822   \n",
       "75                                  0.093953   \n",
       "76                                  0.079554   \n",
       "90                                  0.080650   \n",
       "91                                  0.081869   \n",
       "97                                  0.110150   \n",
       "98                                  0.071605   \n",
       "101                                 0.077873   \n",
       "107                                 0.078262   \n",
       "115                                 0.083228   \n",
       "116                                 0.088272   \n",
       "120                                 0.078072   \n",
       "124                                 0.082115   \n",
       "128                                 0.064186   \n",
       "...                                      ...   \n",
       "9869                                0.071667   \n",
       "9871                                0.069964   \n",
       "9882                                0.072669   \n",
       "9883                                0.085298   \n",
       "9895                                0.078093   \n",
       "9900                                0.072548   \n",
       "9905                                0.092536   \n",
       "9908                                0.076459   \n",
       "9914                                0.113954   \n",
       "9921                                0.070658   \n",
       "9923                                0.071777   \n",
       "9924                                0.078499   \n",
       "9925                                0.071847   \n",
       "9929                                0.067378   \n",
       "9930                                0.075186   \n",
       "9931                                0.072123   \n",
       "9934                                0.078314   \n",
       "9935                                0.072851   \n",
       "9946                                0.099039   \n",
       "9952                                0.077958   \n",
       "9953                                0.086589   \n",
       "9957                                0.084184   \n",
       "9964                                0.115240   \n",
       "9965                                0.073472   \n",
       "9972                                0.075687   \n",
       "9975                                0.073899   \n",
       "9976                                0.078597   \n",
       "9983                                0.071617   \n",
       "9985                                0.068337   \n",
       "9988                                0.071519   \n",
       "\n",
       "      label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                                  0.153386   \n",
       "4                                  0.129310   \n",
       "5                                  0.135647   \n",
       "7                                  0.135647   \n",
       "14                                 0.147959   \n",
       "21                                 0.213592   \n",
       "27                                 0.153386   \n",
       "31                                 0.241199   \n",
       "35                                 0.171610   \n",
       "41                                 0.159763   \n",
       "48                                 0.213592   \n",
       "51                                 0.241199   \n",
       "59                                 0.420354   \n",
       "61                                 0.146924   \n",
       "62                                 0.241199   \n",
       "69                                 0.171610   \n",
       "72                                 0.164964   \n",
       "75                                 0.213740   \n",
       "76                                 0.153386   \n",
       "90                                 0.128655   \n",
       "91                                 0.164964   \n",
       "97                                 0.420354   \n",
       "98                                 0.164964   \n",
       "101                                0.164964   \n",
       "107                                0.159292   \n",
       "115                                0.133475   \n",
       "116                                0.241199   \n",
       "120                                0.146924   \n",
       "124                                0.153153   \n",
       "128                                0.133475   \n",
       "...                                     ...   \n",
       "9869                               0.112306   \n",
       "9871                               0.121622   \n",
       "9882                               0.116667   \n",
       "9883                               0.373444   \n",
       "9895                               0.148772   \n",
       "9900                               0.120835   \n",
       "9905                               0.338710   \n",
       "9908                               0.310734   \n",
       "9914                               0.373444   \n",
       "9921                               0.159091   \n",
       "9923                               0.161725   \n",
       "9924                               0.139394   \n",
       "9925                               0.112500   \n",
       "9929                               0.136228   \n",
       "9930                               0.148772   \n",
       "9931                               0.115896   \n",
       "9934                               0.127413   \n",
       "9935                               0.142857   \n",
       "9946                               0.373444   \n",
       "9952                               0.238994   \n",
       "9953                               0.310734   \n",
       "9957                               0.142857   \n",
       "9964                               0.373444   \n",
       "9965                               0.169565   \n",
       "9972                               0.148649   \n",
       "9975                               0.133903   \n",
       "9976                               0.142259   \n",
       "9983                               0.161725   \n",
       "9985                               0.148772   \n",
       "9988                               0.117192   \n",
       "\n",
       "      label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                                  0.009756   \n",
       "4                                  0.040923   \n",
       "5                                  0.038522   \n",
       "7                                  0.029412   \n",
       "14                                 0.020346   \n",
       "21                                 0.027059   \n",
       "27                                 0.042620   \n",
       "31                                 0.043796   \n",
       "35                                 0.011194   \n",
       "41                                 0.012225   \n",
       "48                                 0.012225   \n",
       "51                                 0.000000   \n",
       "59                                 0.020346   \n",
       "61                                 0.020346   \n",
       "62                                 0.014252   \n",
       "69                                 0.052069   \n",
       "72                                 0.000000   \n",
       "75                                 0.038522   \n",
       "76                                 0.030534   \n",
       "90                                 0.036585   \n",
       "91                                 0.038522   \n",
       "97                                 0.025974   \n",
       "98                                 0.009756   \n",
       "101                                0.020346   \n",
       "107                                0.044776   \n",
       "115                                0.027059   \n",
       "116                                0.025974   \n",
       "120                                0.024129   \n",
       "124                                0.042842   \n",
       "128                                0.009756   \n",
       "...                                     ...   \n",
       "9869                               0.017163   \n",
       "9871                               0.035088   \n",
       "9882                               0.054700   \n",
       "9883                               0.026077   \n",
       "9895                               0.031746   \n",
       "9900                               0.026316   \n",
       "9905                               0.050556   \n",
       "9908                               0.008299   \n",
       "9914                               0.050000   \n",
       "9921                               0.009681   \n",
       "9923                               0.009681   \n",
       "9924                               0.040925   \n",
       "9925                               0.037456   \n",
       "9929                               0.009681   \n",
       "9930                               0.009681   \n",
       "9931                               0.017163   \n",
       "9934                               0.045762   \n",
       "9935                               0.014963   \n",
       "9946                               0.037500   \n",
       "9952                               0.018401   \n",
       "9953                               0.045762   \n",
       "9957                               0.038072   \n",
       "9964                               0.043243   \n",
       "9965                               0.014760   \n",
       "9972                               0.015152   \n",
       "9975                               0.013793   \n",
       "9976                               0.049383   \n",
       "9983                               0.017163   \n",
       "9985                               0.013793   \n",
       "9988                               0.024096   \n",
       "\n",
       "      label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                                  0.029972   \n",
       "4                                  0.023791   \n",
       "5                                  0.024237   \n",
       "7                                  0.028315   \n",
       "14                                 0.026922   \n",
       "21                                 0.036084   \n",
       "27                                 0.022371   \n",
       "31                                 0.033514   \n",
       "35                                 0.028748   \n",
       "41                                 0.026776   \n",
       "48                                 0.034215   \n",
       "51                                 0.035909   \n",
       "59                                 0.062467   \n",
       "61                                 0.023959   \n",
       "62                                 0.040664   \n",
       "69                                 0.032770   \n",
       "72                                 0.028204   \n",
       "75                                 0.034209   \n",
       "76                                 0.026225   \n",
       "90                                 0.026191   \n",
       "91                                 0.025352   \n",
       "97                                 0.061464   \n",
       "98                                 0.032687   \n",
       "101                                0.025905   \n",
       "107                                0.023311   \n",
       "115                                0.029516   \n",
       "116                                0.031402   \n",
       "120                                0.027093   \n",
       "124                                0.032418   \n",
       "128                                0.026457   \n",
       "...                                     ...   \n",
       "9869                               0.023250   \n",
       "9871                               0.019864   \n",
       "9882                               0.018390   \n",
       "9883                               0.058396   \n",
       "9895                               0.028209   \n",
       "9900                               0.017582   \n",
       "9905                               0.078682   \n",
       "9908                               0.050948   \n",
       "9914                               0.062768   \n",
       "9921                               0.031291   \n",
       "9923                               0.031984   \n",
       "9924                               0.018190   \n",
       "9925                               0.019039   \n",
       "9929                               0.028328   \n",
       "9930                               0.029222   \n",
       "9931                               0.020573   \n",
       "9934                               0.022859   \n",
       "9935                               0.027207   \n",
       "9946                               0.063906   \n",
       "9952                               0.032525   \n",
       "9953                               0.045592   \n",
       "9957                               0.023586   \n",
       "9964                               0.080921   \n",
       "9965                               0.029699   \n",
       "9972                               0.025596   \n",
       "9975                               0.031257   \n",
       "9976                               0.023354   \n",
       "9983                               0.033119   \n",
       "9985                               0.024497   \n",
       "9988                               0.024625   \n",
       "\n",
       "      label_onehot_17_word_ctr_list_sum_fea  \\\n",
       "0                                  3.330386   \n",
       "4                                  1.863055   \n",
       "5                                  2.865540   \n",
       "7                                  3.559021   \n",
       "14                                 2.759523   \n",
       "21                                 3.267410   \n",
       "27                                 4.561104   \n",
       "31                                 3.105038   \n",
       "35                                 3.722838   \n",
       "41                                 4.798670   \n",
       "48                                 3.611987   \n",
       "51                                 4.061775   \n",
       "59                                 6.199551   \n",
       "61                                 4.058066   \n",
       "62                                 5.081112   \n",
       "69                                 1.628966   \n",
       "72                                 8.116511   \n",
       "75                                 3.664183   \n",
       "76                                 3.023063   \n",
       "90                                 2.984046   \n",
       "91                                 7.204490   \n",
       "97                                 6.168415   \n",
       "98                                 4.296322   \n",
       "101                                5.373257   \n",
       "107                                1.721771   \n",
       "115                                1.581325   \n",
       "116                                8.827220   \n",
       "120                                4.372006   \n",
       "124                                1.888649   \n",
       "128                                2.888355   \n",
       "...                                     ...   \n",
       "9869                               0.931667   \n",
       "9871                               1.469235   \n",
       "9882                               1.526059   \n",
       "9883                               2.558946   \n",
       "9895                               1.718037   \n",
       "9900                               1.958801   \n",
       "9905                               1.017899   \n",
       "9908                               2.752540   \n",
       "9914                               2.962808   \n",
       "9921                               2.826317   \n",
       "9923                               3.014622   \n",
       "9924                               3.061474   \n",
       "9925                               1.436946   \n",
       "9929                               2.560350   \n",
       "9930                               5.789292   \n",
       "9931                               2.740680   \n",
       "9934                               1.566289   \n",
       "9935                               2.185532   \n",
       "9946                               3.466371   \n",
       "9952                               5.535034   \n",
       "9953                               3.290368   \n",
       "9957                               3.030628   \n",
       "9964                               2.189551   \n",
       "9965                               3.232763   \n",
       "9972                               2.043555   \n",
       "9975                               2.586449   \n",
       "9976                               0.864563   \n",
       "9983                               3.795677   \n",
       "9985                               3.963548   \n",
       "9988                               3.504436   \n",
       "\n",
       "                                                   prob  \n",
       "0     [0.0028005423955619335, 0.0076747918501496315,...  \n",
       "4     [0.0012862442526966333, 0.007899697870016098, ...  \n",
       "5     [0.004175003618001938, 0.004221336916089058, 0...  \n",
       "7     [0.00320462416857481, 0.0036855146754533052, 0...  \n",
       "14    [0.9999947547912598, 1.0, 0.009344044141471386...  \n",
       "21    [0.003285845974460244, 0.004417122341692448, 0...  \n",
       "27    [0.0022288879845291376, 0.002418902702629566, ...  \n",
       "31    [0.0037080259062349796, 0.003557736985385418, ...  \n",
       "35    [0.0013001956976950169, 0.004078374244272709, ...  \n",
       "41    [0.00013342891179490834, 0.0001463307853555306...  \n",
       "48    [0.00019667034212034196, 0.0001271027722395956...  \n",
       "51    [0.0017424769466742873, 0.009933008812367916, ...  \n",
       "59    [0.0023305437061935663, 0.0031611761078238487,...  \n",
       "61    [0.003944179508835077, 0.007959757931530476, 0...  \n",
       "62    [0.00015689046995248646, 0.0001928202545968815...  \n",
       "69    [0.0021400004625320435, 0.0035199911799281836,...  \n",
       "72    [1.0, 0.001229653600603342, 0.0036125583574175...  \n",
       "75    [0.0002591898664832115, 0.0007651884225197136,...  \n",
       "76    [0.0025879545137286186, 0.0039453040808439255,...  \n",
       "90    [0.002920850645750761, 0.0044312505051493645, ...  \n",
       "91    [1.0, 0.008882715366780758, 0.0032057776115834...  \n",
       "97    [0.001932140439748764, 0.003069933271035552, 0...  \n",
       "98    [0.004211496561765671, 0.005881054326891899, 0...  \n",
       "101   [0.011942751705646515, 0.014644548296928406, 0...  \n",
       "107   [0.003337035421282053, 0.0033456122037023306, ...  \n",
       "115   [0.002847346942871809, 0.00308043509721756, 0....  \n",
       "116   [0.001564481994137168, 0.00918856542557478, 1....  \n",
       "120   [0.0021932879462838173, 0.0056733014062047005,...  \n",
       "124   [0.0043333470821380615, 0.0035896128974854946,...  \n",
       "128   [1.0, 1.0, 1.0, 0.14246928691864014, 0.0012420...  \n",
       "...                                                 ...  \n",
       "9869  [0.1602904498577118, 0.022107252851128578, 1.0...  \n",
       "9871  [0.03574756905436516, 0.026403557509183884, 0....  \n",
       "9882  [0.038853686302900314, 0.02297392673790455, 0....  \n",
       "9883  [0.024663055315613747, 0.017592065036296844, 0...  \n",
       "9895  [0.007288849446922541, 0.01736750826239586, 0....  \n",
       "9900  [0.04298226907849312, 0.038915395736694336, 0....  \n",
       "9905  [0.04486940801143646, 0.03844381868839264, 0.0...  \n",
       "9908  [0.04112799093127251, 0.0010431066621094942, 0...  \n",
       "9914  [0.0027669889386743307, 0.0056350030936300755,...  \n",
       "9921  [0.061021022498607635, 0.13621199131011963, 0....  \n",
       "9923  [0.040380824357271194, 1.0, 0.0296803265810012...  \n",
       "9924  [0.03418154641985893, 0.028990620747208595, 0....  \n",
       "9925  [0.03763478994369507, 0.03385389596223831, 0.0...  \n",
       "9929  [0.191211998462677, 1.0, 0.014529337175190449,...  \n",
       "9930  [0.010188275016844273, 0.006628052331507206, 1...  \n",
       "9931  [0.06826052814722061, 1.0, 0.00065556756453588...  \n",
       "9934  [0.043339379131793976, 0.03707332909107208, 0....  \n",
       "9935  [0.26044851541519165, 0.23536370694637299, 0.1...  \n",
       "9946  [0.03880390152335167, 0.018888194113969803, 0....  \n",
       "9952  [0.019613750278949738, 0.009316817857325077, 0...  \n",
       "9953  [0.9999983310699463, 0.006364456843584776, 0.0...  \n",
       "9957  [0.018360840156674385, 0.049435317516326904, 0...  \n",
       "9964  [0.0339277908205986, 0.015157333575189114, 0.0...  \n",
       "9965  [0.04536737501621246, 0.04386813938617706, 0.0...  \n",
       "9972  [0.03291209787130356, 0.033716049045324326, 0....  \n",
       "9975  [1.0, 0.16065192222595215, 0.09659413248300552...  \n",
       "9976  [0.02550085075199604, 0.03326879441738129, 0.0...  \n",
       "9983  [0.01746930181980133, 0.04129023477435112, 0.0...  \n",
       "9985  [0.020824184641242027, 0.031393904238939285, 0...  \n",
       "9988  [0.016151729971170425, 0.006156772840768099, 1...  \n",
       "\n",
       "[10000 rows x 108 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:06.920908Z",
     "start_time": "2021-03-27T04:08:05.220821Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_train['score'] = oof_train.apply(lambda x:ss_score(x.label,x.prob)[1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:06.948360Z",
     "start_time": "2021-03-27T04:08:06.922379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95933291015625\n"
     ]
    }
   ],
   "source": [
    "oof_score = oof_train.score.mean()\n",
    "print(oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:07.982698Z",
     "start_time": "2021-03-27T04:08:07.951357Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "h7Mv4gKCDBfx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_onehot_1_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_min_fea</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "      <th>label</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>0.393008</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>4.122316</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.058020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>2.555291</td>\n",
       "      <td></td>\n",
       "      <td>[0.00797245861031115, 0.013774707075208425, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>3.501624</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>6.358730</td>\n",
       "      <td>0.087905</td>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>2.725062</td>\n",
       "      <td></td>\n",
       "      <td>[0.012245426326990128, 0.016009846050292254, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>0.124938</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>2.373818</td>\n",
       "      <td>0.131235</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>3.788926</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>0.241986</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>1.783205</td>\n",
       "      <td></td>\n",
       "      <td>[0.0040807744022458795, 0.006838956056162715, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.423272</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>8.067832</td>\n",
       "      <td>0.131398</td>\n",
       "      <td>0.338954</td>\n",
       "      <td>0.046332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.069743</td>\n",
       "      <td>12.619198</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.152263</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>4.690812</td>\n",
       "      <td></td>\n",
       "      <td>[0.21206430047750474, 0.02738276617601514, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>0.230356</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>5.039707</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054931</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>7.241030</td>\n",
       "      <td>0.078502</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>3.218583</td>\n",
       "      <td></td>\n",
       "      <td>[0.03910873774439096, 0.029323529871180653, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text  \\\n",
       "0    0|  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1    1|  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2    2|  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3    3|  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4    4|  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_mean_fea  \\\n",
       "0                               0.124919   \n",
       "1                               0.112956   \n",
       "2                               0.124938   \n",
       "3                               0.130126   \n",
       "4                               0.122920   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_max_fea  label_onehot_1_word_ctr_list_min_fea  \\\n",
       "0                              0.393008                              0.054608   \n",
       "1                              0.197067                              0.079536   \n",
       "2                              0.224359                              0.062696   \n",
       "3                              0.423272                              0.052124   \n",
       "4                              0.230356                              0.045000   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_std_fea  label_onehot_1_word_ctr_list_sum_fea  \\\n",
       "0                              0.079149                              4.122316   \n",
       "1                              0.021437                              3.501624   \n",
       "2                              0.039191                              2.373818   \n",
       "3                              0.051302                              8.067832   \n",
       "4                              0.041414                              5.039707   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_mean_fea  \\\n",
       "0                               0.127946   \n",
       "1                               0.108086   \n",
       "2                               0.131235   \n",
       "3                               0.131398   \n",
       "4                               0.137787   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_max_fea  label_onehot_2_word_ctr_list_min_fea  \\\n",
       "0                              0.403226                              0.058020   \n",
       "1                              0.158730                              0.064725   \n",
       "2                              0.224359                              0.078652   \n",
       "3                              0.338954                              0.046332   \n",
       "4                              0.403226                              0.071305   \n",
       "\n",
       "   ...  label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0  ...                               0.089904   \n",
       "1  ...                               0.159265   \n",
       "2  ...                               0.100313   \n",
       "3  ...                               0.089904   \n",
       "4  ...                               0.054931   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                               0.042000   \n",
       "1                               0.034133   \n",
       "2                               0.092820   \n",
       "3                               0.069743   \n",
       "4                               0.057410   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                               5.529130   \n",
       "1                               6.358730   \n",
       "2                               3.788926   \n",
       "3                              12.619198   \n",
       "4                               7.241030   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                0.077433   \n",
       "1                                0.087905   \n",
       "2                                0.093853   \n",
       "3                                0.075658   \n",
       "4                                0.078502   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                               0.147368   \n",
       "1                               0.156806   \n",
       "2                               0.241986   \n",
       "3                               0.152263   \n",
       "4                               0.147368   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                               0.038760   \n",
       "1                               0.041667   \n",
       "2                               0.029197   \n",
       "3                               0.015444   \n",
       "4                               0.017427   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                               0.028777   \n",
       "1                               0.030928   \n",
       "2                               0.044474   \n",
       "3                               0.025709   \n",
       "4                               0.023886   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_sum_fea  label  \\\n",
       "0                               2.555291          \n",
       "1                               2.725062          \n",
       "2                               1.783205          \n",
       "3                               4.690812          \n",
       "4                               3.218583          \n",
       "\n",
       "                                                   2  \n",
       "0  [0.00797245861031115, 0.013774707075208425, 0....  \n",
       "1  [0.012245426326990128, 0.016009846050292254, 0...  \n",
       "2  [0.0040807744022458795, 0.006838956056162715, ...  \n",
       "3  [0.21206430047750474, 0.02738276617601514, 0.0...  \n",
       "4  [0.03910873774439096, 0.029323529871180653, 0....  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[2] = m\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:32.432503Z",
     "start_time": "2021-03-27T04:08:32.393607Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "IybR8dA8N1I4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label_onehot_1_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_1_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_2_word_ctr_list_min_fea</th>\n",
       "      <th>...</th>\n",
       "      <th>label_onehot_16_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_16_word_ctr_list_sum_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_mean_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_max_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_min_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_std_fea</th>\n",
       "      <th>label_onehot_17_word_ctr_list_sum_fea</th>\n",
       "      <th>label</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>0.393008</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>4.122316</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.058020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>2.555291</td>\n",
       "      <td></td>\n",
       "      <td>[0.00797245861031115, 0.013774707075208425, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>0.197067</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>3.501624</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159265</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>6.358730</td>\n",
       "      <td>0.087905</td>\n",
       "      <td>0.156806</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>2.725062</td>\n",
       "      <td></td>\n",
       "      <td>[0.012245426326990128, 0.016009846050292254, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>0.124938</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>2.373818</td>\n",
       "      <td>0.131235</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>3.788926</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>0.241986</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>1.783205</td>\n",
       "      <td></td>\n",
       "      <td>[0.0040807744022458795, 0.006838956056162715, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.423272</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>8.067832</td>\n",
       "      <td>0.131398</td>\n",
       "      <td>0.338954</td>\n",
       "      <td>0.046332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.069743</td>\n",
       "      <td>12.619198</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.152263</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>4.690812</td>\n",
       "      <td></td>\n",
       "      <td>[0.21206430047750474, 0.02738276617601514, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>0.230356</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>5.039707</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.071305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054931</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>7.241030</td>\n",
       "      <td>0.078502</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>3.218583</td>\n",
       "      <td></td>\n",
       "      <td>[0.03910873774439096, 0.029323529871180653, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                               text  \\\n",
       "0     0  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1     1  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2     2  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3     3  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4     4  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_mean_fea  \\\n",
       "0                               0.124919   \n",
       "1                               0.112956   \n",
       "2                               0.124938   \n",
       "3                               0.130126   \n",
       "4                               0.122920   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_max_fea  label_onehot_1_word_ctr_list_min_fea  \\\n",
       "0                              0.393008                              0.054608   \n",
       "1                              0.197067                              0.079536   \n",
       "2                              0.224359                              0.062696   \n",
       "3                              0.423272                              0.052124   \n",
       "4                              0.230356                              0.045000   \n",
       "\n",
       "   label_onehot_1_word_ctr_list_std_fea  label_onehot_1_word_ctr_list_sum_fea  \\\n",
       "0                              0.079149                              4.122316   \n",
       "1                              0.021437                              3.501624   \n",
       "2                              0.039191                              2.373818   \n",
       "3                              0.051302                              8.067832   \n",
       "4                              0.041414                              5.039707   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_mean_fea  \\\n",
       "0                               0.127946   \n",
       "1                               0.108086   \n",
       "2                               0.131235   \n",
       "3                               0.131398   \n",
       "4                               0.137787   \n",
       "\n",
       "   label_onehot_2_word_ctr_list_max_fea  label_onehot_2_word_ctr_list_min_fea  \\\n",
       "0                              0.403226                              0.058020   \n",
       "1                              0.158730                              0.064725   \n",
       "2                              0.224359                              0.078652   \n",
       "3                              0.338954                              0.046332   \n",
       "4                              0.403226                              0.071305   \n",
       "\n",
       "   ...  label_onehot_16_word_ctr_list_min_fea  \\\n",
       "0  ...                               0.089904   \n",
       "1  ...                               0.159265   \n",
       "2  ...                               0.100313   \n",
       "3  ...                               0.089904   \n",
       "4  ...                               0.054931   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_std_fea  \\\n",
       "0                               0.042000   \n",
       "1                               0.034133   \n",
       "2                               0.092820   \n",
       "3                               0.069743   \n",
       "4                               0.057410   \n",
       "\n",
       "   label_onehot_16_word_ctr_list_sum_fea  \\\n",
       "0                               5.529130   \n",
       "1                               6.358730   \n",
       "2                               3.788926   \n",
       "3                              12.619198   \n",
       "4                               7.241030   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_mean_fea  \\\n",
       "0                                0.077433   \n",
       "1                                0.087905   \n",
       "2                                0.093853   \n",
       "3                                0.075658   \n",
       "4                                0.078502   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_max_fea  \\\n",
       "0                               0.147368   \n",
       "1                               0.156806   \n",
       "2                               0.241986   \n",
       "3                               0.152263   \n",
       "4                               0.147368   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_min_fea  \\\n",
       "0                               0.038760   \n",
       "1                               0.041667   \n",
       "2                               0.029197   \n",
       "3                               0.015444   \n",
       "4                               0.017427   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_std_fea  \\\n",
       "0                               0.028777   \n",
       "1                               0.030928   \n",
       "2                               0.044474   \n",
       "3                               0.025709   \n",
       "4                               0.023886   \n",
       "\n",
       "   label_onehot_17_word_ctr_list_sum_fea  label  \\\n",
       "0                               2.555291          \n",
       "1                               2.725062          \n",
       "2                               1.783205          \n",
       "3                               4.690812          \n",
       "4                               3.218583          \n",
       "\n",
       "                                                   2  \n",
       "0  [0.00797245861031115, 0.013774707075208425, 0....  \n",
       "1  [0.012245426326990128, 0.016009846050292254, 0...  \n",
       "2  [0.0040807744022458795, 0.006838956056162715, ...  \n",
       "3  [0.21206430047750474, 0.02738276617601514, 0.0...  \n",
       "4  [0.03910873774439096, 0.029323529871180653, 0....  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['index']=test_df['index'].apply(lambda x:x[:-1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:43.921053Z",
     "start_time": "2021-03-27T04:08:43.849690Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "awVBkOVKPRNE"
   },
   "outputs": [],
   "source": [
    "sub_id=test_df['index'].values\n",
    "pres_all = sub.tolist()\n",
    "str_w=''\n",
    "with open(f'{save_path}/submit_{oof_score}.csv','w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        pres_fold = pres_all[i]\n",
    "        pres_fold=[str(p) for p in pres_fold]\n",
    "        prob = \" \".join(pres_fold)\n",
    "        str_w+=sub_id[i]+'|'+','+'|'+prob+'\\n'\n",
    "    str_w=str_w.strip('\\n')\n",
    "    f.write(str_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T04:08:49.821704Z",
     "start_time": "2021-03-27T04:08:46.176430Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "mirMQlPPmHNI"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(f\"{save_path}/oof_test_{score}.csv\")\n",
    "oof_train.to_csv(f\"{save_path}/oof_train_{score}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BMxuk94uvEhw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_transformers_gpu_macbert_model-多标签分类v2.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
