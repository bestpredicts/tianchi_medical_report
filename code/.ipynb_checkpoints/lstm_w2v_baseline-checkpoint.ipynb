{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:35.924968Z",
     "start_time": "2021-03-19T01:17:35.798705Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11830,
     "status": "ok",
     "timestamp": 1614770513449,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "O7WFLSg4DPma",
    "outputId": "76c70351-b51f-436e-d398-da17cceb9fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            251          11         146           0          92         237\r\n",
      "Swap:             1           0           1\r\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.004750Z",
     "start_time": "2021-03-19T01:17:35.928871Z"
    },
    "executionInfo": {
     "elapsed": 54243,
     "status": "ok",
     "timestamp": 1614770555888,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "9yok51vCDoWl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.050010Z",
     "start_time": "2021-03-19T01:17:39.006975Z"
    },
    "executionInfo": {
     "elapsed": 54246,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "VpFla5NVPayv"
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/track1_round1_train_20210222.csv\"\n",
    "test_path = \"../input/track1_round1_testA_20210222.csv\"\n",
    "train_df = pd.read_csv(train_path,sep=',',header=None)\n",
    "test_df = pd.read_csv(test_path,sep=',',header=None)\n",
    "\n",
    "train_df[1]=train_df[1].apply(lambda x:x[1:-1])\n",
    "train_df[2]=train_df[2].apply(lambda x:x[1:])\n",
    "\n",
    "test_df[1] = test_df[1].apply(lambda x:x[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.107217Z",
     "start_time": "2021-03-19T01:17:39.051867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "train_df.drop_duplicates(subset=[1,2],inplace=True)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.119742Z",
     "start_time": "2021-03-19T01:17:39.108437Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 54241,
     "status": "ok",
     "timestamp": 1614770555897,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "f1GQc7JFDz46",
    "outputId": "d7609944-c200-4d73-8906-f31cb906c7c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6|</td>\n",
       "      <td>48 322 795 856 374 439 48 328 443 380 597 172 ...</td>\n",
       "      <td>4 11 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8|</td>\n",
       "      <td>852 328 471 585 117 458 399 607 693 380 522 62...</td>\n",
       "      <td>6 12 14 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9|</td>\n",
       "      <td>229 172 200 737 437 547 651 693 623 328 355 65...</td>\n",
       "      <td>1 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10|</td>\n",
       "      <td>852 328 305 461 71 413 728 479 122 693 697 382...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11|</td>\n",
       "      <td>697 582 439 48 328 755 355 582 617 265 478 162...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12|</td>\n",
       "      <td>380 315 177 415 145 755 693 698 521 177 415 38...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13|</td>\n",
       "      <td>811 328 538 845 832 122 693 788 579 460 787 95...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15|</td>\n",
       "      <td>111 328 213 661 542 265 363 145 424 490 693 66...</td>\n",
       "      <td>10 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16|</td>\n",
       "      <td>543 328 328 380 197 320 698 160 338 14 177 415...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17|</td>\n",
       "      <td>380 172 551 737 221 290 480 171 514 569 231 11...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18|</td>\n",
       "      <td>623 328 204 461 851 842 698 549 81 832 122 693...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19|</td>\n",
       "      <td>358 380 616 363 399 556 698 313 66 432 449 133...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1            2\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...           2 \n",
       "1    1|  48 328 538 382 809 623 434 355 382 382 363 145...             \n",
       "2    2|  623 656 293 851 636 842 698 493 338 266 369 69...          15 \n",
       "3    3|  48 328 380 259 439 107 380 265 172 470 290 693...             \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...          16 \n",
       "5    5|  80 328 328 54 172 439 741 380 172 842 698 177 ...          15 \n",
       "6    6|  48 322 795 856 374 439 48 328 443 380 597 172 ...     4 11 15 \n",
       "7    7|  623 328 659 486 582 162 711 289 606 405 809 78...             \n",
       "8    8|  852 328 471 585 117 458 399 607 693 380 522 62...  6 12 14 15 \n",
       "9    9|  229 172 200 737 437 547 651 693 623 328 355 65...         1 3 \n",
       "10  10|  852 328 305 461 71 413 728 479 122 693 697 382...             \n",
       "11  11|  697 582 439 48 328 755 355 582 617 265 478 162...          15 \n",
       "12  12|  380 315 177 415 145 755 693 698 521 177 415 38...          14 \n",
       "13  13|  811 328 538 845 832 122 693 788 579 460 787 95...             \n",
       "14  14|  623 328 697 661 809 48 46 355 661 414 852 328 ...    0 1 8 10 \n",
       "15  15|  111 328 213 661 542 265 363 145 424 490 693 66...       10 15 \n",
       "16  16|  543 328 328 380 197 320 698 160 338 14 177 415...          15 \n",
       "17  17|  380 172 551 737 221 290 480 171 514 569 231 11...             \n",
       "18  18|  623 328 204 461 851 842 698 549 81 832 122 693...          16 \n",
       "19  19|  358 380 616 363 399 556 698 313 66 432 449 133...             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.125753Z",
     "start_time": "2021-03-19T01:17:39.121209Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 54233,
     "status": "ok",
     "timestamp": 1614770555898,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "ESC_TLmo236c",
    "outputId": "c6dbcd8b-794b-49bc-a0fc-b4d7b8dfab44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1\n",
       "0  0|  852 328 697 538 142 355 582 800 728 4 647 169 ...\n",
       "1  1|  380 358 343 654 171 832 47 832 690 693 48 563 ...\n",
       "2  2|  751 335 834 582 717 583 585 693 623 328 107 38...\n",
       "3  3|  623 328 649 582 488 12 578 623 538 382 382 265...\n",
       "4  4|  83 293 398 797 382 363 145 424 693 698 800 691..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.128813Z",
     "start_time": "2021-03-19T01:17:39.126911Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.135087Z",
     "start_time": "2021-03-19T01:17:39.130613Z"
    },
    "executionInfo": {
     "elapsed": 54231,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AP7PUpB6FjDo"
   },
   "outputs": [],
   "source": [
    "def data_aug(df):\n",
    "    \n",
    "    import random\n",
    "    df = df.copy()\n",
    "    df[2]=df[2].apply(lambda x:x.split())\n",
    "    new_df = df.copy()\n",
    "    m =  shuffle(df)\n",
    "    m.reset_index(drop=True,inplace=True)\n",
    "    new_df[0]=100000\n",
    "    new_df[1] = new_df[1]+m[1]\n",
    "    new_df[2] = new_df[2]+m[2]\n",
    "    new_df[2]=new_df[2].apply(lambda x:\" \".join(list(set(x))))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.163440Z",
     "start_time": "2021-03-19T01:17:39.136661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.utils.data\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"F-score is ill-defined and being set to 0.0 due to no predicted samples.\")\n",
    "import re\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.398478Z",
     "start_time": "2021-03-19T01:17:39.164621Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_df,test_df])\n",
    "max_features = 1000\n",
    "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "full_text = list(data[1].values)\n",
    "tk.fit_on_texts(full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.402665Z",
     "start_time": "2021-03-19T01:17:39.399704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.410917Z",
     "start_time": "2021-03-19T01:17:39.403986Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "class config:\n",
    "    TOKENIZER = tk\n",
    "    MAX_LEN = 100\n",
    "\n",
    "\n",
    "class TextDataset:\n",
    "    def __init__(self,text1, target):\n",
    "        self.text1 = text1\n",
    "        self.target = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_length = config.MAX_LEN\n",
    "        self.text1 =  tk.texts_to_sequences(self.text1)\n",
    "        self.text1 =  pad_sequences(self.text1, maxlen = self.max_length ,padding='post')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text1)\n",
    "\n",
    "    def get_dumm(self,s):\n",
    "\n",
    "        re=[0]*17\n",
    "        if s=='' or s==\" \":\n",
    "            return re\n",
    "        else:\n",
    "            tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "            for i in tmp:\n",
    "                re[i]=1\n",
    "        return re\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        input_ids = self.text1[item]\n",
    "        label = self.target[item]\n",
    "        label=self.get_dumm(label)\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(label, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.414270Z",
     "start_time": "2021-03-19T01:17:39.412086Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = TextDataset(train_df[1].tolist(),train_df[2].tolist())\n",
    "# train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSl04MfxtWup"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.435033Z",
     "start_time": "2021-03-19T01:17:39.415638Z"
    },
    "executionInfo": {
     "elapsed": 54219,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "CJQFASGKswVR"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_param_size(model, trainable=True):\n",
    "    if trainable:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return psize\n",
    "\n",
    "# https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856\n",
    "class EMA():\n",
    "    def __init__(self, model, mu, level='batch', n=1):\n",
    "        \"\"\"\n",
    "        level: 'batch' or 'epoch'\n",
    "          'batch': Update params every n batches.\n",
    "          'epoch': Update params every epoch.\n",
    "        \"\"\"\n",
    "        # self.ema_model = copy.deepcopy(model)\n",
    "        self.mu = mu\n",
    "        self.level = level\n",
    "        self.n = n\n",
    "        self.cnt = self.n\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data\n",
    "\n",
    "    def _update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1 - self.mu) * param.data + self.mu * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def set_weights(self, ema_model):\n",
    "        for name, param in ema_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def on_batch_end(self, model):\n",
    "        if self.level is 'batch':\n",
    "            self.cnt -= 1\n",
    "            if self.cnt == 0:\n",
    "                self._update(model)\n",
    "                self.cnt = self.n\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.level is 'epoch':\n",
    "            self._update(model)\n",
    "\n",
    "\n",
    "class GlobalMaxPooling1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPooling1D, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z, _ = torch.max(inputs, 1)\n",
    "        return z\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "drop_last = True\n",
    "\n",
    "hidden_dim = 128\n",
    "\n",
    "# Embedding\n",
    "fix_embedding = True\n",
    "unk_uni = True  # Initializer for unknown words\n",
    "n_embed = 2\n",
    "embed_dim = n_embed * 300\n",
    "proj_dim = hidden_dim\n",
    "\n",
    "# GRU\n",
    "bidirectional = True\n",
    "n_layers = 1\n",
    "rnn_dim = hidden_dim\n",
    "\n",
    "# The second last Linear layer\n",
    "dense_dim = 2 * rnn_dim if bidirectional else rnn_dim\n",
    "\n",
    "# EMA\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_dim=300, proj_dim=128, rnn_dim=128, n_layers=1, bidirectional=True, dense_dim=256,\n",
    "                 padding_idx=0, pretrained_embedding=None, fix_embedding=True,\n",
    "                 n_out=17):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.n_vocab = n_vocab\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dense_dim = dense_dim\n",
    "        self.n_out = n_out\n",
    "        self.bidirectional = bidirectional\n",
    "        self.fix_embedding = fix_embedding\n",
    "        self.padding_idx = padding_idx\n",
    "        if pretrained_embedding is not None:\n",
    "            self.embed = nn.Embedding.from_pretrained(pretrained_embedding, freeze=fix_embedding)\n",
    "            self.embed.padding_idx = self.padding_idx\n",
    "        else:\n",
    "            self.embed = nn.Embedding(self.n_vocab, self.embed_dim, padding_idx=self.padding_idx)\n",
    "        self.proj = nn.Linear(embed_dim, proj_dim)\n",
    "        self.proj_act = nn.ReLU()\n",
    "        self.gru = nn.GRU(proj_dim, rnn_dim, self.n_layers,\n",
    "                          batch_first=True, bidirectional=bidirectional)\n",
    "        self.pooling = GlobalMaxPooling1D()\n",
    "        in_dim = 2 * rnn_dim if self.bidirectional else rnn_dim\n",
    "        self.dense = nn.Linear(in_dim, dense_dim)\n",
    "        self.dense_act = nn.ReLU()\n",
    "        self.out_linear = nn.Linear(dense_dim, n_out)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.find('embed') > -1:\n",
    "                continue\n",
    "            elif name.find('weight') > -1 and len(param.size()) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: (bs, max_len)\n",
    "        x = self.embed(inputs)\n",
    "        x = self.proj_act(self.proj(x))\n",
    "        x, hidden = self.gru(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.dense_act(self.dense(x))\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.499254Z",
     "start_time": "2021-03-19T01:17:39.436205Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embed_size = 300\n",
    "embedding_path = \"w2v_emb.txt\"\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
    "# all_embs = np.stack(embedding_index.values())\n",
    "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std = -0.005838499, 0.48782197\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.502372Z",
     "start_time": "2021-03-19T01:17:39.500444Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_vocab = len(tk.index_word)\n",
    "# model = GRUModel(n_vocab=n_vocab,pretrained_embedding=torch.tensor(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.513450Z",
     "start_time": "2021-03-19T01:17:39.503661Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "BMxuk94uvEhw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_fn(model, dataloader, optimizer, criterion, epoch_number, max_gradient_norm):\n",
    "    \"\"\"\n",
    "    Train a model for one epoch on some input data with a given optimizer and\n",
    "    criterion.\n",
    "    Args:\n",
    "        model: A torch module that must be trained on some input data.\n",
    "        dataloader: A DataLoader object to iterate over the training data.\n",
    "        optimizer: A torch optimizer to use for training on the input model.\n",
    "        criterion: A loss criterion to use for training.\n",
    "        epoch_number: The number of the epoch for which training is performed.\n",
    "        max_gradient_norm: Max. norm for gradient norm clipping.\n",
    "    Returns:\n",
    "        epoch_time: The total time necessary to train the epoch.\n",
    "        epoch_loss: The training loss computed for the epoch.\n",
    "        epoch_accuracy: The accuracy computed for the epoch.\n",
    "    \"\"\"\n",
    "    # Switch the model to train mode.\n",
    "    model.train()\n",
    "    epoch_start = time.time()\n",
    "    batch_time_avg = 0.0\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    tqdm_batch_iterator = tqdm(dataloader)\n",
    "    for batch_index, d  in enumerate(tqdm_batch_iterator):\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        ids = d[\"ids\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "        batch_time_avg += time.time() - batch_start\n",
    "        running_loss += loss.item()\n",
    "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
    "                      .format(batch_time_avg/(batch_index+1), running_loss/(batch_index+1))\n",
    "        tqdm_batch_iterator.set_description(description)\n",
    "        \n",
    "        \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_time, epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            outputs = model(ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.571352Z",
     "start_time": "2021-03-19T01:17:39.514619Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "test_df[2]=\"\"\n",
    "test_dataset = TextDataset(test_df[1].tolist(),test_df[2].tolist())\n",
    "config.VALID_BATCH_SIZE = 200\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:17:39.576838Z",
     "start_time": "2021-03-19T01:17:39.572678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': tensor([ 14,   2,  32,  36, 135,  34,  21, 208,  88, 500, 190,  76, 200, 207,\n",
      "         83, 855,  70,   1,  14,   2,  32,  21,   8,  36, 517, 187, 310, 275,\n",
      "         88,  56, 149,  15,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0]), 'targets': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.302822Z",
     "start_time": "2021-03-19T01:17:39.578135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 1 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "Avg. batch proc. time: 0.0286s, loss: 0.6445:   8%|▊         | 3/40 [00:00<00:01, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0247s, loss: 0.3536: 100%|██████████| 40/40 [00:01<00:00, 31.60it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 70.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2688s, loss = 0.3536\n",
      "* Validation for epoch 0:\n",
      "loss = 0.72786545753479, score is 0.957184374332428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0241s, loss: 0.2630:  10%|█         | 4/40 [00:00<00:01, 32.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0240s, loss: 0.2672: 100%|██████████| 40/40 [00:01<00:00, 33.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 70.33it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2134s, loss = 0.2672\n",
      "* Validation for epoch 1:\n",
      "loss = 0.7269143462181091, score is 0.9572403430938721\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.2643: 100%|██████████| 40/40 [00:01<00:00, 27.54it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 55.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4541s, loss = 0.2643\n",
      "* Validation for epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 55.08it/s]\n",
      "Avg. batch proc. time: 0.0278s, loss: 0.2518:   8%|▊         | 3/40 [00:00<00:01, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.726230263710022, score is 0.9572805762290955\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0285s, loss: 0.2532: 100%|██████████| 40/40 [00:01<00:00, 27.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4548s, loss = 0.2532\n",
      "* Validation for epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0273s, loss: 0.2461:   8%|▊         | 3/40 [00:00<00:01, 27.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7211924195289612, score is 0.9575769305229187\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0284s, loss: 0.2268: 100%|██████████| 40/40 [00:01<00:00, 27.73it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 56.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4444s, loss = 0.2268\n",
      "* Validation for epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 33.62it/s]\n",
      "Avg. batch proc. time: 0.0261s, loss: 0.2115:  10%|█         | 4/40 [00:00<00:01, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7167998552322388, score is 0.95783531665802\n",
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0285s, loss: 0.2024: 100%|██████████| 40/40 [00:01<00:00, 27.72it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 54.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4444s, loss = 0.2024\n",
      "* Validation for epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 54.81it/s]\n",
      "Avg. batch proc. time: 0.0273s, loss: 0.1871:   8%|▊         | 3/40 [00:00<00:01, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7104807496070862, score is 0.9582070112228394\n",
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0280s, loss: 0.1839: 100%|██████████| 40/40 [00:01<00:00, 27.98it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 54.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4318s, loss = 0.1839\n",
      "* Validation for epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 54.80it/s]\n",
      "Avg. batch proc. time: 0.0297s, loss: 0.1694:   8%|▊         | 3/40 [00:00<00:01, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7070606350898743, score is 0.9584081768989563\n",
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0280s, loss: 0.1713: 100%|██████████| 40/40 [00:01<00:00, 27.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4513s, loss = 0.1713\n",
      "* Validation for epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0277s, loss: 0.1601:   8%|▊         | 3/40 [00:00<00:01, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7058351635932922, score is 0.9584802985191345\n",
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0287s, loss: 0.1624: 100%|██████████| 40/40 [00:01<00:00, 27.64it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4489s, loss = 0.1624\n",
      "* Validation for epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg. batch proc. time: 0.0286s, loss: 0.1567:   8%|▊         | 3/40 [00:00<00:01, 26.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7024733424186707, score is 0.9586780071258545\n",
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0281s, loss: 0.1552: 100%|██████████| 40/40 [00:01<00:00, 27.33it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 53.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4656s, loss = 0.1552\n",
      "* Validation for epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 54.58it/s]\n",
      "Avg. batch proc. time: 0.0272s, loss: 0.1573:   8%|▊         | 3/40 [00:00<00:01, 29.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7013697624206543, score is 0.9587429761886597\n",
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0284s, loss: 0.1498: 100%|██████████| 40/40 [00:01<00:00, 27.86it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 55.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4412s, loss = 0.1498\n",
      "* Validation for epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 55.09it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 60.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7025595903396606, score is 0.9586729407310486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/root1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 15/15 [00:00<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 2 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0246s, loss: 0.5602:  10%|█         | 4/40 [00:00<00:01, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0252s, loss: 0.3303: 100%|██████████| 40/40 [00:01<00:00, 31.24it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 74.81it/s]\n",
      "Avg. batch proc. time: 0.0246s, loss: 0.2542:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2816s, loss = 0.3303\n",
      "* Validation for epoch 0:\n",
      "loss = 0.7299216985702515, score is 0.9570634365081787\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0242s, loss: 0.2663: 100%|██████████| 40/40 [00:01<00:00, 32.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 71.21it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2291s, loss = 0.2663\n",
      "* Validation for epoch 1:\n",
      "loss = 0.7260723114013672, score is 0.9572898745536804\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0291s, loss: 0.2520: 100%|██████████| 40/40 [00:01<00:00, 27.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4548s, loss = 0.2520\n",
      "* Validation for epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0281s, loss: 0.2334:   8%|▊         | 3/40 [00:00<00:01, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7192661166191101, score is 0.9576902389526367\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0285s, loss: 0.2204: 100%|██████████| 40/40 [00:01<00:00, 27.70it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4461s, loss = 0.2204\n",
      "* Validation for epoch 3:\n",
      "loss = 0.7132319808006287, score is 0.9580451846122742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.2067:   8%|▊         | 3/40 [00:00<00:01, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.1955: 100%|██████████| 40/40 [00:01<00:00, 27.50it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4564s, loss = 0.1955\n",
      "* Validation for epoch 4:\n",
      "loss = 0.7106054425239563, score is 0.958199679851532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0289s, loss: 0.1783:   8%|▊         | 3/40 [00:00<00:01, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0277s, loss: 0.1781: 100%|██████████| 40/40 [00:01<00:00, 27.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4555s, loss = 0.1781\n",
      "* Validation for epoch 5:\n",
      "loss = 0.705973744392395, score is 0.9584721326828003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0271s, loss: 0.1761:   8%|▊         | 3/40 [00:00<00:01, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0273s, loss: 0.1654: 100%|██████████| 40/40 [00:01<00:00, 27.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4392s, loss = 0.1654\n",
      "* Validation for epoch 6:\n",
      "loss = 0.7032438516616821, score is 0.9586327075958252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0278s, loss: 0.1592:   8%|▊         | 3/40 [00:00<00:01, 28.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0272s, loss: 0.1559: 100%|██████████| 40/40 [00:01<00:00, 27.92it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4344s, loss = 0.1559\n",
      "* Validation for epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg. batch proc. time: 0.0272s, loss: 0.1487:   8%|▊         | 3/40 [00:00<00:01, 28.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7023653388023376, score is 0.9586843848228455\n",
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0285s, loss: 0.1480: 100%|██████████| 40/40 [00:01<00:00, 27.89it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 54.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4358s, loss = 0.1480\n",
      "* Validation for epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 55.09it/s]\n",
      "Avg. batch proc. time: 0.0264s, loss: 0.1440:   8%|▊         | 3/40 [00:00<00:01, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6991431713104248, score is 0.9588739275932312\n",
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0279s, loss: 0.1421: 100%|██████████| 40/40 [00:01<00:00, 27.79it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4410s, loss = 0.1421\n",
      "* Validation for epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0304s, loss: 0.1449:   8%|▊         | 3/40 [00:00<00:01, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6991698145866394, score is 0.958872377872467\n",
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0328s, loss: 0.1375: 100%|██████████| 40/40 [00:01<00:00, 22.64it/s]\n",
      " 45%|████▌     | 5/11 [00:00<00:00, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.7692s, loss = 0.1375\n",
      "* Validation for epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 44.78it/s]\n",
      " 45%|████▌     | 5/11 [00:00<00:00, 43.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6964536905288696, score is 0.9590321183204651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 47.12it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 54.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 3 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.6494:   8%|▊         | 3/40 [00:00<00:01, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0281s, loss: 0.3580: 100%|██████████| 40/40 [00:01<00:00, 27.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4515s, loss = 0.3580\n",
      "* Validation for epoch 0:\n",
      "loss = 0.7282140254974365, score is 0.9571638703346252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0275s, loss: 0.2696:   8%|▊         | 3/40 [00:00<00:01, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0279s, loss: 0.2682: 100%|██████████| 40/40 [00:01<00:00, 27.65it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4482s, loss = 0.2682\n",
      "* Validation for epoch 1:\n",
      "loss = 0.7263645529747009, score is 0.9572726488113403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0289s, loss: 0.2712:   8%|▊         | 3/40 [00:00<00:01, 27.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0288s, loss: 0.2636: 100%|██████████| 40/40 [00:01<00:00, 27.15it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4749s, loss = 0.2636\n",
      "* Validation for epoch 2:\n",
      "loss = 0.7230370044708252, score is 0.9574683904647827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0281s, loss: 0.2496:   8%|▊         | 3/40 [00:00<00:01, 27.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0287s, loss: 0.2434: 100%|██████████| 40/40 [00:01<00:00, 27.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4548s, loss = 0.2434\n",
      "* Validation for epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0270s, loss: 0.2325:   8%|▊         | 3/40 [00:00<00:01, 28.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7194685935974121, score is 0.9576783180236816\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0279s, loss: 0.2157: 100%|██████████| 40/40 [00:01<00:00, 27.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4396s, loss = 0.2157\n",
      "* Validation for epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0268s, loss: 0.1980:   8%|▊         | 3/40 [00:00<00:01, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7131924629211426, score is 0.9580475091934204\n",
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0278s, loss: 0.1956: 100%|██████████| 40/40 [00:01<00:00, 27.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4362s, loss = 0.1956\n",
      "* Validation for epoch 5:\n",
      "loss = 0.7128872871398926, score is 0.9580654501914978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0278s, loss: 0.1876:   8%|▊         | 3/40 [00:00<00:01, 27.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0286s, loss: 0.1808: 100%|██████████| 40/40 [00:01<00:00, 27.34it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 57.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4650s, loss = 0.1808\n",
      "* Validation for epoch 6:\n",
      "loss = 0.7079507112503052, score is 0.9583558440208435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0277s, loss: 0.1718:   8%|▊         | 3/40 [00:00<00:01, 28.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.1703: 100%|██████████| 40/40 [00:01<00:00, 27.61it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 59.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4501s, loss = 0.1703\n",
      "* Validation for epoch 7:\n",
      "loss = 0.7047770023345947, score is 0.95854252576828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0272s, loss: 0.1698:   8%|▊         | 3/40 [00:00<00:01, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0282s, loss: 0.1610: 100%|██████████| 40/40 [00:01<00:00, 27.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 58.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4388s, loss = 0.1610\n",
      "* Validation for epoch 8:\n",
      "loss = 0.7044695615768433, score is 0.958560585975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0296s, loss: 0.1572:   8%|▊         | 3/40 [00:00<00:01, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0279s, loss: 0.1528: 100%|██████████| 40/40 [00:01<00:00, 27.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4549s, loss = 0.1528\n",
      "* Validation for epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0273s, loss: 0.1444:   8%|▊         | 3/40 [00:00<00:01, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7018054127693176, score is 0.9587173461914062\n",
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0280s, loss: 0.1460: 100%|██████████| 40/40 [00:01<00:00, 27.70it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 55.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4460s, loss = 0.1460\n",
      "* Validation for epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 54.85it/s]\n",
      " 55%|█████▍    | 6/11 [00:00<00:00, 58.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7001272439956665, score is 0.9588160514831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 58.10it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 58.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 4 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0233s, loss: 0.5741:  10%|▉         | 4/41 [00:00<00:01, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0240s, loss: 0.3351: 100%|██████████| 41/41 [00:01<00:00, 33.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 79.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2333s, loss = 0.3351\n",
      "* Validation for epoch 0:\n",
      "loss = 0.7271191477775574, score is 0.9572283029556274\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0247s, loss: 0.2665: 100%|██████████| 41/41 [00:01<00:00, 32.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 73.17it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2644s, loss = 0.2665\n",
      "* Validation for epoch 1:\n",
      "loss = 0.7254191637039185, score is 0.9573282599449158\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0243s, loss: 0.2426: 100%|██████████| 41/41 [00:01<00:00, 32.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 73.49it/s]\n",
      "Avg. batch proc. time: 0.0204s, loss: 0.2208:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2452s, loss = 0.2426\n",
      "* Validation for epoch 2:\n",
      "loss = 0.716721773147583, score is 0.9578399062156677\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0241s, loss: 0.2178: 100%|██████████| 41/41 [00:01<00:00, 33.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 71.58it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2377s, loss = 0.2178\n",
      "* Validation for epoch 3:\n",
      "loss = 0.7146626114845276, score is 0.9579610228538513\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0243s, loss: 0.1965: 100%|██████████| 41/41 [00:01<00:00, 32.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 72.84it/s]\n",
      "Avg. batch proc. time: 0.0236s, loss: 0.1845:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2496s, loss = 0.1965\n",
      "* Validation for epoch 4:\n",
      "loss = 0.7118216753005981, score is 0.9581281542778015\n",
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0241s, loss: 0.1781: 100%|██████████| 41/41 [00:01<00:00, 32.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 77.62it/s]\n",
      "Avg. batch proc. time: 0.0232s, loss: 0.1687:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2443s, loss = 0.1781\n",
      "* Validation for epoch 5:\n",
      "loss = 0.7053837776184082, score is 0.9585068225860596\n",
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0239s, loss: 0.1643: 100%|██████████| 41/41 [00:01<00:00, 32.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 70.17it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2531s, loss = 0.1643\n",
      "* Validation for epoch 6:\n",
      "loss = 0.7025047540664673, score is 0.9586762189865112\n",
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0255s, loss: 0.1546: 100%|██████████| 41/41 [00:01<00:00, 31.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 71.66it/s]\n",
      "Avg. batch proc. time: 0.0209s, loss: 0.1428:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.3211s, loss = 0.1546\n",
      "* Validation for epoch 7:\n",
      "loss = 0.7019058465957642, score is 0.9587114453315735\n",
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0239s, loss: 0.1474: 100%|██████████| 41/41 [00:01<00:00, 32.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 69.22it/s]\n",
      "Avg. batch proc. time: 0.0236s, loss: 0.1530:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2498s, loss = 0.1474\n",
      "* Validation for epoch 8:\n",
      "loss = 0.6983951926231384, score is 0.9589179158210754\n",
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0243s, loss: 0.1420: 100%|██████████| 41/41 [00:01<00:00, 32.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 74.27it/s]\n",
      "Avg. batch proc. time: 0.0266s, loss: 0.1349:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2715s, loss = 0.1420\n",
      "* Validation for epoch 9:\n",
      "loss = 0.6985685229301453, score is 0.9589077234268188\n",
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0238s, loss: 0.1376: 100%|██████████| 41/41 [00:01<00:00, 32.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 76.05it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2566s, loss = 0.1376\n",
      "* Validation for epoch 10:\n",
      "loss = 0.6986544728279114, score is 0.9589026570320129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 70.20it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始第 5 折训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0236s, loss: 0.5639:  10%|▉         | 4/41 [00:00<00:01, 33.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0240s, loss: 0.3351: 100%|██████████| 41/41 [00:01<00:00, 33.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 74.40it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2421s, loss = 0.3351\n",
      "* Validation for epoch 0:\n",
      "loss = 0.7291954755783081, score is 0.9571061730384827\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0245s, loss: 0.2661: 100%|██████████| 41/41 [00:01<00:00, 32.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 69.79it/s]\n",
      "Avg. batch proc. time: 0.0268s, loss: 0.2720:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2681s, loss = 0.2661\n",
      "* Validation for epoch 1:\n",
      "loss = 0.7249788045883179, score is 0.9573541879653931\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0238s, loss: 0.2434: 100%|██████████| 41/41 [00:01<00:00, 32.30it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 69.71it/s]\n",
      "Avg. batch proc. time: 0.0243s, loss: 0.2370:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2706s, loss = 0.2434\n",
      "* Validation for epoch 2:\n",
      "loss = 0.7151157855987549, score is 0.9579343795776367\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0246s, loss: 0.2151: 100%|██████████| 41/41 [00:01<00:00, 32.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 82.73it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2649s, loss = 0.2151\n",
      "* Validation for epoch 3:\n",
      "loss = 0.7136635184288025, score is 0.9580197930335999\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0240s, loss: 0.1922: 100%|██████████| 41/41 [00:01<00:00, 32.74it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 76.37it/s]\n",
      "Avg. batch proc. time: 0.0294s, loss: 0.1701:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2543s, loss = 0.1922\n",
      "* Validation for epoch 4:\n",
      "loss = 0.7112213969230652, score is 0.9581634402275085\n",
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0241s, loss: 0.1740: 100%|██████████| 41/41 [00:01<00:00, 32.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 73.90it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.2710s, loss = 0.1740\n",
      "* Validation for epoch 5:\n",
      "loss = 0.707688570022583, score is 0.9583712816238403\n",
      "* Training epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0248s, loss: 0.1604: 100%|██████████| 41/41 [00:01<00:00, 31.58it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 71.05it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.3000s, loss = 0.1604\n",
      "* Validation for epoch 6:\n",
      "loss = 0.7034445405006409, score is 0.9586209058761597\n",
      "* Training epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0275s, loss: 0.1511: 100%|██████████| 41/41 [00:01<00:00, 28.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4303s, loss = 0.1511\n",
      "* Validation for epoch 7:\n",
      "loss = 0.7003470063209534, score is 0.958803117275238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0297s, loss: 0.1496:   7%|▋         | 3/41 [00:00<00:01, 27.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.1438: 100%|██████████| 41/41 [00:01<00:00, 27.74it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4799s, loss = 0.1438\n",
      "* Validation for epoch 8:\n",
      "loss = 0.6977381110191345, score is 0.9589565992355347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0299s, loss: 0.1436:   7%|▋         | 3/41 [00:00<00:01, 26.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0292s, loss: 0.1387: 100%|██████████| 41/41 [00:01<00:00, 27.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 56.63it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4832s, loss = 0.1387\n",
      "* Validation for epoch 9:\n",
      "loss = 0.698643684387207, score is 0.9589033126831055\n",
      "* Training epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0283s, loss: 0.1328: 100%|██████████| 41/41 [00:01<00:00, 27.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 56.07it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1.4743s, loss = 0.1328\n",
      "* Validation for epoch 10:\n",
      "loss = 0.6978228688240051, score is 0.9589515924453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 56.35it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 54.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,GroupKFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score , recall_score\t, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold,GroupKFold\n",
    "# gkf =  GroupKFold(n_splits=5)\n",
    "# groups_by_text_id_list = train['qid'].tolist()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=4590, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "oof_df_list = []\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "oof_train_list = []\n",
    "pred = [] \n",
    "\n",
    "# score\n",
    "\n",
    "def ss_score(targets,outputs):\n",
    "    \n",
    "    targets = torch.tensor(targets,dtype=torch.float)\n",
    "    outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "    loss = nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "    score = 1- loss/17\n",
    "    return loss.cpu().detach().numpy(),score\n",
    "\n",
    "\n",
    "for idx,(trn_idx,val_idx) in enumerate(skf.split(train_df,train_df[2])):\n",
    "    \n",
    "\n",
    "#     if idx<1:\n",
    "#         continue\n",
    "    print(\"开始第 %d 折训练\"%(idx+1))\n",
    "    \n",
    "\n",
    "    \n",
    "    save_path = 'lstm_w2v_model'\n",
    "    \n",
    "    model_path = \"%s/model_%d.bin\"%(save_path,idx)\n",
    "    \n",
    "    tr_df = train_df.iloc[trn_idx]\n",
    "    va_df = train_df.iloc[val_idx]\n",
    "    \n",
    "    tr_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #data aug\n",
    "    \n",
    "#     aug_tr_df = data_aug(tr_df)\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "    \n",
    "#     tr_df = pd.concat([tr_df,aug_tr_df])\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "\n",
    "\n",
    "    train_dataset = TextDataset(tr_df[1].tolist(),tr_df[2].tolist())\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=200,shuffle=True)\n",
    "    dev_dataset =  TextDataset(va_df[1].tolist(),va_df[2].tolist())\n",
    "    dev_loader = torch.utils.data.DataLoader(dev_dataset,batch_size=200,shuffle=False)\n",
    "\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "    n_vocab = len(tk.index_word)\n",
    "    model = GRUModel(n_vocab=n_vocab,pretrained_embedding=torch.from_numpy(embedding_matrix).float())\n",
    "    model.to(device)\n",
    "    \n",
    "    lr=0.0005\n",
    "    patience=5\n",
    "    max_grad_norm=10.0\n",
    "\n",
    "\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    # 过滤出需要梯度更新的参数\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    # optimizer = optim.Adadelta(parameters, params[\"LEARNING_RATE\"])\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", \n",
    "                                                               factor=0.85, patience=0)\n",
    "    best_score = 0.0\n",
    "    start_epoch = 1\n",
    "    # Data for loss curves plot\n",
    "    epochs_count = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "\n",
    "\n",
    "    patience_counter = 0\n",
    "    start_epoch=0\n",
    "    epochs=50\n",
    "    \n",
    "    criterion =  loss_fn\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "        epochs_count.append(epoch)\n",
    "        print(\"* Training epoch {}:\".format(epoch))\n",
    "        epoch_time, epoch_loss= train_fn(model, train_loader, optimizer,\n",
    "                                                           criterion, epoch, max_grad_norm)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(\"-> Training time: {:.4f}s, loss = {:.4f}\"\n",
    "                  .format(epoch_time, epoch_loss))\n",
    "        print(\"* Validation for epoch {}:\".format(epoch))\n",
    "        \n",
    "        outputs, targets = eval_fn(dev_loader , model, device)\n",
    "        loss,score = ss_score(targets,outputs)\n",
    "\n",
    "        print(f\"loss = {loss}, score is {score}\")\n",
    "        scheduler.step(0.9)\n",
    "        # Early stopping on validation accuracy.\n",
    "        if score < best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = score\n",
    "            patience_counter = 0\n",
    "            torch.save({   \"epoch\": epoch, \n",
    "                            \"model\": model.state_dict(),\n",
    "                            \"best_score\": best_score},\n",
    "                            model_path )\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break\n",
    "            \n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path)[\"model\"])\n",
    "    outputs, targets = eval_fn(dev_loader, model, device)\n",
    "    va_df['prob'] = outputs\n",
    "    oof_train_list.append(va_df)\n",
    "\n",
    "    outputs, targets = eval_fn(test_data_loader, model, device)\n",
    "    pred.append(np.array(outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.318542Z",
     "start_time": "2021-03-19T01:19:17.304560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03333572298288345, 0.0906672552227974, 0.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0024807623121887445, 0.003729908959940076, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.025627337396144867, 0.007706626318395138, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0.02462775632739067, 0.008057428523898125, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[0.7286989092826843, 0.7299920916557312, 0.251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1          2  \\\n",
       "0    0|  623 328 538 382 399 400 478 842 698 137 492 26...         2    \n",
       "4    4|  623 328 399 698 493 338 266 14 177 415 511 647...        16    \n",
       "5    5|  80 328 328 54 172 439 741 380 172 842 698 177 ...        15    \n",
       "7    7|  623 328 659 486 582 162 711 289 606 405 809 78...              \n",
       "14  14|  623 328 697 661 809 48 46 355 661 414 852 328 ...  0 1 8 10    \n",
       "\n",
       "                                                 prob  \n",
       "0   [0.03333572298288345, 0.0906672552227974, 0.57...  \n",
       "4   [0.0024807623121887445, 0.003729908959940076, ...  \n",
       "5   [0.025627337396144867, 0.007706626318395138, 0...  \n",
       "7   [0.02462775632739067, 0.008057428523898125, 0....  \n",
       "14  [0.7286989092826843, 0.7299920916557312, 0.251...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = pd.concat(oof_train_list)\n",
    "oof_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.358551Z",
     "start_time": "2021-03-19T01:19:17.319743Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = np.average(pred, axis=0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.366540Z",
     "start_time": "2021-03-19T01:19:17.361239Z"
    }
   },
   "outputs": [],
   "source": [
    "m = sub.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.383143Z",
     "start_time": "2021-03-19T01:19:17.367872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dumm(s):\n",
    "    re=[0]*17\n",
    "    if s=='' or s==\" \":\n",
    "        return re\n",
    "    else:\n",
    "        tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "        for i in tmp:\n",
    "            re[i]=1\n",
    "    return re\n",
    "\n",
    "\n",
    "oof_train['label'] = oof_train[2].apply(lambda x:get_dumm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:17.425236Z",
     "start_time": "2021-03-19T01:19:17.384405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03333572298288345, 0.0906672552227974, 0.57...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0024807623121887445, 0.003729908959940076, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5|</td>\n",
       "      <td>80 328 328 54 172 439 741 380 172 842 698 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.025627337396144867, 0.007706626318395138, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7|</td>\n",
       "      <td>623 328 659 486 582 162 711 289 606 405 809 78...</td>\n",
       "      <td></td>\n",
       "      <td>[0.02462775632739067, 0.008057428523898125, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14|</td>\n",
       "      <td>623 328 697 661 809 48 46 355 661 414 852 328 ...</td>\n",
       "      <td>0 1 8 10</td>\n",
       "      <td>[0.7286989092826843, 0.7299920916557312, 0.251...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21|</td>\n",
       "      <td>380 172 200 791 470 753 693 256 514 569 231 11...</td>\n",
       "      <td></td>\n",
       "      <td>[0.002962421625852585, 0.002378244651481509, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27|</td>\n",
       "      <td>852 328 501 355 360 265 478 162 498 289 169 40...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.01416201051324606, 0.03786063566803932, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31|</td>\n",
       "      <td>91 380 488 12 591 487 197 852 328 538 501 382 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.004090123809874058, 0.004888575524091721, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35|</td>\n",
       "      <td>380 315 809 623 328 160 380 419 789 439 852 81...</td>\n",
       "      <td>6 12 14 15</td>\n",
       "      <td>[0.030209612101316452, 0.05691125616431236, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41|</td>\n",
       "      <td>48 718 328 419 571 769 256 100 809 328 380 172...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.31305351853370667, 0.12507960200309753, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48|</td>\n",
       "      <td>48 231 419 571 769 256 524 809 328 380 373 320...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.08025439828634262, 0.04008999094367027, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51|</td>\n",
       "      <td>852 328 3 697 483 582 582 717 382 363 397 834 ...</td>\n",
       "      <td>7 9</td>\n",
       "      <td>[0.019264789298176765, 0.005316813010722399, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59|</td>\n",
       "      <td>623 328 538 661 698 493 338 266 177 415 832 38...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.06663598865270615, 0.10636500269174576, 0.6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61|</td>\n",
       "      <td>852 328 383 538 661 22 698 338 266 521 177 415...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.048892535269260406, 0.05406201258301735, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62|</td>\n",
       "      <td>328 22 290 380 398 851 728 636 851 636 70 628 ...</td>\n",
       "      <td>4 5 11 12 15</td>\n",
       "      <td>[0.0810622051358223, 0.04780079051852226, 0.00...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69|</td>\n",
       "      <td>48 328 290 380 419 789 523 532 50 693 556 698 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.006412018556147814, 0.0033888055477291346, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72|</td>\n",
       "      <td>328 697 661 19 363 737 698 785 504 493 338 266...</td>\n",
       "      <td>0 7</td>\n",
       "      <td>[0.7720701098442078, 0.34544819593429565, 0.14...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75|</td>\n",
       "      <td>852 328 160 380 439 679 63 541 848 698 510 838...</td>\n",
       "      <td>13 14</td>\n",
       "      <td>[0.006830282509326935, 0.0050435662269592285, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76|</td>\n",
       "      <td>623 164 305 204 204 399 698 641 794 779 437 17...</td>\n",
       "      <td></td>\n",
       "      <td>[0.002345460932701826, 0.004449591506272554, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90|</td>\n",
       "      <td>725 471 453 162 684 289 462 405 788 177 232 23...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0020460986997932196, 0.002832121681421995, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91|</td>\n",
       "      <td>48 328 697 243 19 363 842 698 627 504 493 338 ...</td>\n",
       "      <td>0 7</td>\n",
       "      <td>[0.49854761362075806, 0.07623296976089478, 0.0...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97|</td>\n",
       "      <td>290 351 380 99 809 813 380 786 287 515 305 654...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.004847886506468058, 0.00399818504229188, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98|</td>\n",
       "      <td>623 328 380 834 809 343 809 362 840 556 698 42...</td>\n",
       "      <td>4 11</td>\n",
       "      <td>[0.018064463511109352, 0.008434198796749115, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101|</td>\n",
       "      <td>380 172 200 737 300 78 448 290 693 380 834 343...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.031626418232917786, 0.032340243458747864, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107|</td>\n",
       "      <td>623 328 697 69 698 33 735 382 327 514 381 693 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.03410370275378227, 0.0085780443623662, 0.00...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115|</td>\n",
       "      <td>48 328 328 380 172 320 380 19 363 399 352 494 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.047970809042453766, 0.017863983288407326, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116|</td>\n",
       "      <td>623 328 538 582 842 698 641 769 779 177 166 16...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.04149633273482323, 0.07945777475833893, 0.1...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120|</td>\n",
       "      <td>380 136 363 399 556 438 313 149 713 432 768 11...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.011421224102377892, 0.0164356529712677, 0.1...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124|</td>\n",
       "      <td>623 328 697 538 355 27 386 728 478 647 169 750...</td>\n",
       "      <td></td>\n",
       "      <td>[0.09361369162797928, 0.11069383472204208, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128|</td>\n",
       "      <td>48 328 697 355 766 809 623 328 538 661 265 470...</td>\n",
       "      <td>0 1 2 7 8</td>\n",
       "      <td>[0.804618239402771, 0.7629339098930359, 0.3830...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>9869|</td>\n",
       "      <td>623 328 538 582 439 81 661 374 842 698 78 638 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.03561251983046532, 0.0785086378455162, 0.51...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>9871|</td>\n",
       "      <td>478 333 390 636 276 698 116 71 712 620 381 693...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0030559042934328318, 0.007143103051930666, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>9882|</td>\n",
       "      <td>91 382 569 231 556 698 313 66 432 449 693 664 ...</td>\n",
       "      <td></td>\n",
       "      <td>[0.004330174066126347, 0.007354632019996643, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>9883|</td>\n",
       "      <td>623 657 320 786 399 851 636 374 698 516 149 26...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.02009272761642933, 0.21570110321044922, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9895|</td>\n",
       "      <td>48 328 380 834 809 343 698 177 415 832 468 25 ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.007459231186658144, 0.005052513908594847, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9900|</td>\n",
       "      <td>623 328 328 380 172 470 651 394 596 502 340 37...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0022058298345655203, 0.0052462294697761536,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>9905|</td>\n",
       "      <td>247 305 461 204 698 162 498 289 177 415 381</td>\n",
       "      <td></td>\n",
       "      <td>[0.002787662437185645, 0.00441490625962615, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>9908|</td>\n",
       "      <td>623 328 290 380 372 236 636 90 735 374 698 14 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.029260724782943726, 0.09012878686189651, 0....</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9914</th>\n",
       "      <td>9914|</td>\n",
       "      <td>290 380 582 809 160 380 786 809 244 328 550 32...</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.010841690935194492, 0.005087593104690313, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>9921|</td>\n",
       "      <td>91 380 769 12 591 423 487 693 623 79 328 380 2...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.003964376635849476, 0.007648487109690905, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>9923|</td>\n",
       "      <td>623 328 355 661 698 338 266 437 521 254 415 38...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1317731887102127, 0.6935627460479736, 0.153...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>9924|</td>\n",
       "      <td>852 328 380 172 54 823 391 693 380 654 439 380...</td>\n",
       "      <td></td>\n",
       "      <td>[0.0013547234702855349, 0.0013351032976061106,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>9925|</td>\n",
       "      <td>139 81 200 737 556 698 313 326 432 449 693 852...</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.0032654404640197754, 0.002070510294288397, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>9929|</td>\n",
       "      <td>256 514 38 582 623 34 693 91 382 556 698 432 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.11640539020299911, 0.4978676438331604, 0.08...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>9930|</td>\n",
       "      <td>380 172 439 380 654 200 737 779 59 655 798 693...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.009727543219923973, 0.005303134676069021, 0...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>9931|</td>\n",
       "      <td>48 328 733 777 204 549 728 832 131 693 623 328...</td>\n",
       "      <td>1 3</td>\n",
       "      <td>[0.10326065123081207, 0.4519693851470947, 0.10...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>9934|</td>\n",
       "      <td>623 727 697 538 382 397 455 693 411 204 439 62...</td>\n",
       "      <td></td>\n",
       "      <td>[0.052793726325035095, 0.040987104177474976, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9935|</td>\n",
       "      <td>162 498 289 169 405 693 623 328 357 661 822 33...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.02710367739200592, 0.029185855761170387, 0....</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>9946|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 189 832 14 381 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.021542122587561607, 0.06650646775960922, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>9952|</td>\n",
       "      <td>48 673 545 784 856 374 439 379 328 717 172 320...</td>\n",
       "      <td>4 11 15</td>\n",
       "      <td>[0.0367252342402935, 0.007300893776118755, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>9953|</td>\n",
       "      <td>623 328 697 582 17 501 382 400 434 439 380 136...</td>\n",
       "      <td>0 3</td>\n",
       "      <td>[0.14197500050067902, 0.08177437633275986, 0.0...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>9957|</td>\n",
       "      <td>135 328 776 355 616 38 91 382 698 514 408 177 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.05955573916435242, 0.20247158408164978, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9964|</td>\n",
       "      <td>160 380 786 439 26 343 654 399 177 415 381 644...</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.002974095055833459, 0.0027377984952181578, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>9965|</td>\n",
       "      <td>380 136 783 16 556 698 313 66 432 449 208 415 ...</td>\n",
       "      <td>6 13</td>\n",
       "      <td>[0.03365844860672951, 0.007951700128614902, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9972|</td>\n",
       "      <td>852 328 328 380 172 487 391 693 210 514 569 71...</td>\n",
       "      <td></td>\n",
       "      <td>[0.001452842028811574, 0.0014934613136574626, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9975|</td>\n",
       "      <td>623 328 697 661 182 698 17 49 486 548 601 818 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.20595727860927582, 0.11324940621852875, 0.0...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>9976|</td>\n",
       "      <td>852 328 647 461 755 549 170 549 728 832 122</td>\n",
       "      <td></td>\n",
       "      <td>[0.0011854994809255004, 0.001472712610848248, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9983|</td>\n",
       "      <td>48 328 733 777 204 549 728 394 832 122 693 852...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.03842570260167122, 0.03279662877321243, 0.4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9985|</td>\n",
       "      <td>623 328 697 204 809 623 328 357 471 672 328 45...</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.09782839566469193, 0.009783857502043247, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9988|</td>\n",
       "      <td>623 328 538 582 91 400 698 10 177 415 569 856 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.060540571808815, 0.04180028289556503, 0.451...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1              2  \\\n",
       "0        0|  623 328 538 382 399 400 478 842 698 137 492 26...             2    \n",
       "4        4|  623 328 399 698 493 338 266 14 177 415 511 647...            16    \n",
       "5        5|  80 328 328 54 172 439 741 380 172 842 698 177 ...            15    \n",
       "7        7|  623 328 659 486 582 162 711 289 606 405 809 78...                  \n",
       "14      14|  623 328 697 661 809 48 46 355 661 414 852 328 ...      0 1 8 10    \n",
       "21      21|  380 172 200 791 470 753 693 256 514 569 231 11...                  \n",
       "27      27|  852 328 501 355 360 265 478 162 498 289 169 40...            15    \n",
       "31      31|  91 380 488 12 591 487 197 852 328 538 501 382 ...                  \n",
       "35      35|  380 315 809 623 328 160 380 419 789 439 852 81...    6 12 14 15    \n",
       "41      41|  48 718 328 419 571 769 256 100 809 328 380 172...  4 5 11 12 15    \n",
       "48      48|  48 231 419 571 769 256 524 809 328 380 373 320...  4 5 11 12 15    \n",
       "51      51|  852 328 3 697 483 582 582 717 382 363 397 834 ...           7 9    \n",
       "59      59|  623 328 538 661 698 493 338 266 177 415 832 38...            16    \n",
       "61      61|  852 328 383 538 661 22 698 338 266 521 177 415...             9    \n",
       "62      62|  328 22 290 380 398 851 728 636 851 636 70 628 ...  4 5 11 12 15    \n",
       "69      69|  48 328 290 380 419 789 523 532 50 693 556 698 ...                  \n",
       "72      72|  328 697 661 19 363 737 698 785 504 493 338 266...           0 7    \n",
       "75      75|  852 328 160 380 439 679 63 541 848 698 510 838...         13 14    \n",
       "76      76|  623 164 305 204 204 399 698 641 794 779 437 17...                  \n",
       "90      90|  725 471 453 162 684 289 462 405 788 177 232 23...                  \n",
       "91      91|  48 328 697 243 19 363 842 698 627 504 493 338 ...           0 7    \n",
       "97      97|  290 351 380 99 809 813 380 786 287 515 305 654...            16    \n",
       "98      98|  623 328 380 834 809 343 809 362 840 556 698 42...          4 11    \n",
       "101    101|  380 172 200 737 300 78 448 290 693 380 834 343...             9    \n",
       "107    107|  623 328 697 69 698 33 735 382 327 514 381 693 ...                  \n",
       "115    115|  48 328 328 380 172 320 380 19 363 399 352 494 ...            15    \n",
       "116    116|  623 328 538 582 842 698 641 769 779 177 166 16...             2    \n",
       "120    120|  380 136 363 399 556 438 313 149 713 432 768 11...             2    \n",
       "124    124|  623 328 697 538 355 27 386 728 478 647 169 750...                  \n",
       "128    128|  48 328 697 355 766 809 623 328 538 661 265 470...     0 1 2 7 8    \n",
       "...     ...                                                ...            ...   \n",
       "9869  9869|  623 328 538 582 439 81 661 374 842 698 78 638 ...             2    \n",
       "9871  9871|  478 333 390 636 276 698 116 71 712 620 381 693...                  \n",
       "9882  9882|  91 382 569 231 556 698 313 66 432 449 693 664 ...                  \n",
       "9883  9883|  623 657 320 786 399 851 636 374 698 516 149 26...            15    \n",
       "9895  9895|  48 328 380 834 809 343 698 177 415 832 468 25 ...            16    \n",
       "9900  9900|  623 328 328 380 172 470 651 394 596 502 340 37...                  \n",
       "9905  9905|       247 305 461 204 698 162 498 289 177 415 381                   \n",
       "9908  9908|  623 328 290 380 372 236 636 90 735 374 698 14 ...             3    \n",
       "9914  9914|  290 380 582 809 160 380 786 809 244 328 550 32...            16    \n",
       "9921  9921|  91 380 769 12 591 423 487 693 623 79 328 380 2...            15    \n",
       "9923  9923|  623 328 355 661 698 338 266 437 521 254 415 38...             1    \n",
       "9924  9924|  852 328 380 172 54 823 391 693 380 654 439 380...                  \n",
       "9925  9925|  139 81 200 737 556 698 313 326 432 449 693 852...            11    \n",
       "9929  9929|  256 514 38 582 623 34 693 91 382 556 698 432 4...             1    \n",
       "9930  9930|  380 172 439 380 654 200 737 779 59 655 798 693...             2    \n",
       "9931  9931|  48 328 733 777 204 549 728 832 131 693 623 328...           1 3    \n",
       "9934  9934|  623 727 697 538 382 397 455 693 411 204 439 62...                  \n",
       "9935  9935|  162 498 289 169 405 693 623 328 357 661 822 33...             1    \n",
       "9946  9946|  160 380 786 439 26 343 654 399 189 832 14 381 ...            15    \n",
       "9952  9952|  48 673 545 784 856 374 439 379 328 717 172 320...       4 11 15    \n",
       "9953  9953|  623 328 697 582 17 501 382 400 434 439 380 136...           0 3    \n",
       "9957  9957|  135 328 776 355 616 38 91 382 698 514 408 177 ...            15    \n",
       "9964  9964|  160 380 786 439 26 343 654 399 177 415 381 644...            15    \n",
       "9965  9965|  380 136 783 16 556 698 313 66 432 449 208 415 ...          6 13    \n",
       "9972  9972|  852 328 328 380 172 487 391 693 210 514 569 71...                  \n",
       "9975  9975|  623 328 697 661 182 698 17 49 486 548 601 818 ...             0    \n",
       "9976  9976|       852 328 647 461 755 549 170 549 728 832 122                   \n",
       "9983  9983|  48 328 733 777 204 549 728 394 832 122 693 852...             9    \n",
       "9985  9985|  623 328 697 204 809 623 328 357 471 672 328 45...            11    \n",
       "9988  9988|  623 328 538 582 91 400 698 10 177 415 569 856 ...             2    \n",
       "\n",
       "                                                   prob  \\\n",
       "0     [0.03333572298288345, 0.0906672552227974, 0.57...   \n",
       "4     [0.0024807623121887445, 0.003729908959940076, ...   \n",
       "5     [0.025627337396144867, 0.007706626318395138, 0...   \n",
       "7     [0.02462775632739067, 0.008057428523898125, 0....   \n",
       "14    [0.7286989092826843, 0.7299920916557312, 0.251...   \n",
       "21    [0.002962421625852585, 0.002378244651481509, 0...   \n",
       "27    [0.01416201051324606, 0.03786063566803932, 0.0...   \n",
       "31    [0.004090123809874058, 0.004888575524091721, 0...   \n",
       "35    [0.030209612101316452, 0.05691125616431236, 0....   \n",
       "41    [0.31305351853370667, 0.12507960200309753, 0.0...   \n",
       "48    [0.08025439828634262, 0.04008999094367027, 0.0...   \n",
       "51    [0.019264789298176765, 0.005316813010722399, 0...   \n",
       "59    [0.06663598865270615, 0.10636500269174576, 0.6...   \n",
       "61    [0.048892535269260406, 0.05406201258301735, 0....   \n",
       "62    [0.0810622051358223, 0.04780079051852226, 0.00...   \n",
       "69    [0.006412018556147814, 0.0033888055477291346, ...   \n",
       "72    [0.7720701098442078, 0.34544819593429565, 0.14...   \n",
       "75    [0.006830282509326935, 0.0050435662269592285, ...   \n",
       "76    [0.002345460932701826, 0.004449591506272554, 0...   \n",
       "90    [0.0020460986997932196, 0.002832121681421995, ...   \n",
       "91    [0.49854761362075806, 0.07623296976089478, 0.0...   \n",
       "97    [0.004847886506468058, 0.00399818504229188, 0....   \n",
       "98    [0.018064463511109352, 0.008434198796749115, 0...   \n",
       "101   [0.031626418232917786, 0.032340243458747864, 0...   \n",
       "107   [0.03410370275378227, 0.0085780443623662, 0.00...   \n",
       "115   [0.047970809042453766, 0.017863983288407326, 0...   \n",
       "116   [0.04149633273482323, 0.07945777475833893, 0.1...   \n",
       "120   [0.011421224102377892, 0.0164356529712677, 0.1...   \n",
       "124   [0.09361369162797928, 0.11069383472204208, 0.0...   \n",
       "128   [0.804618239402771, 0.7629339098930359, 0.3830...   \n",
       "...                                                 ...   \n",
       "9869  [0.03561251983046532, 0.0785086378455162, 0.51...   \n",
       "9871  [0.0030559042934328318, 0.007143103051930666, ...   \n",
       "9882  [0.004330174066126347, 0.007354632019996643, 0...   \n",
       "9883  [0.02009272761642933, 0.21570110321044922, 0.0...   \n",
       "9895  [0.007459231186658144, 0.005052513908594847, 0...   \n",
       "9900  [0.0022058298345655203, 0.0052462294697761536,...   \n",
       "9905  [0.002787662437185645, 0.00441490625962615, 0....   \n",
       "9908  [0.029260724782943726, 0.09012878686189651, 0....   \n",
       "9914  [0.010841690935194492, 0.005087593104690313, 0...   \n",
       "9921  [0.003964376635849476, 0.007648487109690905, 0...   \n",
       "9923  [0.1317731887102127, 0.6935627460479736, 0.153...   \n",
       "9924  [0.0013547234702855349, 0.0013351032976061106,...   \n",
       "9925  [0.0032654404640197754, 0.002070510294288397, ...   \n",
       "9929  [0.11640539020299911, 0.4978676438331604, 0.08...   \n",
       "9930  [0.009727543219923973, 0.005303134676069021, 0...   \n",
       "9931  [0.10326065123081207, 0.4519693851470947, 0.10...   \n",
       "9934  [0.052793726325035095, 0.040987104177474976, 0...   \n",
       "9935  [0.02710367739200592, 0.029185855761170387, 0....   \n",
       "9946  [0.021542122587561607, 0.06650646775960922, 0....   \n",
       "9952  [0.0367252342402935, 0.007300893776118755, 0.0...   \n",
       "9953  [0.14197500050067902, 0.08177437633275986, 0.0...   \n",
       "9957  [0.05955573916435242, 0.20247158408164978, 0.0...   \n",
       "9964  [0.002974095055833459, 0.0027377984952181578, ...   \n",
       "9965  [0.03365844860672951, 0.007951700128614902, 0....   \n",
       "9972  [0.001452842028811574, 0.0014934613136574626, ...   \n",
       "9975  [0.20595727860927582, 0.11324940621852875, 0.0...   \n",
       "9976  [0.0011854994809255004, 0.001472712610848248, ...   \n",
       "9983  [0.03842570260167122, 0.03279662877321243, 0.4...   \n",
       "9985  [0.09782839566469193, 0.009783857502043247, 0....   \n",
       "9988  [0.060540571808815, 0.04180028289556503, 0.451...   \n",
       "\n",
       "                                                  label  \n",
       "0     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "14    [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n",
       "21    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "27    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "31    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "35    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n",
       "41    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "48    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "51    [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "59    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "61    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "62    [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "69    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "72    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "75    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n",
       "76    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "90    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "91    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "97    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "98    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "101   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "107   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "115   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "120   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "124   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "128   [1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "9869  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9871  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9882  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9883  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9895  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9905  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9908  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9914  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9921  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9923  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9924  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9925  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9929  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9930  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9931  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9934  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9935  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9946  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9952  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9953  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9957  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9964  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9965  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "9972  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9975  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9976  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9983  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "9985  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "9988  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:18.835523Z",
     "start_time": "2021-03-19T01:19:17.426342Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_train['score'] = oof_train.apply(lambda x:ss_score(x.label,x.prob)[1],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:18.859281Z",
     "start_time": "2021-03-19T01:19:18.836787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95889501953125\n"
     ]
    }
   ],
   "source": [
    "oof_score = oof_train.score.mean()\n",
    "print(oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:18.900630Z",
     "start_time": "2021-03-19T01:19:18.860599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0|</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>[0.07269788160920143, 0.06756291016936303, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1|</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>[0.002783299359725788, 0.0023060382576659323, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2|</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>[0.0031904116040095687, 0.0024570431094616653,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3|</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>[0.012583044357597828, 0.027001495473086834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4|</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>[0.014879816630855202, 0.08119104504585266, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1  \\\n",
       "0  0|  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1  1|  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2  2|  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3  3|  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4  4|  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "                                                   2  \n",
       "0  [0.07269788160920143, 0.06756291016936303, 0.0...  \n",
       "1  [0.002783299359725788, 0.0023060382576659323, ...  \n",
       "2  [0.0031904116040095687, 0.0024570431094616653,...  \n",
       "3  [0.012583044357597828, 0.027001495473086834, 0...  \n",
       "4  [0.014879816630855202, 0.08119104504585266, 0....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[2] = m\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:18.923436Z",
     "start_time": "2021-03-19T01:19:18.901903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>852 328 697 538 142 355 582 800 728 4 647 169 ...</td>\n",
       "      <td>[0.07269788160920143, 0.06756291016936303, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>380 358 343 654 171 832 47 832 690 693 48 563 ...</td>\n",
       "      <td>[0.002783299359725788, 0.0023060382576659323, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>751 335 834 582 717 583 585 693 623 328 107 38...</td>\n",
       "      <td>[0.0031904116040095687, 0.0024570431094616653,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>623 328 649 582 488 12 578 623 538 382 382 265...</td>\n",
       "      <td>[0.012583044357597828, 0.027001495473086834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83 293 398 797 382 363 145 424 693 698 800 691...</td>\n",
       "      <td>[0.014879816630855202, 0.08119104504585266, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  0  852 328 697 538 142 355 582 800 728 4 647 169 ...   \n",
       "1  1  380 358 343 654 171 832 47 832 690 693 48 563 ...   \n",
       "2  2  751 335 834 582 717 583 585 693 623 328 107 38...   \n",
       "3  3  623 328 649 582 488 12 578 623 538 382 382 265...   \n",
       "4  4  83 293 398 797 382 363 145 424 693 698 800 691...   \n",
       "\n",
       "                                                   2  \n",
       "0  [0.07269788160920143, 0.06756291016936303, 0.0...  \n",
       "1  [0.002783299359725788, 0.0023060382576659323, ...  \n",
       "2  [0.0031904116040095687, 0.0024570431094616653,...  \n",
       "3  [0.012583044357597828, 0.027001495473086834, 0...  \n",
       "4  [0.014879816630855202, 0.08119104504585266, 0....  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[0]=test_df[0].apply(lambda x:x[:-1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:19.014674Z",
     "start_time": "2021-03-19T01:19:18.924560Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_id=test_df[0].values\n",
    "pres_all = sub.tolist()\n",
    "str_w=''\n",
    "with open(f'{save_path}/submit_{oof_score}.csv','w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        pres_fold = pres_all[i]\n",
    "        pres_fold=[str(p) for p in pres_fold]\n",
    "        prob = \" \".join(pres_fold)\n",
    "        str_w+=sub_id[i]+'|'+','+'|'+prob+'\\n'\n",
    "    str_w=str_w.strip('\\n')\n",
    "    f.write(str_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T01:19:20.860708Z",
     "start_time": "2021-03-19T01:19:19.016064Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(f\"{save_path}/oof_test_{score}.csv\")\n",
    "oof_train.to_csv(f\"{save_path}/oof_train_{score}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_transformers_gpu_macbert_model-多标签分类v2.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
