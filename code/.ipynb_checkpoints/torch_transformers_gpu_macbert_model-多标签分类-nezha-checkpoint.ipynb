{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T17:56:37.287908Z",
     "start_time": "2021-03-13T17:56:37.161759Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11830,
     "status": "ok",
     "timestamp": 1614770513449,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "O7WFLSg4DPma",
    "outputId": "76c70351-b51f-436e-d398-da17cceb9fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            251          16         175           0          60         233\r\n",
      "Swap:             1           0           1\r\n"
     ]
    }
   ],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T17:56:37.295369Z",
     "start_time": "2021-03-13T17:56:37.291895Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19379,
     "status": "ok",
     "timestamp": 1614770521007,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3SjuHYnRDkWK",
    "outputId": "9443626d-a88c-49f7-8391-9cd5766d1017"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install transformers==2.5.0 -q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T17:56:37.968608Z",
     "start_time": "2021-03-13T17:56:37.297330Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19372,
     "status": "ok",
     "timestamp": 1614770521008,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "N7G6OGVfgvbt",
    "outputId": "23889a4a-3654-4474-b87e-1ede6897138c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 13 12:56:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  PH402 SKU 200       On   | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   65C    P0    46W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  PH402 SKU 200       On   | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    39W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  PH402 SKU 200       On   | 00000000:21:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    39W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  PH402 SKU 200       On   | 00000000:22:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    37W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  PH402 SKU 200       On   | 00000000:25:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    38W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  PH402 SKU 200       On   | 00000000:26:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    36W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  PH402 SKU 200       On   | 00000000:29:00.0 Off |                    0 |\n",
      "| N/A   60C    P0    44W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  PH402 SKU 200       On   | 00000000:2A:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    39W / 140W |      4MiB / 32630MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 3090    On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   29C    P8    24W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 3090    On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 66%   65C    P2   328W / 350W |  18817MiB / 24268MiB |     77%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|  10  GeForce RTX 3090    On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 71%   68C    P2   293W / 350W |  20847MiB / 24268MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|  11  GeForce RTX 3090    On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 72%   68C    P2   331W / 350W |   8269MiB / 24268MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    8   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    9   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    9   N/A  N/A     10328      C   ...oot1/anaconda3/bin/python    18809MiB |\n",
      "|   10   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|   10   N/A  N/A     19090      C   ...oot1/anaconda3/bin/python    20839MiB |\n",
      "|   11   N/A  N/A      2193      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|   11   N/A  N/A     26580      C   ...oot1/anaconda3/bin/python     8261MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T17:56:37.976468Z",
     "start_time": "2021-03-13T17:56:37.973071Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39911,
     "status": "ok",
     "timestamp": 1614770541554,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "MmMivBRyDbtO",
    "outputId": "35305dcd-c1d0-454c-a173-e8042a4efc30"
   },
   "outputs": [],
   "source": [
    "#  #colab setting \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Competitions/医学影像报告异常检测/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.155Z"
    },
    "executionInfo": {
     "elapsed": 54243,
     "status": "ok",
     "timestamp": 1614770555888,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "9yok51vCDoWl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.160Z"
    },
    "executionInfo": {
     "elapsed": 54249,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "bQxQDR630SCm"
   },
   "outputs": [],
   "source": [
    "# !mkdir chinese-macbert-base\n",
    "\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json  -P  chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/added_tokens.json  -P   chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/pytorch_model.bin  -P  chinese-macbert-base/\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/special_tokens_map.json    -P chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer_config.json  -P  chinese-macbert-base/\n",
    "\n",
    "# !wget https://huggingface.co/hfl/chinese-macbert-base/resolve/main/vocab.txt -P chinese-macbert-base/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.164Z"
    },
    "executionInfo": {
     "elapsed": 54246,
     "status": "ok",
     "timestamp": 1614770555896,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "VpFla5NVPayv"
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/track1_round1_train_20210222.csv\"\n",
    "test_path = \"../input/track1_round1_testA_20210222.csv\"\n",
    "train_df = pd.read_csv(train_path,sep=',',header=None)\n",
    "test_df = pd.read_csv(test_path,sep=',',header=None)\n",
    "\n",
    "train_df[1]=train_df[1].apply(lambda x:x[1:-1])\n",
    "train_df[2]=train_df[2].apply(lambda x:x[1:])\n",
    "\n",
    "test_df[1] = test_df[1].apply(lambda x:x[1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.168Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "train_df.drop_duplicates(subset=[1,2],inplace=True)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.172Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 54241,
     "status": "ok",
     "timestamp": 1614770555897,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "f1GQc7JFDz46",
    "outputId": "d7609944-c200-4d73-8906-f31cb906c7c9"
   },
   "outputs": [],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.177Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 54233,
     "status": "ok",
     "timestamp": 1614770555898,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "ESC_TLmo236c",
    "outputId": "c6dbcd8b-794b-49bc-a0fc-b4d7b8dfab44"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.181Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.185Z"
    },
    "executionInfo": {
     "elapsed": 54231,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AP7PUpB6FjDo"
   },
   "outputs": [],
   "source": [
    "def data_aug(df):\n",
    "    \n",
    "    import random\n",
    "    df = df.copy()\n",
    "    df[2]=df[2].apply(lambda x:x.split())\n",
    "    new_df = df.copy()\n",
    "    m =  shuffle(df)\n",
    "    m.reset_index(drop=True,inplace=True)\n",
    "    new_df[0]=100000\n",
    "    new_df[1] = new_df[1]+m[1]\n",
    "    new_df[2] = new_df[2]+m[2]\n",
    "    new_df[2]=new_df[2].apply(lambda x:\" \".join(list(set(x))))\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.190Z"
    }
   },
   "outputs": [],
   "source": [
    "m = data_aug(train_df)\n",
    "m.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ3gBoKgvOMd"
   },
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.194Z"
    },
    "executionInfo": {
     "elapsed": 54229,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "01VWaoAiFsbE"
   },
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "\n",
    "import transformers\n",
    "\n",
    "class config:\n",
    "    DEVICE = \"cuda\"\n",
    "    MAX_LEN = 150\n",
    "    TRAIN_BATCH_SIZE = 30\n",
    "    VALID_BATCH_SIZE = 30\n",
    "    MODEL_PATH = \"model.bin\"\n",
    "    EPOCHS = 10\n",
    "    BERT_PATH = \"new_macbert\"\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "\n",
    "\n",
    "save_path = config.BERT_PATH+'_weight_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUcAWkrbpmWI"
   },
   "source": [
    "## SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.199Z"
    },
    "executionInfo": {
     "elapsed": 54226,
     "status": "ok",
     "timestamp": 1614770555900,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "Erl9-n_upohh"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import torch  \n",
    "import numpy as np\n",
    "import os\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5Wra6TtssOb"
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.203Z"
    },
    "executionInfo": {
     "elapsed": 54225,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "JteBD9p1oxxp"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self,text1,text2, target):\n",
    "        self.text1 = text1\n",
    "        self.text2 = text2\n",
    "        self.target = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_length = config.MAX_LEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text1)\n",
    "\n",
    "    def get_dumm(self,s):\n",
    "        # print(\"print s\",s)\n",
    "        # print(\"s split\",s.split(' '))\n",
    "\n",
    "        re=[0]*17\n",
    "        if s=='' or s==\" \":\n",
    "            return re\n",
    "        else:\n",
    "            tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "            for i in tmp:\n",
    "                re[i]=1\n",
    "        return re\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text1 = str(self.text1[item])\n",
    "        text1 = \" \".join(text1.split())\n",
    "        text2 = None\n",
    "        # text2 = str(self.text2[item])\n",
    "        # text2 = \" \".join(text2.split())\n",
    "\n",
    "        # inputs = self.tokenizer.encode_plus(\n",
    "        #     text1,\n",
    "        #     text2,\n",
    "        #     # add_special_tokens=True,\n",
    "        #     max_length=self.max_len,\n",
    "        #     pad_to_max_length=True,\n",
    "        #     truncation=True\n",
    "        # )\n",
    "\n",
    "        # ids = inputs[\"input_ids\"]\n",
    "        # mask = inputs[\"attention_mask\"]\n",
    "        # token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text1,\n",
    "            text2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncate_first_sequence=True  # We're truncating the first sequence in priority\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        mask_padding_with_zero=True\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        pad_on_left = False\n",
    "        pad_token=0\n",
    "        pad_token_segment_id=0\n",
    "\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] )* padding_length\n",
    "                                               \n",
    "        label = self.target[item]\n",
    "        # print(\"label\",label)\n",
    "        #print(label,[i for i in label])\n",
    "        label=self.get_dumm(label)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(label, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 54222,
     "status": "ok",
     "timestamp": 1614770555901,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "hOZTjExbUVZP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.210Z"
    },
    "executionInfo": {
     "elapsed": 54221,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "AlmOklJ1JPb7"
   },
   "outputs": [],
   "source": [
    "from transformers.modeling_bert import BertPreTrainedModel,BertModel\n",
    "# from transformers.modeling_roberta import RobertaModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSl04MfxtWup"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.215Z"
    },
    "executionInfo": {
     "elapsed": 54219,
     "status": "ok",
     "timestamp": 1614770555902,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "CJQFASGKswVR"
   },
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBert(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        config.output_hidden_states = True\n",
    "        config.num_labels = 17\n",
    "\n",
    "        super(CustomBert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        n_weights = config.num_hidden_layers + 1\n",
    "        weights_init = torch.zeros(n_weights).float()\n",
    "        weights_init.data[:-1] = -3\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    "\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None,\n",
    "                ):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids\n",
    "                            )\n",
    "\n",
    "        hidden_layers = outputs[2]\n",
    "\n",
    "        cls_outputs = torch.stack([self.dropout(layer[:, 0, :]) for layer in hidden_layers],\n",
    "                                  dim=2)\n",
    "        cls_output = (torch.softmax(self.layer_weights, dim=0) * cls_outputs).sum(-1)\n",
    "\n",
    "        # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
    "        logits = torch.mean(torch.stack([\n",
    "            self.classifier(self.high_dropout(cls_output))\n",
    "            for _ in range(5)\n",
    "        ], dim=0), dim=0)\n",
    "\n",
    "        outputs = logits\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.219Z"
    },
    "executionInfo": {
     "elapsed": 54217,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "DxTdZUYgwr57"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FGM():\n",
    "    \"\"\"\n",
    "    对抗训练方法类\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.5, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s5vuD5dtqRJ"
   },
   "source": [
    "## train units && eval units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.227Z"
    },
    "executionInfo": {
     "elapsed": 54215,
     "status": "ok",
     "timestamp": 1614770555903,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "sW_BcT4ltgxX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    fgm = FGM(model)\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        fgm.attack() # 在embedding上添加对抗扰动\n",
    "        outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "        loss_adv = loss_fn(outputs, targets)\n",
    "        # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "        loss_adv.backward() \n",
    "        # 恢复embedding参数\n",
    "        fgm.restore() \n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.232Z"
    },
    "executionInfo": {
     "elapsed": 54214,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "H1UmKtbj1n-E"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "# def threshold_search(y_true, y_proba, plot=False):\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "#     thresholds = np.append(thresholds, 1.001) \n",
    "#     F = 2 / (1/precision + 1/recall)\n",
    "#     best_score = np.max(F)\n",
    "#     best_th = thresholds[np.argmax(F)]\n",
    "#     if plot:\n",
    "#         plt.plot(thresholds, F, '-b')\n",
    "#         plt.plot([best_th], [best_score], '*r')\n",
    "#         plt.show()\n",
    "#     search_result = {'threshold': best_th , 'f1': best_score}\n",
    "#     return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.237Z"
    },
    "executionInfo": {
     "elapsed": 54213,
     "status": "ok",
     "timestamp": 1614770555904,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "2Y5yWlJ1JU8T"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df[2]=''\n",
    "test_dataset = BERTDataset(text1=test_df[1].values,text2=None,target=test_df[2].values)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54207,
     "status": "ok",
     "timestamp": 1614770555905,
     "user": {
      "displayName": "yong deng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSndyur9-PDshBAHN6N5k7zPMUA9ZJNWM3SXlv=s64",
      "userId": "04661099788502381780"
     },
     "user_tz": -480
    },
    "id": "3o9ESVHNveHE",
    "outputId": "41172ca1-a855-49cb-eda9-08d5e15b0a5e"
   },
   "outputs": [],
   "source": [
    "print(test_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.246Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "To_m5aPptg0s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,GroupKFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score , recall_score\t, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold,GroupKFold\n",
    "# gkf =  GroupKFold(n_splits=5)\n",
    "# groups_by_text_id_list = train['qid'].tolist()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=4590, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "oof_df_list = []\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "oof_train_list = []\n",
    "pred = [] \n",
    "\n",
    "# score\n",
    "\n",
    "def ss_score(targets,outputs):\n",
    "    \n",
    "    targets = torch.tensor(targets,dtype=torch.float)\n",
    "    outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "    loss = nn.BCEWithLogitsLoss()(outputs.view(-1,17), targets.view(-1, 17))\n",
    "    score = 1- loss/17\n",
    "    return loss.cpu().detach().numpy(),score\n",
    "\n",
    "\n",
    "for idx,(trn_idx,val_idx) in enumerate(skf.split(train_df,train_df[2])):\n",
    "    \n",
    "\n",
    "#     if idx<1:\n",
    "#         continue\n",
    "    print(\"开始第 %d 折训练\"%(idx+1))\n",
    "    \n",
    "\n",
    "    \n",
    "    model_path = \"%s/bert_wwm_model_%d.bin\"%(save_path,idx)\n",
    "    config.MODEL_PATH = model_path\n",
    "    tr_df = train_df.iloc[trn_idx]\n",
    "    va_df = train_df.iloc[val_idx]\n",
    "    \n",
    "    tr_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #data aug\n",
    "    \n",
    "#     aug_tr_df = data_aug(tr_df)\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "    \n",
    "#     tr_df = pd.concat([tr_df,aug_tr_df])\n",
    "    \n",
    "#     print(tr_df.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    train_dataset = BERTDataset(\n",
    "        text1=tr_df[1].tolist(),text2=None,target=tr_df[2].tolist()\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4,shuffle=True\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDataset(\n",
    "     text1= va_df[1].tolist(),text2=None,target=va_df[2].tolist()\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "    )\n",
    "\n",
    "    device = torch.device(config.DEVICE)\n",
    "    model = CustomBert.from_pretrained(config.BERT_PATH,num_labels=1)\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    num_train_steps = int(len(tr_df) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    warmup_steps = int(num_train_steps*0.1)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,num_warmup_steps=warmup_steps,num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    min_loss = 100000\n",
    "    best_score =0\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "#         loss= torch.nn.BCEWithLogitsLoss()(torch.tensor(outputs),torch.tensor(targets))\n",
    "        loss,score = ss_score(targets,outputs)\n",
    "\n",
    "        # result =  threshold_search(targets,outputs)\n",
    "        # thr = result['threshold']\n",
    "        # f1 = result['f1']\n",
    "        # outputs = (outputs>thr).astype(int)\n",
    "        # f1 = f1_score(targets,outputs)\n",
    "        # precision = precision_score(targets, outputs)\n",
    "        # recall =  recall_score(targets,outputs)\n",
    "\n",
    "        print(f\"loss = {loss}, score is {score}\")\n",
    "\n",
    "\n",
    "#         if loss<min_loss:\n",
    "#             torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "#             min_loss = loss\n",
    "\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(),config.MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load( config.MODEL_PATH))\n",
    "    outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "    va_df['prob'] = outputs\n",
    "    oof_train_list.append(va_df)\n",
    "\n",
    "    outputs, targets = eval_fn(test_data_loader, model, device)\n",
    "    pred.append(np.array(outputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.250Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "TVCqxmfaHHro"
   },
   "outputs": [],
   "source": [
    "oof_train = pd.concat(oof_train_list)\n",
    "oof_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.254Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "S1svWP3sJPmb"
   },
   "outputs": [],
   "source": [
    "sub = np.average(pred, axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.258Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "xMYQOboMMx5a"
   },
   "outputs": [],
   "source": [
    "m = sub.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.262Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "lNKLriwIL5YP"
   },
   "outputs": [],
   "source": [
    "def get_dumm(s):\n",
    "    re=[0]*17\n",
    "    if s=='' or s==\" \":\n",
    "        return re\n",
    "    else:\n",
    "        tmp=[int(i) for i in s.split(' ') if i!='']\n",
    "        for i in tmp:\n",
    "            re[i]=1\n",
    "    return re\n",
    "\n",
    "\n",
    "oof_train['label'] = oof_train[2].apply(lambda x:get_dumm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.266Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.271Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_train['score'] = oof_train.apply(lambda x:ss_score(x.label,x.prob)[1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.274Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_score = oof_train.score.mean()\n",
    "print(oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.278Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "h7Mv4gKCDBfx"
   },
   "outputs": [],
   "source": [
    "test_df[2] = m\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.283Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "IybR8dA8N1I4"
   },
   "outputs": [],
   "source": [
    "test_df[0]=test_df[0].apply(lambda x:x[:-1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.287Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "awVBkOVKPRNE"
   },
   "outputs": [],
   "source": [
    "sub_id=test_df[0].values\n",
    "pres_all = sub.tolist()\n",
    "str_w=''\n",
    "with open(f'{save_path}/submit_{oof_score}.csv','w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        pres_fold = pres_all[i]\n",
    "        pres_fold=[str(p) for p in pres_fold]\n",
    "        prob = \" \".join(pres_fold)\n",
    "        str_w+=sub_id[i]+'|'+','+'|'+prob+'\\n'\n",
    "    str_w=str_w.strip('\\n')\n",
    "    f.write(str_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-13T17:56:37.291Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "mirMQlPPmHNI"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(f\"{save_path}/oof_test_{score}.csv\")\n",
    "oof_train.to_csv(f\"{save_path}/oof_train_{score}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BMxuk94uvEhw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_transformers_gpu_macbert_model-多标签分类v2.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
